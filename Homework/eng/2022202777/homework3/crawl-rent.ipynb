{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#调用函数\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#翻页函数\n",
    "def next_page(driver):\n",
    "    try:\n",
    "        next_page = driver.find_element(By.LINK_TEXT, \"下一页\")\n",
    "        next_page.click()\n",
    "    except NoSuchElementException:\n",
    "        print(\"NoSuchElementException\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#爬取函数\n",
    "def scrape_page_data(driver):\n",
    "    data = []\n",
    "    houses = driver.find_elements(By.CSS_SELECTOR, 'dl.list.hiddenMap.rel')\n",
    "\n",
    "    for house in houses:\n",
    "        try:\n",
    "            title = house.find_element(\n",
    "                By.CSS_SELECTOR, 'p.title a').get_attribute('title')\n",
    "            price = house.find_element(By.CSS_SELECTOR, 'span.price').text\n",
    "            house_info = house.find_element(\n",
    "                By.CSS_SELECTOR, 'p.font15.mt12.bold').text\n",
    "            info_parts = [x.strip() for x in house_info.split('|')]\n",
    "            area = house.find_element(\n",
    "                By.CSS_SELECTOR, 'p.gray6.mt12').text.replace('\\n', ' ')\n",
    "            try:\n",
    "                metro = house.find_element(\n",
    "                    By.CSS_SELECTOR, 'span.note.subInfor').text\n",
    "            except:\n",
    "                metro = '无'\n",
    "\n",
    "            item = {\n",
    "                '标题': title,\n",
    "                '价格(元/月)': price,\n",
    "                '租赁类型': info_parts[0],\n",
    "                '户型': info_parts[1],\n",
    "                '面积': info_parts[2],\n",
    "                '朝向': info_parts[3],\n",
    "                '区域': area,\n",
    "                '交通信息': metro\n",
    "            }\n",
    "\n",
    "            data.append(item)\n",
    "        except Exception as e:\n",
    "            print(f'解析条目时出错：{str(e)}')\n",
    "            continue\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存数据\n",
    "def save_data(data, filename, is_first_page=False):\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(filename,\n",
    "              mode='a' if not is_first_page else 'w',\n",
    "              header=is_first_page,\n",
    "              index=False,\n",
    "              encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义爬取要求\n",
    "def scrape_real_estate_data(url, filename, max_pages=20):\n",
    "    driver = webdriver.Edge()\n",
    "    driver.get(url)\n",
    "    sleep(20)\n",
    "\n",
    "    first_page = True\n",
    "    for i in range(max_pages):\n",
    "        page_data = scrape_page_data(driver)\n",
    "        save_data(page_data, filename, is_first_page=first_page)\n",
    "        print(f\"第{i+1}页数据处理完成\")\n",
    "        first_page = False\n",
    "        if i < max_pages - 1:\n",
    "            next_page(driver)\n",
    "            sleep(3)\n",
    "    \n",
    "    print(f\"前{max_pages}页处理完成\")\n",
    "    print(f\"爬取网址：{url}\")\n",
    "    print(f\"总页数：{max_pages}\")\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1页数据处理完成\n",
      "第2页数据处理完成\n",
      "NoSuchElementException\n",
      "第3页数据处理完成\n",
      "NoSuchElementException\n",
      "第4页数据处理完成\n",
      "NoSuchElementException\n",
      "第5页数据处理完成\n",
      "NoSuchElementException\n",
      "第6页数据处理完成\n",
      "NoSuchElementException\n",
      "第7页数据处理完成\n",
      "NoSuchElementException\n",
      "第8页数据处理完成\n",
      "NoSuchElementException\n",
      "第9页数据处理完成\n",
      "NoSuchElementException\n",
      "第10页数据处理完成\n",
      "NoSuchElementException\n",
      "第11页数据处理完成\n",
      "NoSuchElementException\n",
      "第12页数据处理完成\n",
      "NoSuchElementException\n",
      "第13页数据处理完成\n",
      "NoSuchElementException\n",
      "第14页数据处理完成\n",
      "NoSuchElementException\n",
      "第15页数据处理完成\n",
      "NoSuchElementException\n",
      "第16页数据处理完成\n",
      "NoSuchElementException\n",
      "第17页数据处理完成\n",
      "NoSuchElementException\n",
      "第18页数据处理完成\n",
      "NoSuchElementException\n",
      "第19页数据处理完成\n",
      "NoSuchElementException\n",
      "第20页数据处理完成\n",
      "前20页处理完成\n",
      "爬取网址：https://tj.zu.fang.com/house-a041-b0967/\n",
      "总页数：20\n"
     ]
    }
   ],
   "source": [
    "#爬取数据\n",
    "scrape_real_estate_data('https://tj.zu.fang.com/house-a041-b0967/', 'rent1-tianjin-balitai.csv', max_pages=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
