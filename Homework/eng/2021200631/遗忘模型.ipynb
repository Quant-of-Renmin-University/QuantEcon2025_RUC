{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07a525ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wrds\n",
    "from pandas.tseries.offsets import *\n",
    "import pickle as pkl\n",
    "import pyarrow.feather as feather\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from scipy.stats import spearmanr\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from typing import Dict, List\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "def v(x,y=5):\n",
    "    print(x.shape)\n",
    "    print(x.head(y))\n",
    "\n",
    "def cm(df):\n",
    "    cols_with_nan = df.columns[df.isna().any()].tolist()\n",
    "    rows_with_nan = df[df.isna().any(axis=1)]\n",
    "    print(cols_with_nan,rows_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2782c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_imputed = pd.read_csv('D:/股票项目/chars60/chars60_rank_imputed.csv')\n",
    "rank_imputed[:1000].to_excel('D:/股票项目/chars60/chars60_rank_impute.xlsx')\n",
    "rank_imputed = rank_imputed[[col for col in rank_imputed.columns if col!='Unnamed: 0']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7527dffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "缺失值填充成功！\n",
      "(332271, 70)\n",
      "   gvkey  permno   sic       ret  exchcd  shrcd        date  ffi49  \\\n",
      "0   1004   54594  5080  0.029534     1.0   11.0  2016-10-31     42   \n",
      "1   1004   54594  5080  0.146721     1.0   11.0  2016-11-30     42   \n",
      "2   1004   54594  5080 -0.104093     1.0   11.0  2016-12-31     42   \n",
      "3   1004   54594  5080 -0.029803     1.0   11.0  2017-01-31     42   \n",
      "4   1004   54594  5080  0.075961     1.0   11.0  2017-02-28     42   \n",
      "\n",
      "       lag_me  rank_mom36m  ...  rank_lev  rank_me_ia  rank_cfp  rank_hire  \\\n",
      "0  1070329.68     0.014351  ...  0.167702    0.621118  0.540373        1.0   \n",
      "1  1099377.58     0.000000  ...  0.099602    0.657371  0.541833        0.0   \n",
      "2  1260678.86     0.000000  ...  0.072897    0.648598  0.461682        0.0   \n",
      "3  1134573.45     0.014351  ...  0.143363    0.610619  0.582301       -1.0   \n",
      "4  1098184.71     0.000000  ...  0.123139    0.610284  0.610284        0.0   \n",
      "\n",
      "   rank_cashdebt   rank_me  rank_ni  rank_roa  rank_grltnoa     log_me  \n",
      "0            0.0  0.136646      0.0 -0.093458           0.0  13.883477  \n",
      "1            0.0  0.243028      0.0  0.081836           0.0  13.910255  \n",
      "2            0.0  0.263551      0.0  0.035647           0.0  14.047161  \n",
      "3            0.0  0.203540      0.0  0.058407           0.0  13.941767  \n",
      "4            0.0  0.161028      0.0  0.031208           0.0  13.909169  \n",
      "\n",
      "[5 rows x 70 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gvkey</th>\n",
       "      <th>permno</th>\n",
       "      <th>sic</th>\n",
       "      <th>ret</th>\n",
       "      <th>exchcd</th>\n",
       "      <th>shrcd</th>\n",
       "      <th>date</th>\n",
       "      <th>ffi49</th>\n",
       "      <th>lag_me</th>\n",
       "      <th>rank_mom36m</th>\n",
       "      <th>...</th>\n",
       "      <th>rank_roa</th>\n",
       "      <th>rank_grltnoa</th>\n",
       "      <th>log_me</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>lag_ret_1</th>\n",
       "      <th>lag_ret_3</th>\n",
       "      <th>monthly_stocks</th>\n",
       "      <th>industry_ret</th>\n",
       "      <th>market_ret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12825</td>\n",
       "      <td>10026</td>\n",
       "      <td>2050</td>\n",
       "      <td>-0.033289</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>2</td>\n",
       "      <td>2.519068e+06</td>\n",
       "      <td>0.122405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.667826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.739400</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.007229</td>\n",
       "      <td>0.048836</td>\n",
       "      <td>726</td>\n",
       "      <td>-0.045933</td>\n",
       "      <td>-0.008713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12825</td>\n",
       "      <td>10026</td>\n",
       "      <td>2050</td>\n",
       "      <td>0.018371</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2017-06-30</td>\n",
       "      <td>2</td>\n",
       "      <td>2.435212e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.675408</td>\n",
       "      <td>0.480519</td>\n",
       "      <td>14.705544</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.033289</td>\n",
       "      <td>0.016293</td>\n",
       "      <td>764</td>\n",
       "      <td>-0.004490</td>\n",
       "      <td>0.015313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12825</td>\n",
       "      <td>10026</td>\n",
       "      <td>2050</td>\n",
       "      <td>-0.005073</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2</td>\n",
       "      <td>2.473539e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.671441</td>\n",
       "      <td>0.662420</td>\n",
       "      <td>14.721161</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>0.018371</td>\n",
       "      <td>-0.007229</td>\n",
       "      <td>807</td>\n",
       "      <td>0.008039</td>\n",
       "      <td>0.000371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12825</td>\n",
       "      <td>10026</td>\n",
       "      <td>2050</td>\n",
       "      <td>-0.029756</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>2</td>\n",
       "      <td>2.462304e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.839416</td>\n",
       "      <td>0.273617</td>\n",
       "      <td>14.716608</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.005073</td>\n",
       "      <td>-0.033289</td>\n",
       "      <td>3421</td>\n",
       "      <td>-0.027544</td>\n",
       "      <td>-0.016907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12825</td>\n",
       "      <td>10026</td>\n",
       "      <td>2050</td>\n",
       "      <td>0.033179</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>2</td>\n",
       "      <td>2.389035e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841316</td>\n",
       "      <td>0.271078</td>\n",
       "      <td>14.686400</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.029756</td>\n",
       "      <td>0.018371</td>\n",
       "      <td>3402</td>\n",
       "      <td>0.045498</td>\n",
       "      <td>0.073296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316382</th>\n",
       "      <td>184996</td>\n",
       "      <td>93436</td>\n",
       "      <td>3711</td>\n",
       "      <td>-0.077391</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2024-08-31</td>\n",
       "      <td>23</td>\n",
       "      <td>7.413801e+08</td>\n",
       "      <td>0.110106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551696</td>\n",
       "      <td>-0.200882</td>\n",
       "      <td>20.424024</td>\n",
       "      <td>2024</td>\n",
       "      <td>8</td>\n",
       "      <td>0.172781</td>\n",
       "      <td>-0.028372</td>\n",
       "      <td>3679</td>\n",
       "      <td>-0.081720</td>\n",
       "      <td>-0.024281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316383</th>\n",
       "      <td>184996</td>\n",
       "      <td>93436</td>\n",
       "      <td>3711</td>\n",
       "      <td>0.221942</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2024-09-30</td>\n",
       "      <td>23</td>\n",
       "      <td>6.840044e+08</td>\n",
       "      <td>0.141393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551432</td>\n",
       "      <td>-0.200127</td>\n",
       "      <td>20.343475</td>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.077391</td>\n",
       "      <td>0.111186</td>\n",
       "      <td>3658</td>\n",
       "      <td>-0.044205</td>\n",
       "      <td>0.003945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316384</th>\n",
       "      <td>184996</td>\n",
       "      <td>93436</td>\n",
       "      <td>3711</td>\n",
       "      <td>-0.045025</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>23</td>\n",
       "      <td>8.390474e+08</td>\n",
       "      <td>-0.015357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.547253</td>\n",
       "      <td>-0.198337</td>\n",
       "      <td>20.547778</td>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>0.221942</td>\n",
       "      <td>0.172781</td>\n",
       "      <td>3629</td>\n",
       "      <td>-0.058508</td>\n",
       "      <td>-0.001507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316385</th>\n",
       "      <td>184996</td>\n",
       "      <td>93436</td>\n",
       "      <td>3711</td>\n",
       "      <td>0.381469</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2024-11-30</td>\n",
       "      <td>23</td>\n",
       "      <td>8.020335e+08</td>\n",
       "      <td>-0.099911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651624</td>\n",
       "      <td>-0.232676</td>\n",
       "      <td>20.502661</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.045025</td>\n",
       "      <td>-0.077391</td>\n",
       "      <td>3624</td>\n",
       "      <td>0.046959</td>\n",
       "      <td>0.100034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316386</th>\n",
       "      <td>184996</td>\n",
       "      <td>93436</td>\n",
       "      <td>3711</td>\n",
       "      <td>0.170008</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>23</td>\n",
       "      <td>1.107984e+09</td>\n",
       "      <td>-0.185141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645983</td>\n",
       "      <td>-0.235558</td>\n",
       "      <td>20.825808</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>0.381469</td>\n",
       "      <td>0.221942</td>\n",
       "      <td>3601</td>\n",
       "      <td>-0.078558</td>\n",
       "      <td>-0.030060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>316387 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         gvkey  permno   sic       ret  exchcd  shrcd       date  ffi49  \\\n",
       "0        12825   10026  2050 -0.033289     3.0   11.0 2017-05-31      2   \n",
       "1        12825   10026  2050  0.018371     3.0   11.0 2017-06-30      2   \n",
       "2        12825   10026  2050 -0.005073     3.0   11.0 2017-07-31      2   \n",
       "3        12825   10026  2050 -0.029756     3.0   11.0 2017-08-31      2   \n",
       "4        12825   10026  2050  0.033179     3.0   11.0 2017-09-30      2   \n",
       "...        ...     ...   ...       ...     ...    ...        ...    ...   \n",
       "316382  184996   93436  3711 -0.077391     3.0   11.0 2024-08-31     23   \n",
       "316383  184996   93436  3711  0.221942     3.0   11.0 2024-09-30     23   \n",
       "316384  184996   93436  3711 -0.045025     3.0   11.0 2024-10-31     23   \n",
       "316385  184996   93436  3711  0.381469     3.0   11.0 2024-11-30     23   \n",
       "316386  184996   93436  3711  0.170008     3.0   11.0 2024-12-31     23   \n",
       "\n",
       "              lag_me  rank_mom36m  ...  rank_roa  rank_grltnoa     log_me  \\\n",
       "0       2.519068e+06     0.122405  ...  0.667826      0.000000  14.739400   \n",
       "1       2.435212e+06     0.000000  ...  0.675408      0.480519  14.705544   \n",
       "2       2.473539e+06     0.000000  ...  0.671441      0.662420  14.721161   \n",
       "3       2.462304e+06     0.000000  ...  0.839416      0.273617  14.716608   \n",
       "4       2.389035e+06     0.000000  ...  0.841316      0.271078  14.686400   \n",
       "...              ...          ...  ...       ...           ...        ...   \n",
       "316382  7.413801e+08     0.110106  ...  0.551696     -0.200882  20.424024   \n",
       "316383  6.840044e+08     0.141393  ...  0.551432     -0.200127  20.343475   \n",
       "316384  8.390474e+08    -0.015357  ...  0.547253     -0.198337  20.547778   \n",
       "316385  8.020335e+08    -0.099911  ...  0.651624     -0.232676  20.502661   \n",
       "316386  1.107984e+09    -0.185141  ...  0.645983     -0.235558  20.825808   \n",
       "\n",
       "        year  month  lag_ret_1  lag_ret_3  monthly_stocks  industry_ret  \\\n",
       "0       2017      5  -0.007229   0.048836             726     -0.045933   \n",
       "1       2017      6  -0.033289   0.016293             764     -0.004490   \n",
       "2       2017      7   0.018371  -0.007229             807      0.008039   \n",
       "3       2017      8  -0.005073  -0.033289            3421     -0.027544   \n",
       "4       2017      9  -0.029756   0.018371            3402      0.045498   \n",
       "...      ...    ...        ...        ...             ...           ...   \n",
       "316382  2024      8   0.172781  -0.028372            3679     -0.081720   \n",
       "316383  2024      9  -0.077391   0.111186            3658     -0.044205   \n",
       "316384  2024     10   0.221942   0.172781            3629     -0.058508   \n",
       "316385  2024     11  -0.045025  -0.077391            3624      0.046959   \n",
       "316386  2024     12   0.381469   0.221942            3601     -0.078558   \n",
       "\n",
       "        market_ret  \n",
       "0        -0.008713  \n",
       "1         0.015313  \n",
       "2         0.000371  \n",
       "3        -0.016907  \n",
       "4         0.073296  \n",
       "...            ...  \n",
       "316382   -0.024281  \n",
       "316383    0.003945  \n",
       "316384   -0.001507  \n",
       "316385    0.100034  \n",
       "316386   -0.030060  \n",
       "\n",
       "[316387 rows x 77 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = rank_imputed.copy()\n",
    "def fmm(data, group_col='permno'):\n",
    "    # 1. 分离分组列与数值列\n",
    "    if group_col not in data.columns:\n",
    "        raise ValueError(f\"分组列'{group_col}'不存在于数据中！\")\n",
    "    \n",
    "    numeric_cols = data.select_dtypes(include=np.number).columns.drop(group_col)  # 提取数值列（排除分组列）\n",
    "    if not numeric_cols.size:\n",
    "        raise ValueError(\"数据中没有可填充的数值列！\")\n",
    "    \n",
    "    # 2. 按分组列计算数值列的中位数（处理空分组和全NaN分组）\n",
    "    group_medians = data.groupby(group_col)[numeric_cols].transform(\n",
    "        lambda x: x.median() if x.notna().any() else np.nan  # 若分组全为NaN，暂存为NaN\n",
    "    )\n",
    "    \n",
    "    # 3. 用全局中位数填充分组中位数中的NaN（避免全NaN分组无法填充）\n",
    "    for col in numeric_cols:\n",
    "        global_median = data[col].median()  # 计算全局中位数\n",
    "        group_medians[col] = group_medians[col].fillna(global_median)  # 填充NaN分组\n",
    "    \n",
    "    # 4. 填充原始数据的缺失值\n",
    "    data_filled = data.copy()\n",
    "    data_filled[numeric_cols] = data_filled[numeric_cols].fillna(group_medians)\n",
    "    \n",
    "    # 5. 检查填充结果（可选但重要）\n",
    "    missing_count = data_filled[numeric_cols].isna().sum().sum()\n",
    "    if missing_count > 0:\n",
    "        print(f\"警告：填充后仍有 {missing_count} 个缺失值，可能因全NaN分组无法填充，建议手动处理或删除相关行。\")\n",
    "    else:\n",
    "        print(\"缺失值填充成功！\")\n",
    "    return data_filled\n",
    "data = fmm(data)\n",
    "data = data.dropna()\n",
    "v(data)\n",
    "\n",
    "## 预处理\n",
    "def preprocess_data(data):\n",
    "    # 将日期转换为datetime格式并提取年、月\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    data['year'] = data['date'].dt.year\n",
    "    data['month'] = data['date'].dt.month\n",
    "    \n",
    "    # 移除包含缺失值的行\n",
    "    data = data.dropna()\n",
    "    \n",
    "    # 创建滞后收益率特征\n",
    "    data = data.sort_values(['permno', 'date'])\n",
    "    data['lag_ret_1'] = data.groupby('permno')['ret'].shift(1)\n",
    "    data['lag_ret_3'] = data.groupby('permno')['ret'].shift(3)\n",
    "    # data['lag_ret_6'] = data.groupby('permno')['ret'].shift(6)\n",
    "    \n",
    "    # 移除包含NaN的行（由于滞后操作产生）\n",
    "    data = data.dropna()\n",
    "    \n",
    "    return data\n",
    "\n",
    "## 行业数据\n",
    "def engineer_features(data):\n",
    "    # 计算每个月的股票数量\n",
    "    monthly_stocks = data.groupby(['year', 'month'])['permno'].count().reset_index()\n",
    "    monthly_stocks.rename(columns={'permno': 'monthly_stocks'}, inplace=True)\n",
    "    data = pd.merge(data, monthly_stocks, on=['year', 'month'], how='left')\n",
    "    \n",
    "    # 计算行业平均收益率\n",
    "    industry_ret = data.groupby(['ffi49', 'year', 'month'])['ret'].mean().reset_index()\n",
    "    industry_ret.rename(columns={'ret': 'industry_ret'}, inplace=True)\n",
    "    data = pd.merge(data, industry_ret, on=['ffi49', 'year', 'month'], how='left')\n",
    "    \n",
    "    # 计算市场平均收益率\n",
    "    market_ret = data.groupby(['year', 'month'])['ret'].mean().reset_index()\n",
    "    market_ret.rename(columns={'ret': 'market_ret'}, inplace=True)\n",
    "    data = pd.merge(data, market_ret, on=['year', 'month'], how='left')\n",
    "    \n",
    "    return data\n",
    "\n",
    "processed_data = preprocess_data(data)\n",
    "edata = engineer_features(processed_data)\n",
    "edata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1905df37",
   "metadata": {},
   "source": [
    "### 遗忘模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2df1235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征分类映射\n",
    "feature_categories = {\n",
    "    \"动量特征\": ['rank_mom1m', 'rank_mom6m', 'rank_mom12m', 'rank_mom36m', 'rank_mom60m'],\n",
    "    \"波动性特征\": ['rank_rvar_mean', 'rank_std_dolvol', 'rank_rvar_ff3', 'rank_baspread', \n",
    "              'rank_std_turn', 'rank_rvar_capm', 'rank_maxret'],\n",
    "    \"基本面特征\": ['rank_op', 'rank_rd_sale', 'rank_noa', 'rank_bm', 'rank_bm_ia', 'rank_acc',\n",
    "             'rank_ato', 'rank_pm', 'rank_agr', 'rank_roe', 'rank_gma', 'rank_cfp',\n",
    "             'rank_ni', 'rank_roa'],\n",
    "    \"流动性特征\": ['rank_dolvol', 'rank_ill', 'rank_turn', 'rank_zerotrade'],\n",
    "    \"市场相关特征\": ['market_ret', 'industry_ret', 'lag_ret_1', 'lag_ret_3'],\n",
    "    \"成长性特征\": ['rank_rsup', 'rank_nincr', 'rank_sue', 'rank_sgr', 'rank_chpm', 'rank_lgr'],\n",
    "    \"风险特征\": ['rank_beta', 'rank_lev'],\n",
    "    \"其他特征\": ['rank_abr', 'rank_adm', 'rank_chtx', 'rank_pctacc', 'rank_rdm', 'rank_depr',\n",
    "           'rank_pscore', 'rank_cash', 'rank_rna', 'rank_chcsho', 'rank_sp', \n",
    "           'rank_cinvest', 'rank_me_ia', 'rank_hire', 'rank_cashdebt', 'rank_me',\n",
    "           'rank_grltnoa', 'log_me', 'lag_me']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56abcceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockDataset(Dataset):\n",
    "    def __init__(self, features, targets, permnos, dates):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        self.permnos = permnos  # 保留股票标识符\n",
    "        self.dates = dates      # 保留日期信息\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx], self.permnos[idx], self.dates[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c3524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, num_stocks, hidden_size=64, num_layers=2, output_size=1, dropout=0.2):\n",
    "        super(EnhancedLSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # 股票嵌入层 - 学习不同股票的特性\n",
    "        self.stock_embedding = nn.Embedding(num_stocks, 16)\n",
    "        \n",
    "        # LSTM层捕获时序特征\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size + 16,  # 输入维度增加嵌入层输出\n",
    "            hidden_size, \n",
    "            num_layers, \n",
    "            batch_first=True, \n",
    "            dropout=dropout, \n",
    "            bidirectional=False\n",
    "        )\n",
    "        \n",
    "        # 全连接层输出预测\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(32, output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, stock_ids):\n",
    "        # 获取股票嵌入\n",
    "        stock_embed = self.stock_embedding(stock_ids)\n",
    "        \n",
    "        # 将嵌入与特征连接\n",
    "        batch_size, seq_len, feat_dim = x.size()\n",
    "        stock_embed_expanded = stock_embed.unsqueeze(1).expand(-1, seq_len, -1)\n",
    "        x_combined = torch.cat([x, stock_embed_expanded], dim=2)\n",
    "        \n",
    "        # LSTM前向传播\n",
    "        h0 = torch.zeros(self.num_layers, x_combined.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x_combined.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x_combined, (h0, c0))\n",
    "        \n",
    "        # 只取最后一个时间步的输出\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "def identify_quality_data(data):\n",
    "    \"\"\"识别高质量数据\"\"\"\n",
    "    momentum_score = data[feature_categories[\"动量特征\"]].mean(axis=1)\n",
    "    volatility_score = 1 - data[feature_categories[\"波动性特征\"]].mean(axis=1)\n",
    "    fundamental_score = data[feature_categories[\"基本面特征\"]].mean(axis=1)\n",
    "    \n",
    "    momentum_score = (momentum_score - momentum_score.min()) / (momentum_score.max() - momentum_score.min())\n",
    "    volatility_score = (volatility_score - volatility_score.min()) / (volatility_score.max() - volatility_score.min())\n",
    "    fundamental_score = (fundamental_score - fundamental_score.min()) / (fundamental_score.max() - fundamental_score.min())\n",
    "    \n",
    "    data['quality_score'] = 0.4 * momentum_score + 0.3 * volatility_score + 0.3 * fundamental_score\n",
    "    quality_threshold = data['quality_score'].quantile(0.8)\n",
    "    return data[data['quality_score'] >= quality_threshold]\n",
    "\n",
    "def identify_noise_data(data):\n",
    "    \"\"\"识别低质量/噪声数据\"\"\"\n",
    "    vol_cols = feature_categories[\"波动性特征\"]\n",
    "    vol_zscore = (data[vol_cols] - data[vol_cols].mean()) / data[vol_cols].std()\n",
    "    vol_outlier = (vol_zscore > 3).any(axis=1)\n",
    "    \n",
    "    liquidity_cols = ['rank_dolvol', 'rank_turn']\n",
    "    liquidity_score = data[liquidity_cols].mean(axis=1)\n",
    "    low_liquidity = liquidity_score < liquidity_score.quantile(0.2)\n",
    "    \n",
    "    ret_zscore = (data['ret'] - data['ret'].mean()) / data['ret'].std()\n",
    "    extreme_ret = ret_zscore.abs() > 3\n",
    "    \n",
    "    noise_mask = vol_outlier | low_liquidity | extreme_ret\n",
    "    return data[noise_mask]\n",
    "\n",
    "def detect_structural_change(self, stock_data, lookback=6):\n",
    "        \"\"\"使用贝叶斯在线变点检测(BOCPD)检测结构性变化\"\"\"\n",
    "        if len(stock_data) < 12: \n",
    "            return False\n",
    "        features = stock_data[['ret', 'rank_mom12m', 'rank_bm']]\n",
    "        # 标准化特征\n",
    "        scaler = StandardScaler()\n",
    "        scaled_features = scaler.fit_transform(features)\n",
    "        \n",
    "        norms = np.linalg.norm(scaled_features, axis=1)\n",
    "        hazard = 1/20  \n",
    "        log_R = np.zeros(len(norms)  \n",
    "        log_R[0] = 0  # 初始概率\n",
    "        # 使用高斯分布作为似然函数\n",
    "        mean = norms[0]\n",
    "        var = 1e-3\n",
    "        precision = 1/var\n",
    "        \n",
    "        for t in range(1, len(norms)):\n",
    "            # 预测步\n",
    "            log_R[t] = np.log(hazard) + np.max(log_R[:t])\n",
    "            # 更新步\n",
    "            diff = norms[t] - mean\n",
    "            log_likelihood = -0.5 * (np.log(2 * np.pi) + 0.5 * np.log(precision) - 0.5 * precision * diff**2\n",
    "            \n",
    "            # 更新分布参数\n",
    "            new_precision = precision + 1\n",
    "            new_mean = (precision * mean + norms[t]) / new_precision\n",
    "            \n",
    "            # 更新概率\n",
    "            log_R[t] += log_likelihood\n",
    "            \n",
    "            # 更新当前分布\n",
    "            mean = new_mean\n",
    "            precision = new_precision\n",
    "        \n",
    "        # 检测最近lookback个月内是否有变点\n",
    "        recent_prob = log_R[-lookback:]\n",
    "        return np.any(recent_prob > np.percentile(log_R, 95))  # 超过95%分位数视为变点\n",
    "\n",
    "class NeuralStockForgettingModel:\n",
    "    def __init__(self, \n",
    "                 input_size, \n",
    "                 stock_mapping,  # 股票ID到索引的映射\n",
    "                 hidden_size=16, \n",
    "                 num_layers=1, \n",
    "                 output_size=1,\n",
    "                 seq_length=8,\n",
    "                 min_history=12,\n",
    "                 device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.device = device\n",
    "        self.seq_length = seq_length\n",
    "        self.min_history = min_history\n",
    "        self.stock_mapping = stock_mapping\n",
    "        self.model = EnhancedLSTMModel(\n",
    "            input_size, \n",
    "            len(stock_mapping), \n",
    "            hidden_size, \n",
    "            num_layers, \n",
    "            output_size\n",
    "        ).to(device)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.memory_bank = pd.DataFrame()\n",
    "        self.predictions_df = pd.DataFrame(columns=['permno', 'date', 'pred_ret', 'memory_type', 'actual_ret'])\n",
    "        self.feature_columns = [col for col in data.columns if col not in \n",
    "                               ['gvkey', 'permno', 'ret', 'date', 'ffi49', 'exchcd', 'shrcd', 'year', 'month', 'monthly_stocks']]\n",
    "        self.scaler = StandardScaler()\n",
    "        self.eval_metrics = {}\n",
    "        self.structural_changes = {}  # 记录发生结构性变化的股票\n",
    "        \n",
    "    def _prepare_sequences(self, data, target_col='ret'):\n",
    "        # 移除不必要的股票分组（关键优化！）\n",
    "        # 直接处理全局数据，利用向量化计算替代groupby\n",
    "        values = data[self.feature_columns].values\n",
    "        targets = data[target_col].values\n",
    "        stock_indices = data['permno'].map(self.stock_mapping).values\n",
    "            \n",
    "         # 标准化仅在首次调用时拟合（避免每月重复计算）\n",
    "        if not hasattr(self, 'scaler_fitted'):\n",
    "            self.scaler.fit(values)\n",
    "            self.scaler_fitted = True\n",
    "        values = self.scaler.transform(values)\n",
    "            \n",
    "        # 滑动窗口向量化生成序列（替代循环）\n",
    "        n = len(values) - self.seq_length\n",
    "        if n < 0: return [], [], [], [], []\n",
    "        X = np.stack([values[i:i+self.seq_length] for i in range(n)])\n",
    "        y = targets[self.seq_length-1:n+self.seq_length-1]\n",
    "        dates = data['date'].values[self.seq_length-1:n+self.seq_length-1]\n",
    "        permnos = data['permno'].values[self.seq_length-1:n+self.seq_length-1]\n",
    "        stock_indices = stock_indices[self.seq_length-1:n+self.seq_length-1]\n",
    "    \n",
    "        return X, y, dates, permnos, stock_indices\n",
    "    \n",
    "    \n",
    "    def _train_epoch(self, dataloader):\n",
    "        \"\"\"训练模型一个轮次\"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for features, targets, stock_ids, _ in dataloader:\n",
    "            features = features.to(self.device).float()\n",
    "            targets = targets.to(self.device).float().view(-1, 1)\n",
    "            stock_ids = stock_ids.to(self.device).long()\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(features, stock_ids)\n",
    "            loss = self.criterion(outputs, targets)\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        return total_loss / len(dataloader)\n",
    "    \n",
    "    def _predict_on_data(self, data, current_date, memory_type='core'):\n",
    "        \"\"\"对给定数据进行预测并记录结果\"\"\"\n",
    "        self.model.eval()\n",
    "        predictions = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            X, y, dates, permnos, stock_indices = self._prepare_sequences(data)\n",
    "            \n",
    "            if len(X) == 0:\n",
    "                return\n",
    "                \n",
    "            features_tensor = torch.tensor(X).to(self.device).float()\n",
    "            stock_ids_tensor = torch.tensor(stock_indices).to(self.device).long()\n",
    "            \n",
    "            outputs = self.model(features_tensor, stock_ids_tensor).cpu().numpy().flatten()\n",
    "            \n",
    "            for i in range(len(outputs)):\n",
    "                # 检查是否为结构性变化的股票\n",
    "                is_structural_change = permnos[i] in self.structural_changes\n",
    "                \n",
    "                predictions.append({\n",
    "                    'permno': permnos[i],\n",
    "                    'date': dates[i],\n",
    "                    'pred_ret': outputs[i],\n",
    "                    'memory_type': memory_type,\n",
    "                    'actual_ret': y[i],\n",
    "                    'structural_change': is_structural_change\n",
    "                })\n",
    "        \n",
    "        if predictions:\n",
    "            batch_pred = pd.DataFrame(predictions)\n",
    "            self.predictions_df = pd.concat([\n",
    "                self.predictions_df[~((self.predictions_df['permno'].isin(batch_pred['permno'])) & \n",
    "                                     (self.predictions_df['date'].isin(batch_pred['date'])))]\n",
    "                , batch_pred\n",
    "            ])\n",
    "    \n",
    "    def train_and_predict(self, full_data, epochs=3):\n",
    "        \"\"\"全数据训练并生成预测\"\"\"\n",
    "        # 确保日期格式正确\n",
    "        full_data['date'] = pd.to_datetime(full_data['date'])\n",
    "        \n",
    "        # 确定全局最小和最大日期\n",
    "        global_min_date = full_data['date'].min()\n",
    "        # global_max_date = full_data['date'].max()\n",
    "        global_max_date = pd.to_datetime('2021-12-01')\n",
    "        \n",
    "        # 生成逐月的日期序列\n",
    "        date_range = pd.date_range(start=global_min_date, end=global_max_date, freq='MS')\n",
    "        \n",
    "        # 对每个月进行处理\n",
    "        for current_date in date_range:\n",
    "            print(f\"处理日期: {current_date}\")\n",
    "            \n",
    "            # 获取当前月及之前的所有数据\n",
    "            current_data = full_data[full_data['date'] <= current_date].copy()\n",
    "            \n",
    "            # 更新记忆库\n",
    "            self._update_memory(current_data, current_date=current_date)\n",
    "            \n",
    "            # 检查记忆库中是否有足够的数据\n",
    "            if len(self.memory_bank) < self.min_history:\n",
    "                continue\n",
    "                \n",
    "            # 准备训练数据\n",
    "            X_train, y_train, _, _, stock_indices = self._prepare_sequences(self.memory_bank)\n",
    "            \n",
    "            if len(X_train) == 0:\n",
    "                continue\n",
    "                \n",
    "            # 创建数据加载器\n",
    "            train_dataset = StockDataset(X_train, y_train, stock_indices, np.zeros(len(y_train)))\n",
    "            train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "            \n",
    "            # 模型训练\n",
    "            for epoch in range(epochs):\n",
    "                train_loss = self._train_epoch(train_loader)\n",
    "                print(f\"Epoch {epoch+1}/{epochs}, Loss: {train_loss:.6f}\")\n",
    "            \n",
    "            # 早停机制（避免无效迭代）\n",
    "            best_loss = np.inf\n",
    "            early_stopping_count = 0\n",
    "            for epoch in range(epochs):\n",
    "                train_loss = self._train_epoch(train_loader)\n",
    "                if train_loss > best_loss:\n",
    "                    early_stopping_count += 1\n",
    "                    if early_stopping_count >= 1: break  # loss上升则停止\n",
    "                else:\n",
    "                    best_loss = train_loss\n",
    "                    early_stopping_count = 0\n",
    "            \n",
    "            # 对当前所有数据进行预测\n",
    "            self._predict_on_data(current_data, current_date, memory_type='train')\n",
    "            \n",
    "            # 对当前月的数据单独预测（如果有）\n",
    "            current_month_data = full_data[full_data['date'] == current_date]\n",
    "            \n",
    "            if not current_month_data.empty:\n",
    "                self._predict_on_data(current_month_data, current_date, memory_type='test')\n",
    "        \n",
    "        # 计算评估指标\n",
    "        self._calculate_metrics()\n",
    "    \n",
    "    def _update_memory(self, new_data, current_date):\n",
    "        \"\"\"动态更新记忆库\"\"\"\n",
    "        if not self.memory_bank.empty:\n",
    "            time_diff = (current_date - self.memory_bank['date']).dt.days / 30\n",
    "            decay_factor = np.exp(-0.02 * time_diff)\n",
    "            self.memory_bank = self.memory_bank[decay_factor >= 0.15]\n",
    "            self.memory_bank = self.memory_bank[(current_date - self.memory_bank['date']) <= pd.Timedelta(days=30*24)]\n",
    "        \n",
    "        self.memory_bank = pd.concat([self.memory_bank, new_data], ignore_index=True).drop_duplicates()\n",
    "        \n",
    "        quality_data = identify_quality_data(self.memory_bank)\n",
    "        self.memory_bank.loc[quality_data.index, 'memory_type'] = 'quality'\n",
    "        \n",
    "        noise_data = identify_noise_data(self.memory_bank)\n",
    "        self.memory_bank = self.memory_bank.drop(noise_data.index, errors='ignore')\n",
    "        # 检测结构性变化\n",
    "        for permno in self.memory_bank['permno'].unique():\n",
    "            stock_data = self.memory_bank[self.memory_bank['permno'] == permno]\n",
    "            \n",
    "            if detect_structural_change(stock_data):\n",
    "                # 记录结构性变化\n",
    "                self.structural_changes[permno] = current_date\n",
    "                \n",
    "                # 保留最近3个月数据，而不是全部删除\n",
    "                recent_data = stock_data[stock_data['date'] > (current_date - pd.DateOffset(months=3))]\n",
    "                self.memory_bank = self.memory_bank[~self.memory_bank['permno'].eq(permno) | \n",
    "                                                   self.memory_bank.index.isin(recent_data.index)]\n",
    "    \n",
    "    def _calculate_metrics(self):\n",
    "        \"\"\"计算模型评估指标\"\"\"\n",
    "        valid_predictions = self.predictions_df.dropna(subset=['pred_ret', 'actual_ret'])\n",
    "        \n",
    "        if not valid_predictions.empty:\n",
    "            y_true = valid_predictions['actual_ret']\n",
    "            y_pred = valid_predictions['pred_ret']\n",
    "            \n",
    "            self.eval_metrics['r2'] = r2_score(y_true, y_pred)\n",
    "            self.eval_metrics['mse'] = mean_squared_error(y_true, y_pred)\n",
    "            self.eval_metrics['count'] = len(valid_predictions)\n",
    "            \n",
    "            # 单独计算结构性变化股票的指标\n",
    "            if 'structural_change' in valid_predictions.columns:\n",
    "                sc_predictions = valid_predictions[valid_predictions['structural_change']]\n",
    "                if len(sc_predictions) > 0:\n",
    "                    self.eval_metrics['r2_sc'] = r2_score(sc_predictions['actual_ret'], sc_predictions['pred_ret'])\n",
    "                    self.eval_metrics['mse_sc'] = mean_squared_error(sc_predictions['actual_ret'], sc_predictions['pred_ret'])\n",
    "    \n",
    "    def get_predictions(self):\n",
    "        \"\"\"返回包含整个数据集的预测DataFrame\"\"\"\n",
    "        return self.predictions_df.sort_values(['date', 'permno'])\n",
    "    \n",
    "    def get_metrics(self):\n",
    "        \"\"\"返回模型评估指标\"\"\"\n",
    "        return self.eval_metrics\n",
    "    \n",
    "    def get_memory_stats(self):\n",
    "        \"\"\"获取记忆库统计信息\"\"\"\n",
    "        stats = {\n",
    "            'total_samples': len(self.memory_bank),\n",
    "            'quality_samples': len(self.memory_bank[self.memory_bank['memory_type'] == 'quality']),\n",
    "            'avg_age_months': (pd.Timestamp.now() - self.memory_bank['date']).dt.days.mean() / 30,\n",
    "            'permno_coverage': self.memory_bank['permno'].nunique(),\n",
    "            'structural_changes': len(self.structural_changes)\n",
    "        }\n",
    "        return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7fb7b02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda1\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理日期: 2016-10-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.046423\n",
      "Epoch 2/3, Loss: 0.042641\n",
      "Epoch 3/3, Loss: 0.038235\n",
      "处理日期: 2016-11-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.033301\n",
      "Epoch 2/3, Loss: 0.026525\n",
      "Epoch 3/3, Loss: 0.018250\n",
      "处理日期: 2016-12-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.020216\n",
      "Epoch 2/3, Loss: 0.017925\n",
      "Epoch 3/3, Loss: 0.017468\n",
      "处理日期: 2017-01-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.016742\n",
      "Epoch 2/3, Loss: 0.015013\n",
      "Epoch 3/3, Loss: 0.014806\n",
      "处理日期: 2017-02-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.014328\n",
      "Epoch 2/3, Loss: 0.013822\n",
      "Epoch 3/3, Loss: 0.014301\n",
      "处理日期: 2017-03-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.013107\n",
      "Epoch 2/3, Loss: 0.012406\n",
      "Epoch 3/3, Loss: 0.012015\n",
      "处理日期: 2017-04-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.010899\n",
      "Epoch 2/3, Loss: 0.011199\n",
      "Epoch 3/3, Loss: 0.010930\n",
      "处理日期: 2017-05-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.009839\n",
      "Epoch 2/3, Loss: 0.009549\n",
      "Epoch 3/3, Loss: 0.009605\n",
      "处理日期: 2017-06-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.009896\n",
      "Epoch 2/3, Loss: 0.010391\n",
      "Epoch 3/3, Loss: 0.010020\n",
      "处理日期: 2017-07-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.009406\n",
      "Epoch 2/3, Loss: 0.008957\n",
      "Epoch 3/3, Loss: 0.008851\n",
      "处理日期: 2017-08-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.008748\n",
      "Epoch 2/3, Loss: 0.008561\n",
      "Epoch 3/3, Loss: 0.008319\n",
      "处理日期: 2017-09-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.009717\n",
      "Epoch 2/3, Loss: 0.009375\n",
      "Epoch 3/3, Loss: 0.009239\n",
      "处理日期: 2017-10-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.010627\n",
      "Epoch 2/3, Loss: 0.010435\n",
      "Epoch 3/3, Loss: 0.010098\n",
      "处理日期: 2017-11-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.009997\n",
      "Epoch 2/3, Loss: 0.009745\n",
      "Epoch 3/3, Loss: 0.009452\n",
      "处理日期: 2017-12-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.009583\n",
      "Epoch 2/3, Loss: 0.009317\n",
      "Epoch 3/3, Loss: 0.009124\n",
      "处理日期: 2018-01-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.009246\n",
      "Epoch 2/3, Loss: 0.008923\n",
      "Epoch 3/3, Loss: 0.008753\n",
      "处理日期: 2018-02-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.008697\n",
      "Epoch 2/3, Loss: 0.008436\n",
      "Epoch 3/3, Loss: 0.008274\n",
      "处理日期: 2018-03-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.008569\n",
      "Epoch 2/3, Loss: 0.008389\n",
      "Epoch 3/3, Loss: 0.008176\n",
      "处理日期: 2018-04-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.008601\n",
      "Epoch 2/3, Loss: 0.008369\n",
      "Epoch 3/3, Loss: 0.008172\n",
      "处理日期: 2018-05-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.008383\n",
      "Epoch 2/3, Loss: 0.008157\n",
      "Epoch 3/3, Loss: 0.008001\n",
      "处理日期: 2018-06-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.008456\n",
      "Epoch 2/3, Loss: 0.008202\n",
      "Epoch 3/3, Loss: 0.008010\n",
      "处理日期: 2018-07-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.008501\n",
      "Epoch 2/3, Loss: 0.008250\n",
      "Epoch 3/3, Loss: 0.008089\n",
      "处理日期: 2018-08-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.008158\n",
      "Epoch 2/3, Loss: 0.007921\n",
      "Epoch 3/3, Loss: 0.007778\n",
      "处理日期: 2018-09-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.008145\n",
      "Epoch 2/3, Loss: 0.007784\n",
      "Epoch 3/3, Loss: 0.007605\n",
      "处理日期: 2018-10-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.008006\n",
      "Epoch 2/3, Loss: 0.007739\n",
      "Epoch 3/3, Loss: 0.007534\n",
      "处理日期: 2018-11-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.008638\n",
      "Epoch 2/3, Loss: 0.008273\n",
      "Epoch 3/3, Loss: 0.008031\n",
      "处理日期: 2018-12-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.008681\n",
      "Epoch 2/3, Loss: 0.008244\n",
      "Epoch 3/3, Loss: 0.008035\n",
      "处理日期: 2019-01-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.008903\n",
      "Epoch 2/3, Loss: 0.008584\n",
      "Epoch 3/3, Loss: 0.008360\n",
      "处理日期: 2019-02-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.010027\n",
      "Epoch 2/3, Loss: 0.009690\n",
      "Epoch 3/3, Loss: 0.009461\n",
      "处理日期: 2019-03-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.010406\n",
      "Epoch 2/3, Loss: 0.010057\n",
      "Epoch 3/3, Loss: 0.009850\n",
      "处理日期: 2019-04-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.009922\n",
      "Epoch 2/3, Loss: 0.009569\n",
      "Epoch 3/3, Loss: 0.009331\n",
      "处理日期: 2019-05-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.009416\n",
      "Epoch 2/3, Loss: 0.009039\n",
      "Epoch 3/3, Loss: 0.008839\n",
      "处理日期: 2019-06-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.009552\n",
      "Epoch 2/3, Loss: 0.009266\n",
      "Epoch 3/3, Loss: 0.009017\n",
      "处理日期: 2019-07-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.009807\n",
      "Epoch 2/3, Loss: 0.009472\n",
      "Epoch 3/3, Loss: 0.009305\n",
      "处理日期: 2019-08-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.009687\n",
      "Epoch 2/3, Loss: 0.009403\n",
      "Epoch 3/3, Loss: 0.009232\n",
      "处理日期: 2019-09-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.009419\n",
      "Epoch 2/3, Loss: 0.009145\n",
      "Epoch 3/3, Loss: 0.008921\n",
      "处理日期: 2019-10-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.009359\n",
      "Epoch 2/3, Loss: 0.009074\n",
      "Epoch 3/3, Loss: 0.008828\n",
      "处理日期: 2019-11-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.009259\n",
      "Epoch 2/3, Loss: 0.008991\n",
      "Epoch 3/3, Loss: 0.008840\n",
      "处理日期: 2019-12-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.009147\n",
      "Epoch 2/3, Loss: 0.008864\n",
      "Epoch 3/3, Loss: 0.008724\n",
      "处理日期: 2020-01-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.009098\n",
      "Epoch 2/3, Loss: 0.008831\n",
      "Epoch 3/3, Loss: 0.008705\n",
      "处理日期: 2020-02-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.009206\n",
      "Epoch 2/3, Loss: 0.008933\n",
      "Epoch 3/3, Loss: 0.008755\n",
      "处理日期: 2020-03-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.009678\n",
      "Epoch 2/3, Loss: 0.009391\n",
      "Epoch 3/3, Loss: 0.009167\n",
      "处理日期: 2020-04-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.011245\n",
      "Epoch 2/3, Loss: 0.010918\n",
      "Epoch 3/3, Loss: 0.010682\n",
      "处理日期: 2020-05-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.013713\n",
      "Epoch 2/3, Loss: 0.013292\n",
      "Epoch 3/3, Loss: 0.013020\n",
      "处理日期: 2020-06-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.014862\n",
      "Epoch 2/3, Loss: 0.014429\n",
      "Epoch 3/3, Loss: 0.014148\n",
      "处理日期: 2020-07-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.014260\n",
      "Epoch 2/3, Loss: 0.013754\n",
      "Epoch 3/3, Loss: 0.013476\n",
      "处理日期: 2020-08-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.013356\n",
      "Epoch 2/3, Loss: 0.013039\n",
      "Epoch 3/3, Loss: 0.012821\n",
      "处理日期: 2020-09-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.013210\n",
      "Epoch 2/3, Loss: 0.012828\n",
      "Epoch 3/3, Loss: 0.012548\n",
      "处理日期: 2020-10-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.013325\n",
      "Epoch 2/3, Loss: 0.012887\n",
      "Epoch 3/3, Loss: 0.012636\n",
      "处理日期: 2020-11-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.013313\n",
      "Epoch 2/3, Loss: 0.012832\n",
      "Epoch 3/3, Loss: 0.012606\n",
      "处理日期: 2020-12-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.014129\n",
      "Epoch 2/3, Loss: 0.013678\n",
      "Epoch 3/3, Loss: 0.013446\n",
      "处理日期: 2021-01-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.014863\n",
      "Epoch 2/3, Loss: 0.014382\n",
      "Epoch 3/3, Loss: 0.014159\n",
      "处理日期: 2021-02-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.015265\n",
      "Epoch 2/3, Loss: 0.014790\n",
      "Epoch 3/3, Loss: 0.014510\n",
      "处理日期: 2021-03-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.014937\n",
      "Epoch 2/3, Loss: 0.014478\n",
      "Epoch 3/3, Loss: 0.014176\n",
      "处理日期: 2021-04-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.014771\n",
      "Epoch 2/3, Loss: 0.014383\n",
      "Epoch 3/3, Loss: 0.014040\n",
      "处理日期: 2021-05-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.014108\n",
      "Epoch 2/3, Loss: 0.013725\n",
      "Epoch 3/3, Loss: 0.013465\n",
      "处理日期: 2021-06-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.013614\n",
      "Epoch 2/3, Loss: 0.013214\n",
      "Epoch 3/3, Loss: 0.012963\n",
      "处理日期: 2021-07-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.013470\n",
      "Epoch 2/3, Loss: 0.013135\n",
      "Epoch 3/3, Loss: 0.012954\n",
      "处理日期: 2021-08-01 00:00:00\n",
      "Epoch 1/3, Loss: 0.013458\n",
      "Epoch 2/3, Loss: 0.013063\n",
      "Epoch 3/3, Loss: 0.012968\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:115] data. DefaultCPUAllocator: not enough memory: you tried to allocate 3312164856 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 15\u001b[0m\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m NeuralStockForgettingModel(\n\u001b[0;32m     10\u001b[0m     input_size\u001b[38;5;241m=\u001b[39minput_size,\n\u001b[0;32m     11\u001b[0m     stock_mapping\u001b[38;5;241m=\u001b[39mstock_mapping\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# 训练并预测\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain_and_predict(edata)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# 获取完整预测结果\u001b[39;00m\n\u001b[0;32m     18\u001b[0m all_predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_predictions()\n",
      "Cell \u001b[1;32mIn[26], line 260\u001b[0m, in \u001b[0;36mNeuralStockForgettingModel.train_and_predict\u001b[1;34m(self, full_data, epochs)\u001b[0m\n\u001b[0;32m    257\u001b[0m         early_stopping_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# 对当前所有数据进行预测\u001b[39;00m\n\u001b[1;32m--> 260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_on_data(current_data, current_date, memory_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    262\u001b[0m \u001b[38;5;66;03m# 对当前月的数据单独预测（如果有）\u001b[39;00m\n\u001b[0;32m    263\u001b[0m current_month_data \u001b[38;5;241m=\u001b[39m full_data[full_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m current_date]\n",
      "Cell \u001b[1;32mIn[26], line 183\u001b[0m, in \u001b[0;36mNeuralStockForgettingModel._predict_on_data\u001b[1;34m(self, data, current_date, memory_type)\u001b[0m\n\u001b[0;32m    180\u001b[0m features_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(X)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m    181\u001b[0m stock_ids_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(stock_indices)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m--> 183\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(features_tensor, stock_ids_tensor)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(outputs)):\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;66;03m# 检查是否为结构性变化的股票\u001b[39;00m\n\u001b[0;32m    187\u001b[0m     is_structural_change \u001b[38;5;241m=\u001b[39m permnos[i] \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructural_changes\n",
      "File \u001b[1;32md:\\Anaconda1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[26], line 41\u001b[0m, in \u001b[0;36mEnhancedLSTMModel.forward\u001b[1;34m(self, x, stock_ids)\u001b[0m\n\u001b[0;32m     38\u001b[0m h0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, x_combined\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     39\u001b[0m c0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, x_combined\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m---> 41\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(x_combined, (h0, c0))\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# 只取最后一个时间步的输出\u001b[39;00m\n\u001b[0;32m     44\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n",
      "File \u001b[1;32md:\\Anaconda1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Anaconda1\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1124\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1121\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1124\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\n\u001b[0;32m   1125\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1126\u001b[0m         hx,\n\u001b[0;32m   1127\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[0;32m   1130\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout,\n\u001b[0;32m   1131\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining,\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first,\n\u001b[0;32m   1134\u001b[0m     )\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1136\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\n\u001b[0;32m   1137\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1138\u001b[0m         batch_sizes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[0;32m   1146\u001b[0m     )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:115] data. DefaultCPUAllocator: not enough memory: you tried to allocate 3312164856 bytes."
     ]
    }
   ],
   "source": [
    "# 创建股票ID到索引的映射\n",
    "unique_permnos = data['permno'].unique()\n",
    "stock_mapping = {permno: i for i, permno in enumerate(unique_permnos)}\n",
    "\n",
    "feature_columns = [col for col in data.columns if col not in \n",
    "                       ['gvkey', 'permno', 'ret', 'date', 'ffi49', 'exchcd', 'shrcd', 'year', 'month', 'monthly_stocks']]\n",
    "# 初始化模型\n",
    "input_size = len(feature_columns)\n",
    "model = NeuralStockForgettingModel(\n",
    "    input_size=input_size,\n",
    "    stock_mapping=stock_mapping\n",
    ")\n",
    "\n",
    "# 训练并预测\n",
    "model.train_and_predict(edata)\n",
    "\n",
    "# 获取完整预测结果\n",
    "all_predictions = model.get_predictions()\n",
    "\n",
    "# 导出到Excel\n",
    "all_predictions.to_excel('D:/股票项目:/memory_predictions.xlsx', index=False)\n",
    "\n",
    "# 获取评估指标\n",
    "metrics = model.get_metrics()\n",
    "print(f\"整体R² Score: {metrics['r2']:.4f}\")\n",
    "print(f\"结构性变化股票R² Score: {metrics.get('r2_sc', 'N/A')}\")\n",
    "print(f\"整体MSE: {metrics['mse']:.8f}\")\n",
    "print(f\"结构性变化股票MSE: {metrics.get('mse_sc', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f74d1a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
