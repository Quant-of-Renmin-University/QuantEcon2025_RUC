{"cells":[{"cell_type":"markdown","metadata":{"id":"B13E4D75D0164942A9E12F780EBBDBA3","trusted":true,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":true,"runtime":{"status":"default","execution_status":null,"is_visible":false},"scrolled":false,"notebookId":"67ed71ba5302e998c323a331"},"source":"## 欢迎进入 Notebook  \n\n这里你可以编写代码，文档  \n\n### 关于文件目录  \n\n\n**project**：project 目录是本项目的工作空间，可以把将项目运行有关的所有文件放在这里，目录中文件的增、删、改操作都会被保留  \n\n\n**input**：input 目录是数据集的挂载位置，所有挂载进项目的数据集都在这里，未挂载数据集时 input 目录被隐藏  \n\n\n**temp**：temp 目录是临时磁盘空间，训练或分析过程中产生的不必要文件可以存放在这里，目录中的文件不会保存  \n"},{"cell_type":"code","metadata":{"id":"FE33122FE65B492595BDC4B0367AA645","trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"scrolled":true,"notebookId":"67ed71ba5302e998c323a331"},"source":"# 查看个人持久化工作区文件\n!ls /home/mw/project/","outputs":[{"output_type":"stream","name":"stdout","text":"processed_file.csv  submission.csv\r\n"}],"execution_count":1},{"cell_type":"code","metadata":{"id":"09B9DE6CC2DD4E49AE5DB5CA4EBA6F0B","trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"scrolled":false,"notebookId":"67ed71ba5302e998c323a331"},"source":"# 查看当前挂载的数据集目录\n!ls /home/mw/input/","outputs":[{"output_type":"stream","name":"stdout","text":"quant4533\r\n"}],"execution_count":2},{"cell_type":"code","metadata":{"id":"E9D970E03F704B7886DC7A80623F6C83","notebookId":"67ed71ba5302e998c323a331","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nimport re\nimport warnings\n\nwarnings.filterwarnings('ignore')","outputs":[],"execution_count":3},{"cell_type":"code","metadata":{"id":"EFC9097C2F514D15A6C4FFFDAA296FA2","notebookId":"67ed71ba5302e998c323a331","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 数据加载\ntrain_data = pd.read_csv('/home/mw/input/quant4533/ruc_Class25Q1_train.csv')\ntest_data = pd.read_csv('/home/mw/input/quant4533/ruc_Class25Q1_test.csv')\ndetail_data = pd.read_csv('/home/mw/input/quant4533/ruc_Class25Q1_details.csv')","outputs":[],"execution_count":4},{"cell_type":"code","metadata":{"id":"5482405943874C41979BB277AB16B669","notebookId":"67ed71ba5302e998c323a331","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"detail_data = detail_data[['名称', '城市', '板块', '建筑年代', '房屋总数', '楼栋总数', \n                          '物业公司', '供水', '供暖', '供电', '停车位']]\n\n# 1. Process 建筑年代: take first 4 characters and convert to numeric\ndetail_data['建筑年代'] = detail_data['建筑年代'].str[:4].astype(float)\n\n# 2. Process 房屋总数 and 楼栋总数: remove last character and convert to numeric\nfor col in ['房屋总数', '楼栋总数']:\n    detail_data[col] = detail_data[col].str[:-1].astype(float)\n\n# Calculate 房屋总数/楼栋总数\ndetail_data['房屋楼栋比'] = detail_data['房屋总数'] / detail_data['楼栋总数']\n\n# 3. Process 物业公司: convert to binary (0 for \"无物业管理服务\" or missing, 1 otherwise)\ndetail_data['物业公司'] = np.where(\n    (detail_data['物业公司'] == \"无物业管理服务\") | detail_data['物业公司'].isna(),\n    0,\n    1\n)\n\n# 4. Process 供水: convert to numeric values\ndetail_data['供水'] = detail_data['供水'].map({\n    '民水': 0,\n    '商水': 1,\n    '商水/民水': 0.5\n})\n\n# 5. Process 供电: convert to numeric values\ndetail_data['供电'] = detail_data['供电'].map({\n    '民电': 0,\n    '商电': 1,\n    '商电/民电': 0.5\n})\n\n# 6. Process 供暖: 0 if contains \"无供暖\", 1 otherwise\ndetail_data['供暖'] = np.where(\n    detail_data['供暖'].str.contains('无供暖', na=False),\n    0,\n    1\n)\n\n# 7. Process 停车位: fill missing values with mean\nif detail_data['停车位'].isna().any():\n    detail_data['停车位'] = detail_data['停车位'].fillna(detail_data['停车位'].mean())\n\n# Finally, fill any remaining missing values with column means\nfor col in detail_data.columns:\n    if detail_data[col].isna().any():\n        if detail_data[col].dtype.kind in 'biufc':  # numeric types\n            detail_data[col] = detail_data[col].fillna(detail_data[col].mean())\n        else:\n            # For non-numeric columns, you might want to use mode or other imputation\n            detail_data[col] = detail_data[col].fillna(detail_data[col].mode()[0])","outputs":[],"execution_count":5},{"cell_type":"code","metadata":{"id":"F68490E9E84942EEA41A30E3681786F7","notebookId":"67ed71ba5302e998c323a331","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"detail_data.head()","outputs":[{"output_type":"execute_result","data":{"text/plain":"         名称  城市     板块         建筑年代   房屋总数  楼栋总数  物业公司        供水  供暖  \\\n0  三峡医专学苑新村   2    9.0  1999.450549  458.0  15.0     0  0.098352   1   \n1       宁静苑   2    9.0  1999.450549   80.0   4.0     0  0.098352   1   \n2      电信小区   2    9.0  1999.450549  102.0   3.0     0  0.098352   1   \n3  三元街甲19号院   0  470.0  1970.000000  103.0   3.0     1  0.000000   1   \n4  东交民巷11号院   0  126.0  1975.000000  222.0   4.0     1  0.000000   1   \n\n         供电         停车位      房屋楼栋比  \n0  0.101024  556.867636  30.533333  \n1  0.101024  556.867636  20.000000  \n2  0.101024  556.867636  34.000000  \n3  0.000000   36.000000  34.333333  \n4  0.000000  556.867636  55.500000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>名称</th>\n      <th>城市</th>\n      <th>板块</th>\n      <th>建筑年代</th>\n      <th>房屋总数</th>\n      <th>楼栋总数</th>\n      <th>物业公司</th>\n      <th>供水</th>\n      <th>供暖</th>\n      <th>供电</th>\n      <th>停车位</th>\n      <th>房屋楼栋比</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>三峡医专学苑新村</td>\n      <td>2</td>\n      <td>9.0</td>\n      <td>1999.450549</td>\n      <td>458.0</td>\n      <td>15.0</td>\n      <td>0</td>\n      <td>0.098352</td>\n      <td>1</td>\n      <td>0.101024</td>\n      <td>556.867636</td>\n      <td>30.533333</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>宁静苑</td>\n      <td>2</td>\n      <td>9.0</td>\n      <td>1999.450549</td>\n      <td>80.0</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>0.098352</td>\n      <td>1</td>\n      <td>0.101024</td>\n      <td>556.867636</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>电信小区</td>\n      <td>2</td>\n      <td>9.0</td>\n      <td>1999.450549</td>\n      <td>102.0</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>0.098352</td>\n      <td>1</td>\n      <td>0.101024</td>\n      <td>556.867636</td>\n      <td>34.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>三元街甲19号院</td>\n      <td>0</td>\n      <td>470.0</td>\n      <td>1970.000000</td>\n      <td>103.0</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>36.000000</td>\n      <td>34.333333</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>东交民巷11号院</td>\n      <td>0</td>\n      <td>126.0</td>\n      <td>1975.000000</td>\n      <td>222.0</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>556.867636</td>\n      <td>55.500000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":6}],"execution_count":6},{"cell_type":"code","metadata":{"id":"AF29678AF6A4445EBDB4C98A570519B9","notebookId":"67ed71ba5302e998c323a331","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"def clean_data(df):\n    # 面积相关字段清洗\n    def clean_area(area):\n        if pd.isna(area):\n            return np.nan\n        # 处理字符串类型的面积（带单位）\n        if isinstance(area, str):\n            # 去除所有非数字字符（保留小数点）\n            cleaned = re.sub(r'[^\\d.]', '', area)\n            try:\n                return float(cleaned)\n            except:\n                return np.nan\n        return float(area)\n    \n    # 处理所有面积相关字段\n    area_columns = ['建筑面积', '套内面积']\n    for col in area_columns:\n        if col in df.columns:\n            df[col] = df[col].apply(clean_area)\n        # 填充中位数前先检查是否有有效值（仅对建筑面积填充）\n            if col == '建筑面积' and not df[col].isna().all():\n                median_val = df[col].median()\n                df[col].fillna(median_val, inplace=True)\n    \n    # 房屋户型解析\n    if '房屋户型' in df.columns:\n        def parse_house_type(house_type):\n            if not isinstance(house_type, str):\n                return None, None, None, None\n            \n            # 正则表达式匹配两种格式：X室Y厅Z厨W卫 和 X房间Y卫\n            match = re.match(r'(\\d+)室(\\d+)厅?(\\d*)厨?(\\d+)卫|(\\d+)房间(\\d+)卫', str(house_type))\n            \n            if match:\n                # 匹配到第一种格式：X室Y厅Z厨W卫\n                if match.group(1) is not None:\n                    bedrooms = int(match.group(1))\n                    living_rooms = int(match.group(2)) if match.group(2) else 0\n                    kitchens = int(match.group(3)) if match.group(3) else 0\n                    bathrooms = int(match.group(4))\n                    return bedrooms, living_rooms, kitchens, bathrooms\n                # 匹配到第二种格式：X房间Y卫\n                else:\n                    bedrooms = int(match.group(5))\n                    bathrooms = int(match.group(6))\n                    living_rooms = 1\n                    kitchens = 1\n                    return bedrooms, living_rooms, kitchens, bathrooms\n            return None, None, None, None\n\n        new_columns = ['卧室数量', '客厅数量', '厨房数量', '卫生间数量']\n        df[new_columns] = df['房屋户型'].apply(lambda x: pd.Series(parse_house_type(x)))\n\n        for col in new_columns:\n            if col in df.columns:\n                df[col].fillna(0, inplace=True)\n\n    # 楼层信息提取\n    if '所在楼层' in df.columns:\n        def extract_floor_info(floor):\n            if not isinstance(floor, str):\n                return None, None\n            # 使用正则表达式提取楼层信息\n            match = re.match(r'(.*?)\\s*\\(共(\\d+)层\\)', floor)\n            if match:\n                floor_level = match.group(1).strip()  # 楼层高低程度\n                total_floors = int(match.group(2))  # 总层数，转换为整数\n                return floor_level, total_floors\n            return None, None\n\n        df[['楼层高低程度', '总层数']] = df['所在楼层'].apply(lambda x: pd.Series(extract_floor_info(x)))\n\n        floor_level_mapping = {\n            '低楼层': 1,\n            '中楼层': 2,\n            '高楼层': 3,\n            '底层': 0,\n            '顶层': 4\n        }\n\n        df['楼层高低程度'] = df['楼层高低程度'].map(floor_level_mapping)\n\n        df['楼层高低程度'] = df['楼层高低程度'].fillna(2).astype(int)\n\n        df['总层数'] = pd.to_numeric(df['总层数'], errors='coerce')  # 确保数据是数值型\n        df['总层数'] = df['总层数'].fillna(df['总层数'].median()).astype(int)\n\n    df['环线'] = df['环线'].astype(str).str.replace(r'[\\s　\\u200b]+', '', regex=True).str.strip()\n    ring_mapping = {\n        '一环内': 1, '二环内': 2, '二至三环': 2.5,\n        '三环外': 3, '三至四环': 3.5, \n        '四环外': 4, '四至五环': 4.5,\n        '五环': 5, '五至六环': 5.5,\n        '六环外': 6, '内环内': 1, '外环外': 7,\n        '内环至外环': 2, '内环至中环': 4, '中环至外环': 6,\n        '一至二环': 1.5  # 补充缺失项\n    }\n    df['环线_调整'] = df['环线'].map(ring_mapping)\n    df['环线_调整'] = df['环线_调整'].fillna(df['环线_调整'].median())\n\n    if '城市' in df.columns:\n        for city_code in range(7):  # 假设城市编码是0-6\n            df[f'城市_{city_code}'] = (df['城市'] == city_code).astype(int)\n\n    # 交通出行特征提取\n    if '交通出行' in df.columns:\n        transport_keywords = ['公交', '地铁']\n        df['交通出行'] = df['交通出行'].fillna('').str.strip().str.replace('　', '') \n        \n        for keyword in transport_keywords:\n            df[f'交通_{keyword}'] = df['交通出行'].str.contains(keyword, case=False, na=False).astype(int)\n\n    # 周边配套特征提取\n    if '周边配套' in df.columns:\n        facilities = ['医院', '公园', '超市', '商场', '银行', '幼儿园', '学校']\n        df['周边配套'] = df['周边配套'].fillna('').str.strip().str.replace('　', '')\n\n        for facility in facilities:\n            df[f'配套_{facility}'] = df['周边配套'].str.contains(facility, case=False, na=False).astype(int)\n\n    # 房屋朝向特征提取\n    if '房屋朝向' in df.columns:\n        directions = ['东', '南', '西', '北']\n        df['房屋朝向'] = df['房屋朝向'].fillna('').str.strip().str.replace('　', '')\n\n        for direction in directions:\n            df[f'朝向_{direction}'] = df['房屋朝向'].str.contains(direction, case=False, na=False).astype(int)\n\n    # 建筑面积优化\n    if '套内面积' in df.columns and '建筑面积' in df.columns:\n        # 当\"套内面积\"不是缺失值时，取\"套内面积\"；否则保留\"建筑面积\"\n        df['使用面积'] = np.where(\n            df['套内面积'].notna(),\n            df['套内面积'],\n            df['建筑面积']\n        )\n    \n    # 建筑结构量化\n    if '建筑结构' in df.columns:\n        structure_rank = {\n            '钢结构': 6,        # 强度最高\n            '框架结构': 5,      # 抗震性强\n            '钢混结构': 4,      # 如框架-剪力墙结构\n            '混合结构': 3,      # 介于钢混和砖混之间\n            '砖混结构': 2,      # 低层建筑常见\n            '砖木结构': 1,      # 强度最弱\n            '未知结构': np.nan,\n            None: np.nan\n        }\n        \n        df['建筑结构'] = df['建筑结构'].map(structure_rank)\n        mean_rank = df['建筑结构'].mean()\n        df['建筑结构'] = df['建筑结构'].fillna(mean_rank)\n\n    if '装修情况' in df.columns:\n        # 定义映射规则\n        decoration_rank = {\n            '精装': 4,    # 最高精度装修\n            '简装': 3,    # 中等精度装修\n            '毛坯': 1,    # 最低精度\n            '其他': np.nan,\n            None: np.nan\n        }\n        \n        df['装修情况_调整'] = df['装修情况'].map(decoration_rank)\n        mean_decoration = df['装修情况_调整'].mean()\n        df['装修情况_调整'] = df['装修情况_调整'].fillna(mean_decoration)  \n\n    if '房屋年限' in df.columns:\n        year_rank = {\n            '满五年': 5,  \n            '满两年': 2,    \n            '未满两年': 0\n        }\n        df['房屋年限'] = df['房屋年限'].map(year_rank)\n        df['房屋年限'] = df['房屋年限'].fillna(1)\n\n    if '别墅类型' in df.columns:\n        df['别墅类型标志'] = np.where(\n            df['别墅类型'].isna(),  # 判断条件\n            0,                     # 空值赋值为0\n            1                      # 非空赋值为1\n        )\n\n    # 对经纬度进行标准化\n    if all(col in df.columns for col in ['lon', 'lat']):\n        # 创建副本避免SettingWithCopyWarning\n        coords = df[['lon', 'lat']].copy()\n        \n        # 检查是否有有效值\n        if not coords.isnull().all().all():\n            scaler = StandardScaler()  # 初始化标准化器\n            scaled_coords = scaler.fit_transform(coords)\n            # 更新到DataFrame\n            df['lon'] = scaled_coords[:, 0]\n            df['lat'] = scaled_coords[:, 1]    \n\n    if '配备电梯' in df.columns:\n        ladder_rank = {\n            '有': 1,\n            '无': 0,\n            None: np.nan,\n        }\n        df['配备电梯'] = df['配备电梯'].str.strip().str.replace(' ', '')\n        df['配备电梯_d'] = df['配备电梯'].map(ladder_rank)\n    mean_rank = df['配备电梯_d'].mean()\n    df['配备电梯_d'] = df['配备电梯_d'].fillna(mean_rank)\n    \n\n    def parse_ladder_ratio(ratio_str, has_elevator):\n        # 中文数字到阿拉伯数字的映射\n        chinese_num_map = {\n            '零':0, '一':1, '二':2, '两':2, '三':3, '四':4,\n            '五':5, '六':6, '七':7, '八':8, '九':9, '十':10\n        }\n        # 如果输入为空，直接返回0\n        if pd.isna(ratio_str):\n            return 0.0\n        try:\n            # 使用正则表达式提取梯数和户数\n            match = re.search(r'([零一二两三四五六七八九十]+)梯([零一二两三四五六七八九十]+)户', str(ratio_str))\n            if not match:\n                return 0.0 \n            # 转换中文数字\n            def cn_to_num(cn):\n                cn = str(cn)\n                if cn in chinese_num_map:\n                    return chinese_num_map[cn]\n                if len(cn) == 2 and cn[0] == '十':  # 如\"十一\"\n                    return 10 + chinese_num_map.get(cn[1], 0)\n                if len(cn) == 2 and cn[1] == '十':  # 如\"二十\"\n                    return chinese_num_map.get(cn[0], 0) * 10\n                return None\n                \n            ladder = cn_to_num(match.group(1))\n\n            household = cn_to_num(match.group(2))\n            \n            # 计算比例（确保分母不为零）\n            if ladder is not None and household is not None and household != 0:\n                return round(ladder / household, 2)\n            return 0.0\n        except:\n            return 0.0\n\n    df['梯户比例'] = df['梯户比例'].apply(lambda x: parse_ladder_ratio(x, None))\n\n    if '建筑面积' in df.columns:\n        df['建筑面积平方'] = df['建筑面积'] ** 2\n       \n    # 建筑面积 × 卧室数量（衡量空间舒适度）\n    if all(col in df.columns for col in ['建筑面积','卧室数量']):\n        df['面积_卧室比'] = df['建筑面积'] / (df['卧室数量'] + 1e-6)  # 防止除零\n        \n    # 交通 × 商业配套（地铁房+商圈的复合价值）\n    if all(col in df.columns for col in ['交通_地铁','配套_商场']):\n        df['地铁_商圈交互'] = df['交通_地铁'] * df['配套_商场']\n        \n    # 朝向组合（南北通透的溢价）\n    if all(col in df.columns for col in ['朝向_南','朝向_北']):\n        df['南北通透'] = df['朝向_南'] * df['朝向_北']\n      \n    return df","outputs":[],"execution_count":7},{"cell_type":"code","metadata":{"id":"030F3EF695E248E08B97EE439A47DEF1","notebookId":"67ed71ba5302e998c323a331","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 应用清洗函数\ntrain_data = clean_data(train_data)\ntest_data = clean_data(test_data)","outputs":[],"execution_count":8},{"cell_type":"code","metadata":{"id":"7738C008A1964BE09CFBC40293AE417E","notebookId":"67ed71ba5302e998c323a331","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 合并训练数据与rent数据\ntrain_merged = pd.merge(train_data, detail_data, \n                 left_on=['城市', '板块', '小区名称'],\n                 right_on=['城市', '板块', '名称'],\n                 how='left')\n\ntrain_cleaned = train_merged[['价格',\n    '城市_0','城市_1','城市_2','城市_3','城市_4','城市_5','建筑面积','卧室数量','卫生间数量','楼层高低程度','总层数','环线_调整', 'lon','lat',\n    '交通_公交', '交通_地铁','配套_医院','配套_公园','配套_超市','配套_商场','朝向_东','朝向_南','朝向_西','朝向_北',\n    '装修情况_调整', '房屋年限', '别墅类型标志','配备电梯_d', '梯户比例','建筑面积平方', '建筑年代','停车位','房屋楼栋比',\n    '面积_卧室比','地铁_商圈交互','南北通透'\n]]\n\n# 合并测试数据与rent数据\ntest_merged = pd.merge(test_data, detail_data, \n                 left_on=['城市', '板块', '小区名称'],\n                 right_on=['城市', '板块', '名称'],\n                 how='left')\n\ntest_cleaned = test_merged[[\n    '城市_0','城市_1','城市_2','城市_3','城市_4','城市_5','建筑面积','卧室数量','卫生间数量','楼层高低程度','总层数','环线_调整', 'lon','lat',\n    '交通_公交', '交通_地铁','配套_医院','配套_公园','配套_超市','配套_商场','朝向_东','朝向_南','朝向_西','朝向_北',\n    '装修情况_调整', '房屋年限', '别墅类型标志','配备电梯_d', '梯户比例','建筑面积平方', '建筑年代','停车位','房屋楼栋比',\n    '面积_卧室比','地铁_商圈交互','南北通透'\n]]","outputs":[],"execution_count":9},{"cell_type":"code","metadata":{"id":"44551504E93A44B2A96B4073C531E2FF","notebookId":"67ed71ba5302e998c323a331","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"print(train_cleaned.columns)","outputs":[{"output_type":"stream","name":"stdout","text":"Index(['价格', '城市_0', '城市_1', '城市_2', '城市_3', '城市_4', '城市_5', '建筑面积', '卧室数量',\n       '卫生间数量', '楼层高低程度', '总层数', '环线_调整', 'lon', 'lat', '交通_公交', '交通_地铁',\n       '配套_医院', '配套_公园', '配套_超市', '配套_商场', '朝向_东', '朝向_南', '朝向_西', '朝向_北',\n       '装修情况_调整', '房屋年限', '别墅类型标志', '配备电梯_d', '梯户比例', '建筑面积平方', '建筑年代', '停车位',\n       '房屋楼栋比', '面积_卧室比', '地铁_商圈交互', '南北通透', '楼层占比'],\n      dtype='object')\n"}],"execution_count":10},{"cell_type":"code","metadata":{"id":"B69B617C2558434CB558F9F3FBDB7117","notebookId":"67ed71ba5302e998c323a331","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 选择特征和目标变量\nfeatures = ['城市_0','城市_1','城市_2','城市_3','城市_4','城市_5','建筑面积','建筑面积平方','卧室数量','卫生间数量','环线_调整', 'lon','lat','楼层高低程度','总层数',\n    '交通_公交', '交通_地铁','配套_医院','配套_公园','配套_超市','配套_商场','朝向_东','朝向_南','朝向_西','朝向_北','建筑年代',\n    '装修情况_调整', '房屋年限', '配备电梯_d', '梯户比例', '停车位','房屋楼栋比','别墅类型标志',#'面积_卧室比','地铁_商圈交互','南北通透'\n]\ntarget = '价格'","outputs":[],"execution_count":11},{"cell_type":"code","metadata":{"id":"B8581534A1724E7396DA6E7C2FE5D825","notebookId":"67ed71ba5302e998c323a331","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"X = train_cleaned[features]\ny = train_cleaned['价格']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=111)\n\nnumeric_features = X.columns.tolist()  \n\npreprocessor = Pipeline([\n    ('imputer', SimpleImputer(strategy='mean')), \n    ('scaler', StandardScaler()),  \n])\n\n# 预处理数据\nX_train_processed = preprocessor.fit_transform(X_train)\nX_test_processed = preprocessor.transform(X_test)","outputs":[],"execution_count":12},{"cell_type":"code","metadata":{"id":"782260FF677C41DBA5CB20AE916B1288","notebookId":"67ed71ba5302e998c323a331","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 1. 定义模型\nmodels = {\n    'OLS': LinearRegression(),          # 普通最小二乘回归\n    'LASSO': Lasso(alpha=0.1),          # L1正则化回归\n    'Ridge': Ridge(alpha=1.0),          # L2正则化回归\n    'ElasticNet': ElasticNet(alpha=0.8, l1_ratio=0.8)  # L1+L2正则化\n}\n\n# 2. 评估函数\ndef evaluate_model(model, X_train, X_test, y_train, y_test):\n    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n    pipeline.fit(X_train, y_train)  \n\n    y_train_pred = pipeline.predict(X_train)  \n    y_test_pred = pipeline.predict(X_test)\n    \n    # 计算指标\n    train_mae = mean_absolute_error(y_train, y_train_pred)\n    test_mae = mean_absolute_error(y_test, y_test_pred)\n    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n    \n    # 交叉验证\n    cv = KFold(n_splits=6, shuffle=True, random_state=111)\n    cv_scores_mae = -cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='neg_mean_absolute_error')\n    cv_scores_rmse = -cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='neg_root_mean_squared_error')\n    \n    return {\n        'train_mae': float(train_mae), \n        'test_mae': float(test_mae),\n        'train_rmse': float(train_rmse), \n        'test_rmse': float(test_rmse),\n        'cv_mae': float(np.mean(cv_scores_mae)), \n        'cv_rmse': float(np.mean(cv_scores_rmse)),\n        'pipeline': pipeline\n    }\n\n# 3. 训练并比较所有模型\nresults = {}\nbest_model = None\nbest_score = float('inf')\n\nfor name, model in models.items():\n    print(f\"Evaluating {name}...\")\n    result = evaluate_model(model, X_train, X_test, y_train, y_test)\n    results[name] = dict(result) \n    if result['test_rmse'] < best_score:\n        best_score = result['test_rmse']\n        best_model = name\n\nprint(f\"\\nBest model: {best_model} with test RMSE: {best_score:.2f}\")","outputs":[{"output_type":"stream","name":"stdout","text":"Evaluating OLS...\nEvaluating LASSO...\n"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_549/2558797860.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Evaluating {name}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 确保 result 是字典\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_549/2558797860.py\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m111\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mcv_scores_mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_absolute_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mcv_scores_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_root_mean_squared_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     return {\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m     )\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         )\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1057\u001b[0m                 \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m                 \u001b[0mselection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m                 \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m             )\n\u001b[1;32m   1061\u001b[0m             \u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthis_coef\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py\u001b[0m in \u001b[0;36menet_path\u001b[0;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mprecompute\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m             model = cd_fast.enet_coordinate_descent(\n\u001b[0;32m--> 648\u001b[0;31m                 \u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m             )\n\u001b[1;32m    650\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32msklearn/linear_model/_cd_fast.pyx\u001b[0m in \u001b[0;36msklearn.linear_model._cd_fast.enet_coordinate_descent\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/core/getlimits.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0m_finfo_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumeric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"execution_count":13},{"cell_type":"code","metadata":{"id":"66377F9479044603AE2FD0CD6845F064","notebookId":"67ed71ba5302e998c323a331","jupyter":{},"collapsed":false,"scrolled":true,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"hide_input":false},"source":"from sklearn.model_selection import GridSearchCV\n\n# 1. 定义参数网格（注意添加model__前缀）\nparam_grid = {\n    'model__alpha': [0.01,0.1,0.5,1],  # 正则化强度\n    'model__l1_ratio': [0.6, 0.7,0.8]       # L1/L2比例\n}\n\n# 2. 创建预处理+模型的pipeline（保持不变）\nelastic_pipe = Pipeline([\n    ('preprocessor', preprocessor),\n    ('model', ElasticNet(max_iter=10000))\n])\n\n# 3. 网格搜索（使用6折交叉验证）\nelastic_gs = GridSearchCV(elastic_pipe, \n                        param_grid,\n                        cv=6,\n                        scoring='neg_root_mean_squared_error',\n                        n_jobs=-1,\n                        verbose=1)\nprint(\"开始网格搜索...\")\nelastic_gs.fit(X_train, y_train)\n\n# 4. 输出最佳参数\nprint(\"\\n最佳参数组合: \", elastic_gs.best_params_)\nprint(\"最佳RMSE: \", -elastic_gs.best_score_)\n\n# ========== 参数搜索可视化 ==========\n# 5. 提取网格搜索结果并调整列名（去掉model__前缀）\nresults = pd.DataFrame(elastic_gs.cv_results_)\nresults = results.rename(columns={\n    'param_model__alpha': 'alpha',\n    'param_model__l1_ratio': 'l1_ratio'\n})\n\n# ========== 特征重要性分析 ==========\n# 获取最佳模型\nbest_elastic = elastic_gs.best_estimator_\n\n# 提取特征重要性\nfeature_importance = pd.DataFrame({\n    'feature': numeric_features,\n    'coefficient': best_elastic.named_steps['model'].coef_,\n    'abs_coef': np.abs(best_elastic.named_steps['model'].coef_)\n}).sort_values('abs_coef', ascending=False)\n\n# 输出系数表格\nprint(\"\\n特征重要性排序：\")\nprint(feature_importance.head(15))","outputs":[],"execution_count":21},{"cell_type":"code","metadata":{"id":"565EB828706E43EE86B1B82B4072C5D7","notebookId":"67ed71ba5302e998c323a331","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"metrics_df = pd.DataFrame({\n    'Model': list(results.keys()),\n    'In sample MAE': [float(res['train_mae']) for res in results.values()],\n    'Out of sample MAE': [float(res['test_mae']) for res in results.values()],\n    'CV MAE': [float(res['cv_mae']) for res in results.values()],\n    'In sample RMSE': [float(res['train_rmse']) for res in results.values()],\n    'Out of sample RMSE': [float(res['test_rmse']) for res in results.values()],\n    'CV RMSE': [float(res['cv_rmse']) for res in results.values()]\n})\n\nprint(\"\\nPerformance Metrics:\")\nprint(metrics_df)","outputs":[],"execution_count":23},{"cell_type":"code","metadata":{"id":"209A055D2ECA44F78C794FAE3849F524","notebookId":"67ed71ba5302e998c323a331","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"best_pipeline = results[best_model]['pipeline']\nbest_pipeline.fit(X, y)  # 在整个训练集上重新训练\n\n# 准备测试数据\nX_final_test = test_cleaned[features]\n\n# 预测\npredictions = best_pipeline.predict(X_final_test)","outputs":[],"execution_count":108},{"cell_type":"code","metadata":{"id":"BF03CEF5191C4D9E828B0EE9AFC21643","notebookId":"67ed71ba5302e998c323a331","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"submission = pd.DataFrame({\n    'ID': range(len(predictions)),  # 从0开始生成连续的ID\n    'price': predictions\n})\n\nsubmission.to_csv('submission.csv', index=False)\nprint(\"\\nSubmission file created: submission.csv\")","outputs":[],"execution_count":109},{"cell_type":"markdown","metadata":{"id":"50B394435A3C4E11AD328C4797F2BA98","notebookId":"67ed71ba5302e998c323a331","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":""}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":0}