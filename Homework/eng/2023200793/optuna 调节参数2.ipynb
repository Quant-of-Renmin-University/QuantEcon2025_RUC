{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d67530c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold,train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f609c31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据\n",
    "data_train=pd.read_csv(\"/Users/macbookair/Documents/python 2/data.csv\")\n",
    "data_train_price=data_train[\"价格\"]\n",
    "data_train=data_train.drop(columns=[\"Unnamed: 0\",\"价格\",\"text\"])\n",
    "X=data_train\n",
    "y=data_train_price\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f8c962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sampled, _, y_sampled, _ = train_test_split(X, y, random_state=42, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d617b263",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "120it [1:35:40, 47.84s/it]                               | 0/50 [00:00<?, ?it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "# 总试验次数\n",
    "N_TRIALS = 50\n",
    "progress_bar = tqdm(total=N_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "709dd240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义每个模型的调参目标函数\n",
    "def create_objective(model_name):\n",
    "    def objective(trial):\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        rmse_scores = []\n",
    "\n",
    "        for train_idx, val_idx in kf.split(X_sampled):\n",
    "            X_train, X_val = X_sampled.iloc[train_idx], X_sampled.iloc[val_idx]\n",
    "            y_train, y_val = y_sampled.iloc[train_idx], y_sampled.iloc[val_idx]\n",
    "\n",
    "            if model_name == 'xgb':\n",
    "                params = {\n",
    "                    'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "                    'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "                    'n_estimators': trial.suggest_int('n_estimators', 100, 1000)\n",
    "                }\n",
    "                model = XGBRegressor(**params, verbosity=0)\n",
    "            elif model_name == 'lgb':\n",
    "                params = {\n",
    "                    'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "                    'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "                    'n_estimators': trial.suggest_int('n_estimators', 100, 1000)\n",
    "                }\n",
    "                model = LGBMRegressor(**params)\n",
    "            elif model_name == 'cat':\n",
    "                params = {\n",
    "                    'depth': trial.suggest_int('depth', 3, 10),\n",
    "                    'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "                    'iterations': trial.suggest_int('iterations', 100, 1000)\n",
    "                }\n",
    "                model = CatBoostRegressor(**params, verbose=0)\n",
    "            elif model_name == 'rf':\n",
    "                params = {\n",
    "                    'max_depth': trial.suggest_int('max_depth', 5, 20),\n",
    "                    'n_estimators': trial.suggest_int('n_estimators', 100, 1000)\n",
    "                }\n",
    "                model = RandomForestRegressor(**params)\n",
    "            else:\n",
    "                raise ValueError(\"Unknown model\")\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "            preds = model.predict(X_val)\n",
    "            rmse = mean_squared_error(y_val, preds, squared=False)\n",
    "            rmse_scores.append(rmse)\n",
    "\n",
    "        return np.mean(rmse_scores)\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46d8b9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback(study, trial):\n",
    "    progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4785926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个函数批量调参\n",
    "def tune_all_models():\n",
    "    models = ['xgb', 'lgb', 'cat', 'rf']\n",
    "    best_params = {}\n",
    "\n",
    "    for model_name in tqdm(models, desc=\"Tuning models\"):\n",
    "        study = optuna.create_study(direction='minimize')\n",
    "        study.optimize(create_objective(model_name), n_trials=30,callbacks=[callback])\n",
    "        best_params[model_name] = study.best_params\n",
    "\n",
    "    return best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b31b385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f125b9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tuning models:   0%|                                      | 0/4 [00:00<?, ?it/s][I 2025-06-04 00:51:31,544] A new study created in memory with name: no-name-1f92eaf7-0471-4ad7-a478-76d2e8296cce\n",
      "[I 2025-06-04 00:51:44,981] Trial 0 finished with value: 751375.3734359893 and parameters: {'max_depth': 6, 'learning_rate': 0.2872039039390133, 'n_estimators': 535}. Best is trial 0 with value: 751375.3734359893.\n",
      "\n",
      "  2%|▉                                           | 1/50 [00:18<15:12, 18.61s/it]\u001b[A[I 2025-06-04 00:52:11,856] Trial 1 finished with value: 750305.1649093869 and parameters: {'max_depth': 8, 'learning_rate': 0.09541100974833464, 'n_estimators': 770}. Best is trial 1 with value: 750305.1649093869.\n",
      "\n",
      "  4%|█▊                                          | 2/50 [00:45<18:46, 23.47s/it]\u001b[A[I 2025-06-04 00:52:18,879] Trial 2 finished with value: 781796.7353751882 and parameters: {'max_depth': 8, 'learning_rate': 0.20868223113430293, 'n_estimators': 143}. Best is trial 1 with value: 750305.1649093869.\n",
      "\n",
      "  6%|██▋                                         | 3/50 [00:52<12:30, 15.96s/it]\u001b[A[I 2025-06-04 00:52:46,076] Trial 3 finished with value: 766794.1921003544 and parameters: {'max_depth': 9, 'learning_rate': 0.20605602213575275, 'n_estimators': 476}. Best is trial 1 with value: 750305.1649093869.\n",
      "\n",
      "  8%|███▌                                        | 4/50 [01:19<15:38, 20.40s/it]\u001b[A[I 2025-06-04 00:53:39,327] Trial 4 finished with value: 785920.9935723252 and parameters: {'max_depth': 10, 'learning_rate': 0.27732153987091446, 'n_estimators': 741}. Best is trial 1 with value: 750305.1649093869.\n",
      "\n",
      " 10%|████▍                                       | 5/50 [02:12<24:11, 32.25s/it]\u001b[A[I 2025-06-04 00:53:44,254] Trial 5 finished with value: 853954.5517749276 and parameters: {'max_depth': 5, 'learning_rate': 0.16511818791239957, 'n_estimators': 187}. Best is trial 1 with value: 750305.1649093869.\n",
      "\n",
      " 12%|█████▎                                      | 6/50 [02:17<16:50, 22.96s/it]\u001b[A[I 2025-06-04 00:53:48,234] Trial 6 finished with value: 846515.3109731895 and parameters: {'max_depth': 5, 'learning_rate': 0.27214251193660277, 'n_estimators': 158}. Best is trial 1 with value: 750305.1649093869.\n",
      "\n",
      " 14%|██████▏                                     | 7/50 [02:21<12:00, 16.75s/it]\u001b[A[I 2025-06-04 00:53:57,295] Trial 7 finished with value: 832314.3843832002 and parameters: {'max_depth': 4, 'learning_rate': 0.1852538387583296, 'n_estimators': 456}. Best is trial 1 with value: 750305.1649093869.\n",
      "\n",
      " 16%|███████                                     | 8/50 [02:30<10:00, 14.30s/it]\u001b[A[I 2025-06-04 00:54:03,076] Trial 8 finished with value: 776590.8474440814 and parameters: {'max_depth': 8, 'learning_rate': 0.26275386128859063, 'n_estimators': 145}. Best is trial 1 with value: 750305.1649093869.\n",
      "\n",
      " 18%|███████▉                                    | 9/50 [02:36<07:57, 11.64s/it]\u001b[A[I 2025-06-04 00:54:40,039] Trial 9 finished with value: 756937.7116709977 and parameters: {'max_depth': 9, 'learning_rate': 0.101196522871971, 'n_estimators': 929}. Best is trial 1 with value: 750305.1649093869.\n",
      "\n",
      " 20%|████████▌                                  | 10/50 [03:13<12:58, 19.46s/it]\u001b[A[I 2025-06-04 00:54:55,344] Trial 10 finished with value: 1082416.6992626423 and parameters: {'max_depth': 3, 'learning_rate': 0.022759569774082306, 'n_estimators': 748}. Best is trial 1 with value: 750305.1649093869.\n",
      "\n",
      " 22%|█████████▍                                 | 11/50 [03:28<11:49, 18.19s/it]\u001b[A[I 2025-06-04 00:55:16,147] Trial 11 finished with value: 751351.4294185449 and parameters: {'max_depth': 7, 'learning_rate': 0.09865586681522052, 'n_estimators': 641}. Best is trial 1 with value: 750305.1649093869.\n",
      "\n",
      " 24%|██████████▎                                | 12/50 [03:49<12:01, 18.98s/it]\u001b[A[I 2025-06-04 00:55:38,840] Trial 12 finished with value: 750694.2934780273 and parameters: {'max_depth': 7, 'learning_rate': 0.09257550309622892, 'n_estimators': 695}. Best is trial 1 with value: 750305.1649093869.\n",
      "\n",
      " 26%|███████████▏                               | 13/50 [04:12<12:24, 20.12s/it]\u001b[A[I 2025-06-04 00:56:12,292] Trial 13 finished with value: 742854.223435255 and parameters: {'max_depth': 7, 'learning_rate': 0.09877808708637634, 'n_estimators': 985}. Best is trial 13 with value: 742854.223435255.\n",
      "\n",
      " 28%|████████████                               | 14/50 [04:45<14:28, 24.13s/it]\u001b[A[I 2025-06-04 00:56:39,045] Trial 14 finished with value: 787915.4391432267 and parameters: {'max_depth': 6, 'learning_rate': 0.04416830607825334, 'n_estimators': 973}. Best is trial 13 with value: 742854.223435255.\n",
      "\n",
      " 30%|████████████▉                              | 15/50 [05:12<14:32, 24.92s/it]\u001b[A[I 2025-06-04 00:57:10,368] Trial 15 finished with value: 756988.004933025 and parameters: {'max_depth': 8, 'learning_rate': 0.12753634151134846, 'n_estimators': 859}. Best is trial 13 with value: 742854.223435255.\n",
      "\n",
      " 32%|█████████████▊                             | 16/50 [05:44<15:12, 26.85s/it]\u001b[A[I 2025-06-04 00:57:47,761] Trial 16 finished with value: 768575.8805740515 and parameters: {'max_depth': 9, 'learning_rate': 0.06218812780784089, 'n_estimators': 867}. Best is trial 13 with value: 742854.223435255.\n",
      "\n",
      " 34%|██████████████▌                            | 17/50 [06:21<16:30, 30.02s/it]\u001b[A[I 2025-06-04 00:58:27,312] Trial 17 finished with value: 728038.1171161274 and parameters: {'max_depth': 7, 'learning_rate': 0.14005821753397463, 'n_estimators': 998}. Best is trial 17 with value: 728038.1171161274.\n",
      "\n",
      " 36%|███████████████▍                           | 18/50 [07:00<17:32, 32.89s/it]\u001b[A[I 2025-06-04 00:58:52,518] Trial 18 finished with value: 760497.6395707756 and parameters: {'max_depth': 5, 'learning_rate': 0.13364857864533497, 'n_estimators': 999}. Best is trial 17 with value: 728038.1171161274.\n",
      "\n",
      " 38%|████████████████▎                          | 19/50 [07:26<15:47, 30.58s/it]\u001b[A[I 2025-06-04 00:59:03,616] Trial 19 finished with value: 762806.2312151253 and parameters: {'max_depth': 7, 'learning_rate': 0.14517606220819618, 'n_estimators': 305}. Best is trial 17 with value: 728038.1171161274.\n",
      "\n",
      " 40%|█████████████████▏                         | 20/50 [07:37<12:21, 24.73s/it]\u001b[A[I 2025-06-04 00:59:28,006] Trial 20 finished with value: 733996.9201789561 and parameters: {'max_depth': 6, 'learning_rate': 0.23104882328367693, 'n_estimators': 842}. Best is trial 17 with value: 728038.1171161274.\n",
      "\n",
      " 42%|██████████████████                         | 21/50 [08:01<11:54, 24.63s/it]\u001b[A[I 2025-06-04 00:59:52,704] Trial 21 finished with value: 735980.1918789151 and parameters: {'max_depth': 6, 'learning_rate': 0.2328151639211383, 'n_estimators': 864}. Best is trial 17 with value: 728038.1171161274.\n",
      "\n",
      " 44%|██████████████████▉                        | 22/50 [08:26<11:30, 24.65s/it]\u001b[A[I 2025-06-04 01:00:13,950] Trial 22 finished with value: 739040.0284039847 and parameters: {'max_depth': 6, 'learning_rate': 0.22692378173479485, 'n_estimators': 849}. Best is trial 17 with value: 728038.1171161274.\n",
      "\n",
      " 46%|███████████████████▊                       | 23/50 [08:47<10:37, 23.63s/it]\u001b[A[I 2025-06-04 01:00:32,503] Trial 23 finished with value: 771260.7878391508 and parameters: {'max_depth': 4, 'learning_rate': 0.24262217039294642, 'n_estimators': 886}. Best is trial 17 with value: 728038.1171161274.\n",
      "\n",
      " 48%|████████████████████▋                      | 24/50 [09:06<09:34, 22.10s/it]\u001b[A[I 2025-06-04 01:00:47,503] Trial 24 finished with value: 742985.2586449075 and parameters: {'max_depth': 6, 'learning_rate': 0.17498014906884235, 'n_estimators': 619}. Best is trial 17 with value: 728038.1171161274.\n",
      "\n",
      " 50%|█████████████████████▌                     | 25/50 [09:21<08:19, 19.97s/it]\u001b[A[I 2025-06-04 01:01:04,863] Trial 25 finished with value: 754596.7100357146 and parameters: {'max_depth': 5, 'learning_rate': 0.241902494191921, 'n_estimators': 804}. Best is trial 17 with value: 728038.1171161274.\n",
      "\n",
      " 52%|██████████████████████▎                    | 26/50 [09:38<07:40, 19.19s/it]\u001b[A[I 2025-06-04 01:01:27,417] Trial 26 finished with value: 735643.1364988917 and parameters: {'max_depth': 6, 'learning_rate': 0.19670382107928422, 'n_estimators': 924}. Best is trial 17 with value: 728038.1171161274.\n",
      "\n",
      " 54%|███████████████████████▏                   | 27/50 [10:01<07:44, 20.20s/it]\u001b[A[I 2025-06-04 01:01:45,198] Trial 27 finished with value: 781146.7123784984 and parameters: {'max_depth': 4, 'learning_rate': 0.1952794304701692, 'n_estimators': 942}. Best is trial 17 with value: 728038.1171161274.\n",
      "\n",
      " 56%|████████████████████████                   | 28/50 [10:18<07:08, 19.47s/it]\u001b[A[I 2025-06-04 01:02:11,347] Trial 28 finished with value: 746499.4076381685 and parameters: {'max_depth': 7, 'learning_rate': 0.15620643219670366, 'n_estimators': 927}. Best is trial 17 with value: 728038.1171161274.\n",
      "\n",
      " 58%|████████████████████████▉                  | 29/50 [10:44<07:30, 21.48s/it]\u001b[A[I 2025-06-04 01:02:23,942] Trial 29 finished with value: 768498.0382578088 and parameters: {'max_depth': 5, 'learning_rate': 0.2146567536470898, 'n_estimators': 574}. Best is trial 17 with value: 728038.1171161274.\n",
      "\n",
      "Tuning models:  25%|███████▎                     | 1/4 [10:52<32:37, 652.41s/it]\u001b[A[I 2025-06-04 01:02:23,946] A new study created in memory with name: no-name-0a63dd4b-03a7-424e-8fa3-cbaffa8274b7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008853 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1069\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1966133.280770\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007811 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1066\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1959077.578795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007795 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1970383.414291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008271 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1067\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1972013.208859\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008731 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 50480, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1965128.784469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:02:43,913] Trial 0 finished with value: 731489.4631806696 and parameters: {'num_leaves': 39, 'learning_rate': 0.2548768558471221, 'n_estimators': 923}. Best is trial 0 with value: 731489.4631806696.\n",
      "\n",
      " 62%|██████████████████████████▋                | 31/50 [11:17<06:04, 19.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1069\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1966133.280770\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008887 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1066\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1959077.578795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1970383.414291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009932 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1067\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1972013.208859\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008988 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 50480, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1965128.784469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:02:58,171] Trial 1 finished with value: 778529.5193881042 and parameters: {'num_leaves': 45, 'learning_rate': 0.05613946202155921, 'n_estimators': 541}. Best is trial 0 with value: 731489.4631806696.\n",
      "\n",
      " 64%|███████████████████████████▌               | 32/50 [11:31<05:18, 17.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1069\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1966133.280770\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008316 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1066\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1959077.578795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008917 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1970383.414291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1067\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1972013.208859\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 50480, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1965128.784469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:03:06,806] Trial 2 finished with value: 802301.3537346857 and parameters: {'num_leaves': 60, 'learning_rate': 0.07100243328181766, 'n_estimators': 242}. Best is trial 0 with value: 731489.4631806696.\n",
      "\n",
      " 66%|████████████████████████████▍              | 33/50 [11:40<04:14, 14.97s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1069\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1966133.280770\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009694 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1066\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1959077.578795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008995 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1970383.414291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007667 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1067\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1972013.208859\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 50480, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1965128.784469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:03:13,728] Trial 3 finished with value: 789290.3201352238 and parameters: {'num_leaves': 29, 'learning_rate': 0.09354162509218239, 'n_estimators': 323}. Best is trial 0 with value: 731489.4631806696.\n",
      "\n",
      " 68%|█████████████████████████████▏             | 34/50 [11:47<03:20, 12.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1069\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1966133.280770\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1066\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1959077.578795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008830 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1970383.414291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008765 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1067\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1972013.208859\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009095 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 50480, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1965128.784469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:03:39,210] Trial 4 finished with value: 771250.5584730072 and parameters: {'num_leaves': 61, 'learning_rate': 0.2360094047270342, 'n_estimators': 811}. Best is trial 0 with value: 731489.4631806696.\n",
      "\n",
      " 70%|██████████████████████████████             | 35/50 [12:12<04:06, 16.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008708 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1069\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1966133.280770\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1066\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1959077.578795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007730 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1970383.414291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008893 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1067\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1972013.208859\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 50480, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1965128.784469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:03:46,282] Trial 5 finished with value: 811928.4717269632 and parameters: {'num_leaves': 43, 'learning_rate': 0.06509513003536752, 'n_estimators': 249}. Best is trial 0 with value: 731489.4631806696.\n",
      "\n",
      " 72%|██████████████████████████████▉            | 36/50 [12:19<03:10, 13.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008805 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1069\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1966133.280770\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008547 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1066\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1959077.578795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1970383.414291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009000 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1067\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1972013.208859\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 50480, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1965128.784469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:03:53,311] Trial 6 finished with value: 778749.1510358794 and parameters: {'num_leaves': 48, 'learning_rate': 0.1429380532858638, 'n_estimators': 244}. Best is trial 0 with value: 731489.4631806696.\n",
      "\n",
      " 74%|███████████████████████████████▊           | 37/50 [12:26<02:31, 11.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008987 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1069\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1966133.280770\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007626 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1066\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1959077.578795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008575 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1970383.414291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008817 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1067\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1972013.208859\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008392 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 50480, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1965128.784469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:04:27,179] Trial 7 finished with value: 780960.4871965782 and parameters: {'num_leaves': 74, 'learning_rate': 0.1815208927221762, 'n_estimators': 921}. Best is trial 0 with value: 731489.4631806696.\n",
      "\n",
      " 76%|████████████████████████████████▋          | 38/50 [13:00<03:39, 18.31s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1069\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1966133.280770\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1066\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1959077.578795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009223 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1970383.414291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008513 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1067\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1972013.208859\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009795 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 50480, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1965128.784469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:04:49,708] Trial 8 finished with value: 771657.3455804976 and parameters: {'num_leaves': 81, 'learning_rate': 0.1778026325182301, 'n_estimators': 522}. Best is trial 0 with value: 731489.4631806696.\n",
      "\n",
      " 78%|█████████████████████████████████▌         | 39/50 [13:23<03:35, 19.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008806 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1069\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1966133.280770\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1066\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1959077.578795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008985 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1970383.414291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008614 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1067\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1972013.208859\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 50480, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1965128.784469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:05:06,153] Trial 9 finished with value: 775435.4423876603 and parameters: {'num_leaves': 28, 'learning_rate': 0.04503261578455015, 'n_estimators': 883}. Best is trial 0 with value: 731489.4631806696.\n",
      "\n",
      " 80%|██████████████████████████████████▍        | 40/50 [13:39<03:06, 18.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1069\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1966133.280770\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007784 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1066\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1959077.578795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1970383.414291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1067\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1972013.208859\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 50480, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1965128.784469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:05:17,294] Trial 10 finished with value: 744727.0358062129 and parameters: {'num_leaves': 24, 'learning_rate': 0.27735987666603157, 'n_estimators': 707}. Best is trial 0 with value: 731489.4631806696.\n",
      "\n",
      " 82%|███████████████████████████████████▎       | 41/50 [13:50<02:27, 16.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1069\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1966133.280770\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1066\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1959077.578795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1970383.414291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007886 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1067\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1972013.208859\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 50480, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1965128.784469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:05:30,343] Trial 11 finished with value: 740278.8554184828 and parameters: {'num_leaves': 27, 'learning_rate': 0.2988798490712939, 'n_estimators': 749}. Best is trial 0 with value: 731489.4631806696.\n",
      "\n",
      " 84%|████████████████████████████████████       | 42/50 [14:03<02:03, 15.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007856 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1069\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1966133.280770\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008759 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1066\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1959077.578795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1970383.414291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1067\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1972013.208859\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 50480, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1965128.784469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:06:16,451] Trial 12 finished with value: 793867.3593519125 and parameters: {'num_leaves': 100, 'learning_rate': 0.29271474894547667, 'n_estimators': 991}. Best is trial 0 with value: 731489.4631806696.\n",
      "\n",
      " 86%|████████████████████████████████████▉      | 43/50 [14:50<02:52, 24.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1069\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1966133.280770\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1066\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1959077.578795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009012 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1970383.414291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011331 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1067\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1972013.208859\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007645 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 50480, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1965128.784469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:06:32,147] Trial 13 finished with value: 747541.8643330268 and parameters: {'num_leaves': 38, 'learning_rate': 0.2396378032884777, 'n_estimators': 705}. Best is trial 0 with value: 731489.4631806696.\n",
      "\n",
      " 88%|█████████████████████████████████████▊     | 44/50 [15:05<02:11, 21.93s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009922 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1069\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1966133.280770\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008524 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1066\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1959077.578795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1970383.414291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008712 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1067\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1972013.208859\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 50480, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1965128.784469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:06:43,005] Trial 14 finished with value: 736955.3962913199 and parameters: {'num_leaves': 22, 'learning_rate': 0.24307657817013617, 'n_estimators': 723}. Best is trial 0 with value: 731489.4631806696.\n",
      "\n",
      " 90%|██████████████████████████████████████▋    | 45/50 [15:16<01:33, 18.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008066 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1069\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1966133.280770\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008273 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1066\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1959077.578795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1970383.414291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1067\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1972013.208859\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008839 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 50480, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1965128.784469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:06:55,440] Trial 15 finished with value: 751331.898425779 and parameters: {'num_leaves': 36, 'learning_rate': 0.24033755026552045, 'n_estimators': 621}. Best is trial 0 with value: 731489.4631806696.\n",
      "\n",
      " 92%|███████████████████████████████████████▌   | 46/50 [15:29<01:07, 16.76s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007857 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1069\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1966133.280770\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1066\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1959077.578795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007968 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1970383.414291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007480 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1067\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1972013.208859\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008744 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 50480, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1965128.784469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:07:01,675] Trial 16 finished with value: 756793.403238869 and parameters: {'num_leaves': 21, 'learning_rate': 0.2086301310477772, 'n_estimators': 417}. Best is trial 0 with value: 731489.4631806696.\n",
      "\n",
      " 94%|████████████████████████████████████████▍  | 47/50 [15:35<00:40, 13.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007874 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1069\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1966133.280770\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1066\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1959077.578795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1970383.414291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008988 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1067\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1972013.208859\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007829 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 50480, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1965128.784469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:07:25,145] Trial 17 finished with value: 754515.6390801053 and parameters: {'num_leaves': 53, 'learning_rate': 0.1375137064650746, 'n_estimators': 834}. Best is trial 0 with value: 731489.4631806696.\n",
      "\n",
      " 96%|█████████████████████████████████████████▎ | 48/50 [15:58<00:33, 16.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008692 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1069\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1966133.280770\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1066\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1959077.578795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007562 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1970383.414291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007981 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1067\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1972013.208859\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008280 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 50480, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1965128.784469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:07:44,115] Trial 18 finished with value: 735856.8906027703 and parameters: {'num_leaves': 35, 'learning_rate': 0.2632291286664726, 'n_estimators': 983}. Best is trial 0 with value: 731489.4631806696.\n",
      "\n",
      " 98%|██████████████████████████████████████████▏| 49/50 [16:17<00:17, 17.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008189 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1069\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1966133.280770\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009002 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1066\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1959077.578795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008758 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1970383.414291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009782 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1067\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1972013.208859\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008915 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 50480, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1965128.784469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:08:15,973] Trial 19 finished with value: 770759.4822556733 and parameters: {'num_leaves': 56, 'learning_rate': 0.258945918062371, 'n_estimators': 977}. Best is trial 0 with value: 731489.4631806696.\n",
      "\n",
      "100%|███████████████████████████████████████████| 50/50 [16:49<00:00, 21.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1069\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1966133.280770\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1066\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1959077.578795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1970383.414291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008747 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1067\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1972013.208859\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 50480, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1965128.784469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:08:38,484] Trial 20 finished with value: 817761.0915336258 and parameters: {'num_leaves': 36, 'learning_rate': 0.018102296136151108, 'n_estimators': 888}. Best is trial 0 with value: 731489.4631806696.\n",
      "\n",
      "51it [17:12, 21.91s/it]                                                         \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011688 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1069\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1966133.280770\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1066\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1959077.578795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008277 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1970383.414291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1067\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1972013.208859\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008125 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 50480, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1965128.784469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:08:56,687] Trial 21 finished with value: 739110.9811020407 and parameters: {'num_leaves': 35, 'learning_rate': 0.20583075939599144, 'n_estimators': 797}. Best is trial 0 with value: 731489.4631806696.\n",
      "\n",
      "52it [17:30, 20.80s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005381 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1069\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1966133.280770\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017545 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1066\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1959077.578795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008370 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1970383.414291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007890 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1067\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1972013.208859\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006989 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 50480, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1965128.784469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:09:06,905] Trial 22 finished with value: 745048.0944676977 and parameters: {'num_leaves': 20, 'learning_rate': 0.26424194855342065, 'n_estimators': 644}. Best is trial 0 with value: 731489.4631806696.\n",
      "\n",
      "53it [17:40, 17.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012918 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1069\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1966133.280770\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1066\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1959077.578795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1970383.414291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1067\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1972013.208859\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007700 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 50480, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1965128.784469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:09:27,381] Trial 23 finished with value: 739681.1903274016 and parameters: {'num_leaves': 31, 'learning_rate': 0.21990755580009147, 'n_estimators': 993}. Best is trial 0 with value: 731489.4631806696.\n",
      "\n",
      "54it [18:01, 18.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1069\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1966133.280770\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008675 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1066\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1959077.578795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009703 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1970383.414291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009154 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1067\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1972013.208859\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008586 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 50480, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1965128.784469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:09:47,527] Trial 24 finished with value: 750897.6701574555 and parameters: {'num_leaves': 40, 'learning_rate': 0.1807314624323546, 'n_estimators': 907}. Best is trial 0 with value: 731489.4631806696.\n",
      "\n",
      "55it [18:21, 18.98s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1069\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1966133.280770\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010021 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1066\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1959077.578795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007473 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1970383.414291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008354 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1067\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1972013.208859\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008807 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 50480, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1965128.784469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:09:53,623] Trial 25 finished with value: 794521.8120910327 and parameters: {'num_leaves': 72, 'learning_rate': 0.2752692528966756, 'n_estimators': 141}. Best is trial 0 with value: 731489.4631806696.\n",
      "\n",
      "56it [18:27, 15.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008918 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1069\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1966133.280770\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008360 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1066\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1959077.578795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009315 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1970383.414291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008737 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1067\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1972013.208859\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008962 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 50480, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1965128.784469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:10:15,364] Trial 26 finished with value: 770476.029921944 and parameters: {'num_leaves': 49, 'learning_rate': 0.26135392637626303, 'n_estimators': 771}. Best is trial 0 with value: 731489.4631806696.\n",
      "\n",
      "57it [18:48, 17.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010112 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1069\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1966133.280770\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007311 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1066\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1959077.578795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010253 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1970383.414291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008185 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1067\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1972013.208859\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008653 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 50480, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1965128.784469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:10:29,100] Trial 27 finished with value: 745448.9363265677 and parameters: {'num_leaves': 30, 'learning_rate': 0.11436084353605902, 'n_estimators': 636}. Best is trial 0 with value: 731489.4631806696.\n",
      "\n",
      "58it [19:02, 16.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1069\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1966133.280770\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1066\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1959077.578795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007779 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1970383.414291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1067\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1972013.208859\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008823 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 50480, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1965128.784469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:10:42,042] Trial 28 finished with value: 729935.657262458 and parameters: {'num_leaves': 20, 'learning_rate': 0.2199761426536558, 'n_estimators': 937}. Best is trial 28 with value: 729935.657262458.\n",
      "\n",
      "59it [19:15, 15.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009022 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1069\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1966133.280770\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008725 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1066\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1959077.578795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1970383.414291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1067\n",
      "[LightGBM] [Info] Number of data points in the train set: 50479, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1972013.208859\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008583 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1068\n",
      "[LightGBM] [Info] Number of data points in the train set: 50480, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1965128.784469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 01:11:04,727] Trial 29 finished with value: 756440.7668716877 and parameters: {'num_leaves': 44, 'learning_rate': 0.21861089125396205, 'n_estimators': 939}. Best is trial 28 with value: 729935.657262458.\n",
      "\n",
      "Tuning models:  50%|██████████████▌              | 2/4 [19:33<19:09, 574.98s/it][I 2025-06-04 01:11:04,731] A new study created in memory with name: no-name-648f0f2c-fa53-411f-8c23-413879a7b4d0\n",
      "[I 2025-06-04 01:11:33,385] Trial 0 finished with value: 780945.9285754373 and parameters: {'depth': 8, 'learning_rate': 0.048272840390416745, 'iterations': 728}. Best is trial 0 with value: 780945.9285754373.\n",
      "\n",
      "61it [20:07, 20.78s/it]\u001b[A[I 2025-06-04 01:12:08,445] Trial 1 finished with value: 690130.5048388718 and parameters: {'depth': 8, 'learning_rate': 0.13124769075930845, 'iterations': 929}. Best is trial 1 with value: 690130.5048388718.\n",
      "\n",
      "62it [20:42, 25.07s/it]\u001b[A[I 2025-06-04 01:12:22,873] Trial 2 finished with value: 701852.1314063268 and parameters: {'depth': 7, 'learning_rate': 0.2765862840120269, 'iterations': 530}. Best is trial 1 with value: 690130.5048388718.\n",
      "\n",
      "63it [20:56, 21.88s/it]\u001b[A[I 2025-06-04 01:12:32,900] Trial 3 finished with value: 752110.4362480689 and parameters: {'depth': 8, 'learning_rate': 0.24646231598218757, 'iterations': 258}. Best is trial 1 with value: 690130.5048388718.\n",
      "\n",
      "64it [21:06, 18.32s/it]\u001b[A[I 2025-06-04 01:12:43,305] Trial 4 finished with value: 1023888.8004647691 and parameters: {'depth': 4, 'learning_rate': 0.024140597648725066, 'iterations': 715}. Best is trial 1 with value: 690130.5048388718.\n",
      "\n",
      "65it [21:16, 15.95s/it]\u001b[A[I 2025-06-04 01:12:59,950] Trial 5 finished with value: 778158.9365710145 and parameters: {'depth': 7, 'learning_rate': 0.07595461512392575, 'iterations': 614}. Best is trial 1 with value: 690130.5048388718.\n",
      "\n",
      "66it [21:33, 16.16s/it]\u001b[A[I 2025-06-04 01:13:05,327] Trial 6 finished with value: 807241.0096148384 and parameters: {'depth': 6, 'learning_rate': 0.22867879326989687, 'iterations': 240}. Best is trial 1 with value: 690130.5048388718.\n",
      "\n",
      "67it [21:38, 12.92s/it]\u001b[A[I 2025-06-04 01:13:19,339] Trial 7 finished with value: 752477.464862796 and parameters: {'depth': 5, 'learning_rate': 0.2219531145518879, 'iterations': 742}. Best is trial 1 with value: 690130.5048388718.\n",
      "\n",
      "68it [21:52, 13.25s/it]\u001b[A[I 2025-06-04 01:13:48,768] Trial 8 finished with value: 778526.1400957616 and parameters: {'depth': 8, 'learning_rate': 0.04953556095552783, 'iterations': 722}. Best is trial 1 with value: 690130.5048388718.\n",
      "\n",
      "69it [22:22, 18.10s/it]\u001b[A[I 2025-06-04 01:13:57,846] Trial 9 finished with value: 850405.791881939 and parameters: {'depth': 5, 'learning_rate': 0.09551793313959915, 'iterations': 508}. Best is trial 1 with value: 690130.5048388718.\n",
      "\n",
      "70it [22:31, 15.40s/it]\u001b[A[I 2025-06-04 01:15:53,632] Trial 10 finished with value: 683007.8586665838 and parameters: {'depth': 10, 'learning_rate': 0.16056869924337988, 'iterations': 1000}. Best is trial 10 with value: 683007.8586665838.\n",
      "\n",
      "71it [24:27, 45.51s/it]\u001b[A[I 2025-06-04 01:17:45,493] Trial 11 finished with value: 680133.7121088717 and parameters: {'depth': 10, 'learning_rate': 0.14586858700180197, 'iterations': 987}. Best is trial 11 with value: 680133.7121088717.\n",
      "\n",
      "72it [26:19, 65.42s/it]\u001b[A[I 2025-06-04 01:19:38,792] Trial 12 finished with value: 680923.7432168756 and parameters: {'depth': 10, 'learning_rate': 0.16869239064984054, 'iterations': 980}. Best is trial 11 with value: 680133.7121088717.\n",
      "\n",
      "73it [28:12, 79.78s/it]\u001b[A[I 2025-06-04 01:21:18,796] Trial 13 finished with value: 686033.3007468793 and parameters: {'depth': 10, 'learning_rate': 0.17730047961313566, 'iterations': 870}. Best is trial 11 with value: 680133.7121088717.\n",
      "\n",
      "74it [29:52, 85.85s/it]\u001b[A[I 2025-06-04 01:23:03,194] Trial 14 finished with value: 686498.526370887 and parameters: {'depth': 10, 'learning_rate': 0.12692700306724214, 'iterations': 876}. Best is trial 11 with value: 680133.7121088717.\n",
      "\n",
      "75it [31:36, 91.41s/it]\u001b[A[I 2025-06-04 01:24:11,147] Trial 15 finished with value: 678629.8037270963 and parameters: {'depth': 9, 'learning_rate': 0.18537299613880068, 'iterations': 979}. Best is trial 15 with value: 678629.8037270963.\n",
      "\n",
      "76it [32:44, 84.38s/it]\u001b[A[I 2025-06-04 01:28:05,121] Trial 16 finished with value: 713103.5211347907 and parameters: {'depth': 9, 'learning_rate': 0.21177904632122757, 'iterations': 380}. Best is trial 15 with value: 678629.8037270963.\n",
      "\n",
      "77it [36:38, 129.25s/it]\u001b[A[I 2025-06-04 01:29:02,463] Trial 17 finished with value: 682036.5881941215 and parameters: {'depth': 9, 'learning_rate': 0.19037116641787813, 'iterations': 831}. Best is trial 15 with value: 678629.8037270963.\n",
      "\n",
      "78it [37:36, 107.68s/it]\u001b[A[I 2025-06-04 01:29:27,038] Trial 18 finished with value: 740726.1816209739 and parameters: {'depth': 9, 'learning_rate': 0.12157630836743899, 'iterations': 398}. Best is trial 15 with value: 678629.8037270963.\n",
      "\n",
      "79it [38:00, 82.75s/it] \u001b[A[I 2025-06-04 01:29:37,126] Trial 19 finished with value: 859561.6397179347 and parameters: {'depth': 3, 'learning_rate': 0.25408801903644, 'iterations': 818}. Best is trial 15 with value: 678629.8037270963.\n",
      "\n",
      "80it [38:10, 60.95s/it]\u001b[A[I 2025-06-04 01:30:13,345] Trial 20 finished with value: 691759.0203197242 and parameters: {'depth': 9, 'learning_rate': 0.196342687803864, 'iterations': 600}. Best is trial 15 with value: 678629.8037270963.\n",
      "\n",
      "81it [38:46, 53.53s/it]\u001b[A[I 2025-06-04 01:32:03,114] Trial 21 finished with value: 694072.5761851171 and parameters: {'depth': 10, 'learning_rate': 0.15090276882121123, 'iterations': 933}. Best is trial 15 with value: 678629.8037270963.\n",
      "\n",
      "82it [40:36, 70.40s/it]\u001b[A[I 2025-06-04 01:33:59,840] Trial 22 finished with value: 689693.1886934123 and parameters: {'depth': 10, 'learning_rate': 0.16225517417676855, 'iterations': 960}. Best is trial 15 with value: 678629.8037270963.\n",
      "\n",
      "83it [42:33, 84.30s/it]\u001b[A[I 2025-06-04 01:34:58,872] Trial 23 finished with value: 693475.6896474875 and parameters: {'depth': 9, 'learning_rate': 0.09814180434340226, 'iterations': 1000}. Best is trial 15 with value: 678629.8037270963.\n",
      "\n",
      "84it [43:32, 76.72s/it]\u001b[A[I 2025-06-04 01:35:13,679] Trial 24 finished with value: 820111.5472051442 and parameters: {'depth': 10, 'learning_rate': 0.1443384758745731, 'iterations': 128}. Best is trial 15 with value: 678629.8037270963.\n",
      "\n",
      "85it [43:47, 58.15s/it]\u001b[A[I 2025-06-04 01:36:00,038] Trial 25 finished with value: 681340.7600006675 and parameters: {'depth': 9, 'learning_rate': 0.17881329789169614, 'iterations': 797}. Best is trial 15 with value: 678629.8037270963.\n",
      "\n",
      "86it [44:33, 54.61s/it]\u001b[A[I 2025-06-04 01:36:24,071] Trial 26 finished with value: 684033.0169218496 and parameters: {'depth': 7, 'learning_rate': 0.20623111882750614, 'iterations': 900}. Best is trial 15 with value: 678629.8037270963.\n",
      "\n",
      "87it [44:57, 45.44s/it]\u001b[A[I 2025-06-04 01:38:28,377] Trial 27 finished with value: 687790.5537170845 and parameters: {'depth': 10, 'learning_rate': 0.09829681912373489, 'iterations': 998}. Best is trial 15 with value: 678629.8037270963.\n",
      "\n",
      "88it [47:02, 69.10s/it]\u001b[A[I 2025-06-04 01:38:52,708] Trial 28 finished with value: 696196.0502333709 and parameters: {'depth': 8, 'learning_rate': 0.29581994201997597, 'iterations': 641}. Best is trial 15 with value: 678629.8037270963.\n",
      "\n",
      "89it [47:26, 55.67s/it]\u001b[A[I 2025-06-04 01:39:22,681] Trial 29 finished with value: 680990.4614912423 and parameters: {'depth': 8, 'learning_rate': 0.1805815872247045, 'iterations': 794}. Best is trial 15 with value: 678629.8037270963.\n",
      "\n",
      "Tuning models:  75%|█████████████████████       | 3/4 [47:51<18:07, 1087.75s/it][I 2025-06-04 01:39:22,684] A new study created in memory with name: no-name-678de641-fb16-432f-8947-49c045d934fc\n",
      "[I 2025-06-04 01:48:05,634] Trial 0 finished with value: 1080451.5256573018 and parameters: {'max_depth': 7, 'n_estimators': 698}. Best is trial 0 with value: 1080451.5256573018.\n",
      "\n",
      "91it [56:39, 190.46s/it]\u001b[A[I 2025-06-04 03:26:36,987] Trial 1 finished with value: 794346.7152472547 and parameters: {'max_depth': 17, 'n_estimators': 697}. Best is trial 1 with value: 794346.7152472547.\n",
      "\n",
      "92it [2:35:10, 1906.73s/it]\u001b[A[I 2025-06-04 03:34:03,780] Trial 2 finished with value: 1080920.1535506113 and parameters: {'max_depth': 7, 'n_estimators': 591}. Best is trial 1 with value: 794346.7152472547.\n",
      "\n",
      "93it [2:42:37, 1468.75s/it]\u001b[A[I 2025-06-04 03:42:37,705] Trial 3 finished with value: 952101.8570519891 and parameters: {'max_depth': 9, 'n_estimators': 537}. Best is trial 1 with value: 794346.7152472547.\n",
      "\n",
      "94it [2:51:11, 1182.30s/it]\u001b[A[I 2025-06-04 03:49:44,375] Trial 4 finished with value: 907470.6940026128 and parameters: {'max_depth': 10, 'n_estimators': 404}. Best is trial 1 with value: 794346.7152472547.\n",
      "\n",
      "95it [2:58:18, 955.61s/it] \u001b[A[I 2025-06-04 03:50:58,613] Trial 5 finished with value: 1179502.2379895088 and parameters: {'max_depth': 6, 'n_estimators': 114}. Best is trial 1 with value: 794346.7152472547.\n",
      "\n",
      "96it [2:59:32, 691.20s/it]\u001b[A[I 2025-06-04 03:53:47,975] Trial 6 finished with value: 1178069.9215198152 and parameters: {'max_depth': 6, 'n_estimators': 261}. Best is trial 1 with value: 794346.7152472547.\n",
      "\n",
      "97it [3:02:21, 534.65s/it]\u001b[A[I 2025-06-04 04:04:45,176] Trial 7 finished with value: 851557.1341292262 and parameters: {'max_depth': 12, 'n_estimators': 524}. Best is trial 1 with value: 794346.7152472547.\n",
      "\n",
      "98it [3:13:18, 571.42s/it]\u001b[A[I 2025-06-04 04:13:56,437] Trial 8 finished with value: 1177120.221076632 and parameters: {'max_depth': 6, 'n_estimators': 850}. Best is trial 1 with value: 794346.7152472547.\n",
      "\n",
      "99it [3:22:30, 565.37s/it]\u001b[A[I 2025-06-04 04:22:15,736] Trial 9 finished with value: 1304144.800994665 and parameters: {'max_depth': 5, 'n_estimators': 914}. Best is trial 1 with value: 794346.7152472547.\n",
      "\n",
      "100it [3:30:49, 545.55s/it]\u001b[A[I 2025-06-04 04:46:13,257] Trial 10 finished with value: 786846.0346380824 and parameters: {'max_depth': 19, 'n_estimators': 758}. Best is trial 10 with value: 786846.0346380824.\n",
      "\n",
      "101it [3:54:46, 813.14s/it]\u001b[A[I 2025-06-04 05:10:20,468] Trial 11 finished with value: 786108.206161727 and parameters: {'max_depth': 19, 'n_estimators': 763}. Best is trial 11 with value: 786108.206161727.\n",
      "\n",
      "102it [4:18:54, 1003.36s/it]\u001b[A[I 2025-06-04 05:36:16,035] Trial 12 finished with value: 785739.4040391378 and parameters: {'max_depth': 20, 'n_estimators': 785}. Best is trial 12 with value: 785739.4040391378.\n",
      "\n",
      "103it [4:44:49, 1169.02s/it]\u001b[A[I 2025-06-04 06:03:19,352] Trial 13 finished with value: 798498.1690567583 and parameters: {'max_depth': 16, 'n_estimators': 995}. Best is trial 12 with value: 785739.4040391378.\n",
      "\n",
      "104it [5:11:52, 1305.31s/it]\u001b[A[I 2025-06-04 06:29:04,625] Trial 14 finished with value: 783202.6671098962 and parameters: {'max_depth': 20, 'n_estimators': 783}. Best is trial 14 with value: 783202.6671098962.\n",
      "\n",
      "105it [5:37:38, 1377.30s/it]\u001b[A[I 2025-06-04 06:50:55,212] Trial 15 finished with value: 807859.3171675808 and parameters: {'max_depth': 15, 'n_estimators': 853}. Best is trial 14 with value: 783202.6671098962.\n",
      "\n",
      "106it [5:59:28, 1357.29s/it]\u001b[A[I 2025-06-04 07:11:41,102] Trial 16 finished with value: 783761.0208800356 and parameters: {'max_depth': 20, 'n_estimators': 630}. Best is trial 14 with value: 783202.6671098962.\n",
      "\n",
      "107it [6:20:14, 1323.87s/it]\u001b[A[I 2025-06-04 07:21:34,370] Trial 17 finished with value: 819579.6224535557 and parameters: {'max_depth': 14, 'n_estimators': 411}. Best is trial 14 with value: 783202.6671098962.\n",
      "\n",
      "108it [6:30:08, 1104.69s/it]\u001b[A[I 2025-06-04 07:40:34,568] Trial 18 finished with value: 789836.5782356481 and parameters: {'max_depth': 18, 'n_estimators': 629}. Best is trial 14 with value: 783202.6671098962.\n",
      "\n",
      "109it [6:49:08, 1115.34s/it]\u001b[A[I 2025-06-04 07:54:50,245] Trial 19 finished with value: 783819.7968319186 and parameters: {'max_depth': 20, 'n_estimators': 433}. Best is trial 14 with value: 783202.6671098962.\n",
      "\n",
      "110it [7:03:23, 1037.44s/it]\u001b[A[I 2025-06-04 08:32:47,915] Trial 20 finished with value: 830880.4676823386 and parameters: {'max_depth': 13, 'n_estimators': 964}. Best is trial 14 with value: 783202.6671098962.\n",
      "\n",
      "111it [7:41:21, 1409.51s/it]\u001b[A[I 2025-06-04 08:47:05,618] Trial 21 finished with value: 785077.9404003026 and parameters: {'max_depth': 20, 'n_estimators': 434}. Best is trial 14 with value: 783202.6671098962.\n",
      "\n",
      "112it [7:55:39, 1243.97s/it]\u001b[A[I 2025-06-04 08:54:59,257] Trial 22 finished with value: 790600.4024659579 and parameters: {'max_depth': 17, 'n_estimators': 274}. Best is trial 14 with value: 783202.6671098962.\n",
      "\n",
      "113it [8:03:32, 1012.87s/it]\u001b[A[I 2025-06-04 09:09:36,880] Trial 23 finished with value: 788399.3900922171 and parameters: {'max_depth': 18, 'n_estimators': 484}. Best is trial 14 with value: 783202.6671098962.\n",
      "\n",
      "114it [8:18:10, 972.29s/it] \u001b[A[I 2025-06-04 09:19:44,253] Trial 24 finished with value: 784002.7671550051 and parameters: {'max_depth': 20, 'n_estimators': 307}. Best is trial 14 with value: 783202.6671098962.\n",
      "\n",
      "115it [8:28:17, 862.82s/it]\u001b[A[I 2025-06-04 09:40:25,792] Trial 25 finished with value: 789775.1554003379 and parameters: {'max_depth': 18, 'n_estimators': 683}. Best is trial 14 with value: 783202.6671098962.\n",
      "\n",
      "116it [8:48:59, 976.44s/it]\u001b[A[I 2025-06-04 09:56:14,504] Trial 26 finished with value: 807481.4045978355 and parameters: {'max_depth': 15, 'n_estimators': 613}. Best is trial 14 with value: 783202.6671098962.\n",
      "\n",
      "117it [9:04:48, 968.12s/it]\u001b[A[I 2025-06-04 10:07:22,336] Trial 27 finished with value: 786638.4596963907 and parameters: {'max_depth': 19, 'n_estimators': 346}. Best is trial 14 with value: 783202.6671098962.\n",
      "\n",
      "118it [9:15:55, 878.03s/it]\u001b[A[I 2025-06-04 10:34:43,771] Trial 28 finished with value: 783309.437360293 and parameters: {'max_depth': 20, 'n_estimators': 487}. Best is trial 14 with value: 783202.6671098962.\n",
      "\n",
      "119it [9:43:17, 1107.05s/it]\u001b[A[I 2025-06-04 11:24:03,512] Trial 29 finished with value: 792328.1156894292 and parameters: {'max_depth': 17, 'n_estimators': 656}. Best is trial 14 with value: 783202.6671098962.\n",
      "\n",
      "Tuning models: 100%|█████████████████████████| 4/4 [10:32:31<00:00, 9488.00s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'xgb': {'max_depth': 7,\n",
       "  'learning_rate': 0.14005821753397463,\n",
       "  'n_estimators': 998},\n",
       " 'lgb': {'num_leaves': 20,\n",
       "  'learning_rate': 0.2199761426536558,\n",
       "  'n_estimators': 937},\n",
       " 'cat': {'depth': 9, 'learning_rate': 0.18537299613880068, 'iterations': 979},\n",
       " 'rf': {'max_depth': 20, 'n_estimators': 783}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 执行调参\n",
    "best_hyperparams = tune_all_models()\n",
    "best_hyperparams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db46644c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xgb': {'max_depth': 7,\n",
       "  'learning_rate': 0.14005821753397463,\n",
       "  'n_estimators': 998},\n",
       " 'lgb': {'num_leaves': 20,\n",
       "  'learning_rate': 0.2199761426536558,\n",
       "  'n_estimators': 937},\n",
       " 'cat': {'depth': 9, 'learning_rate': 0.18537299613880068, 'iterations': 979},\n",
       " 'rf': {'max_depth': 20, 'n_estimators': 783}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyperparams"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
