{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b0f8339",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbookair/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression,Ridge, Lasso\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from transformers import pipeline\n",
    "import jieba\n",
    "from gensim import corpora, models\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import joblib \n",
    "from joblib import loadrom sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6d32c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91649689",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=pd.read_csv(\"/Users/macbookair/Documents/python 2/data.csv\")\n",
    "data_train_price=data_train[\"价格\"]\n",
    "data_train=data_train.drop(columns=[\"Unnamed: 0\",\"价格\",\"text\"])\n",
    "data_pred=pd.read_csv(\"/Users/macbookair/Documents/python 2/X_pred.csv\")\n",
    "data_pred=data_pred.drop(columns=[\"Unnamed: 0\",\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c624fc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbookair/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "#文本的情感分析 使用在hugging face上运用大众点评数据进行调节的Bert 进行情感分析\n",
    "model_path= \"/Users/macbookair/Documents/transformer\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "def text_score(text,tokenizer=tokenizer,model=model):\n",
    "    # 编码并推理\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)#将原始文本转数值输入\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)#正向传播\n",
    "        probs = F.softmax(outputs.logits, dim=1)#将分类问题通过softmax转化为概率\n",
    "    # 获取概率\n",
    "    positive_prob = probs[0][1].item()\n",
    "    negative_prob = probs[0][0].item()\n",
    "\n",
    "    # 自定义评分（线性映射）\n",
    "    score = positive_prob * 5 + negative_prob * 1\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4d1b5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[score]=data_train.apply(lambda row:text_score(row[\"text\"]),axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e11222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data_train\n",
    "y=data_train_price\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea17080f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#因为样本数量太多 所以随机选择10000进行调参\n",
    "sample_size = 10000\n",
    "if len(X) > sample_size:\n",
    "    np.random.seed(42)  # 保证可复现\n",
    "    indices = np.random.choice(len(X), sample_size, replace=False)\n",
    "    X_sample = X.iloc[indices,:]\n",
    "    y_sample = y[indices]\n",
    "else:\n",
    "    X_sample = X\n",
    "    y_sample = y\n",
    "X__sampletrain,X_sample_test,y_sample_train,y_sample_test=train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d653540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    param = {\n",
    "        'verbosity': 0,\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse',\n",
    "        'booster': trial.suggest_categorical('booster', ['gbtree', 'dart']),\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
    "    }\n",
    "\n",
    "    model = XGBRegressor(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, preds)\n",
    "    return mse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49101e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize')  # 回归是“最小化”损失\n",
    "study.optimize(objective, n_trials=50)\n",
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f61b04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_par={'booster': 'dart',\n",
    " 'lambda': 0.008244759581148755,\n",
    " 'alpha': 0.6405598303602479,\n",
    " 'subsample': 0.9721516428059781,\n",
    " 'colsample_bytree': 0.6368787772510718,\n",
    " 'learning_rate': 0.15427365499198334,\n",
    " 'max_depth': 5,\n",
    " 'n_estimators': 154}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d116a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge...\n",
      "Training rf...\n",
      "Training xgb...\n",
      "Training catboost...\n",
      "Training lgbm...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1069\n",
      "[LightGBM] [Info] Number of data points in the train set: 53844, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1956461.644566\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013671 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1071\n",
      "[LightGBM] [Info] Number of data points in the train set: 53845, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1972012.284892\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1076\n",
      "[LightGBM] [Info] Number of data points in the train set: 53845, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1966890.691243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1073\n",
      "[LightGBM] [Info] Number of data points in the train set: 53845, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1965130.307549\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008677 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 53845, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score 1966678.330950\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Test RMSE: 1092943.42919389\n"
     ]
    }
   ],
   "source": [
    "# emsemble 集成学习。将ridge randomforest 和 XGboost 作为第一层模型\n",
    "models = {\n",
    "    'ridge': Ridge(alpha=1.0),\n",
    "    'rf': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'xgb': XGBRegressor(**best_par),\n",
    "    'catboost': CatBoostRegressor(n_estimators=150, learning_rate=0.1, depth=6, verbose=0, random_state=42),\n",
    "    'lgbm': LGBMRegressor(n_estimators=150, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "}  \n",
    "# 3. 训练第一层模型并生成折外预测\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#存储每个模型在训练集上的 （Out-of-Fold）预测\n",
    "meta_features_train = np.zeros((X_train.shape[0], len(models)))\n",
    "# 存储每个模型对验证集 X_val 的平均预测结果\n",
    "meta_features_val = np.zeros((X_test.shape[0], len(models)))\n",
    "\n",
    "for i, (name, model) in enumerate(models.items()):\n",
    "    print(f\"Training {name}...\")\n",
    "    oof_predictions = np.zeros(X_train.shape[0])\n",
    "    val_predictions = np.zeros(X_test.shape[0])\n",
    "    \n",
    "    for train_idx, val_idx in kf.split(X_train):\n",
    "        X_tr, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        model.fit(X_tr, y_tr)\n",
    "        oof_predictions[val_idx] = model.predict(X_val_fold)\n",
    "        val_predictions += model.predict(X_test) / kf.n_splits\n",
    "    joblib.dump(model, f\"{name}_model.pkl\")\n",
    "    \n",
    "    meta_features_train[:, i] = oof_predictions\n",
    "    meta_features_val[:, i] = val_predictions\n",
    "# 4. 训练元模型\n",
    "meta_model = XGBRegressor(n_estimators=60, learning_rate=0.1, random_state=42)\n",
    "meta_model.fit(meta_features_train, y_train)\n",
    "joblib.dump(meta_model, \"meta_model.pkl\")\n",
    "\n",
    "# 5. 预测和评估\n",
    "test_predictions = np.zeros((X_test.shape[0], len(models)))\n",
    "for i, (name, model) in enumerate(models.items()):\n",
    "    test_predictions[:, i] = model.predict(X_test)\n",
    "\n",
    "meta_test_predictions = meta_model.predict(test_predictions)\n",
    "final_predictions = meta_test_predictions  \n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, final_predictions))\n",
    "print(f\"Test RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b6e7be5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Optimal Voting Weights (with meta model): [0.         0.49579131 0.50420869 0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "def objective(weights):\n",
    "    weights = np.array(weights)\n",
    "    weights /= np.sum(weights)  # 归一化权重\n",
    "    final_pred = np.sum([w * pred for w, pred in zip(weights, test_predictions.T)], axis=0)\n",
    "    return mean_squared_error(y_test, final_pred, squared=False)  # RMSE\n",
    "\n",
    "# 初始权重 6 个，对应 5 个基础模型 + 1 个 meta model\n",
    "initial_weights = [1/6] * 6  \n",
    "bounds = [(0, 1)] * 6\n",
    "\n",
    "result = minimize(objective, initial_weights, bounds=bounds)\n",
    "optimal_weights = result.x / np.sum(result.x)\n",
    "\n",
    "print(\" Optimal Voting Weights (with meta model):\", optimal_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1e70ff2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Voting Weights: {'ridge': 0.0, 'rf': 0.49579131, 'xgb': 0.50420869, 'catboost': 0.0, 'lgbm': 0.0, 'meta_model': 0.0}\n"
     ]
    }
   ],
   "source": [
    "#predict\n",
    "models = {\n",
    "    'ridge': load('Ridge_model.pkl'),\n",
    "    'rf': load('rf_model.pkl'),\n",
    "    'xgb': load('xgb_model.pkl'),\n",
    "    \"catboost\": load('catboost_model.pkl'),\n",
    "    'lgbm': load('lgbm_model.pkl')\n",
    "}\n",
    "meta_model = load('meta_model.pkl')\n",
    "# 替换为你的实际优化权重（确保与训练时一致）\n",
    "voting_weights = {'ridge':0,'rf':0.49579131,\"xgb\":0.50420869,\"catboost\":0,'lgbm':0,\"meta_model\":0}\n",
    "total_weight = sum(voting_weights.values())\n",
    "voting_weights = {k: v / total_weight for k, v in voting_weights.items()}\n",
    "print(\"Normalized Voting Weights:\", voting_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3cd893f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with ridge...\n",
      "Predicting with rf...\n",
      "Predicting with xgb...\n",
      "Predicting with catboost...\n",
      "Predicting with lgbm...\n"
     ]
    }
   ],
   "source": [
    "# 第一层模型预测\n",
    "base_predictions = np.zeros((data_pred.shape[0], len(models)))\n",
    "for i, (name, model) in enumerate(models.items()):\n",
    "    print(f\"Predicting with {name}...\")\n",
    "    base_predictions[:, i] = model.predict(data_pred)\n",
    "\n",
    "# 元模型预测\n",
    "meta_predictions = meta_model.predict(base_predictions)\n",
    "#voting 得到最后结果\n",
    "final_predictions = np.zeros(data_pred.shape[0])\n",
    "for i, name in enumerate(models.keys()):\n",
    "    final_predictions += voting_weights[name] * base_predictions[:, i]\n",
    "final_predictions +=voting_weights[\"meta_model\"] * meta_predictions\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'predicted_price': final_predictions\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "056e6e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_par={'booster': 'dart',\n",
    " 'lambda': 0.008244759581148755,\n",
    " 'alpha': 0.6405598303602479,\n",
    " 'subsample': 0.9721516428059781,\n",
    " 'colsample_bytree': 0.6368787772510718,\n",
    " 'learning_rate': 0.15427365499198334,\n",
    " 'max_depth': 5,\n",
    " 'n_estimators': 154}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e009eb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred=pd.DataFrame(results)\n",
    "y_test_pred.to_csv(\"/Users/macbookair/Documents/results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c35b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
