{"cells":[{"cell_type":"markdown","metadata":{"id":"BAEE51CAC7804597B5D0E06FB209A34B","trusted":true,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":true,"runtime":{"status":"default","execution_status":null,"is_visible":false},"scrolled":false,"notebookId":"67ec17035302e998c321293b"},"source":"## 欢迎进入 Notebook  \n\n这里你可以编写代码，文档  \n\n### 关于文件目录  \n\n\n**project**：project 目录是本项目的工作空间，可以把将项目运行有关的所有文件放在这里，目录中文件的增、删、改操作都会被保留  \n\n\n**input**：input 目录是数据集的挂载位置，所有挂载进项目的数据集都在这里，未挂载数据集时 input 目录被隐藏  \n\n\n**temp**：temp 目录是临时磁盘空间，训练或分析过程中产生的不必要文件可以存放在这里，目录中的文件不会保存  \n"},{"cell_type":"code","metadata":{"id":"3999AF60F2754394BA5F1A3C9AD8354B","trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"scrolled":false,"notebookId":"67ec17035302e998c321293b"},"source":"# 查看个人持久化工作区文件\n!ls /home/mw/project/","outputs":[{"output_type":"stream","name":"stdout","text":"lasso_model.pkl  prediction.csv  selected_features.pkl\tword2vec_model.model\r\n"}],"execution_count":1},{"cell_type":"code","metadata":{"id":"F8B70CD7BC87457F9CB6221D1CE5EDBB","trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"scrolled":false,"notebookId":"67ec17035302e998c321293b"},"source":"# 查看当前挂载的数据集目录\n!ls /home/mw/input/","outputs":[{"output_type":"stream","name":"stdout","text":"ls: cannot access '/home/mw/input/': No such file or directory\r\n"}],"execution_count":2},{"cell_type":"markdown","metadata":{"id":"546651B4E19C4F75964709B8BBBC9B86","notebookId":"67ec17035302e998c321293b","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":"# 读取并查看数据"},{"cell_type":"code","metadata":{"id":"E3D20517B1BA42708C005966CEA1E1D9","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"import subprocess\nimport sys\n\n# 检测模块是否安装\ndef install_and_import(package):\n    try:\n        __import__(package)\n        print(f\"{package} 已经安装\")\n    except ImportError:\n        print(f\"{package} 未安装，正在安装...\")\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n        print(f\"{package} 安装成功！\")\n        __import__(package)\n\n# 模块名称列表，名称使用pip中的标准模块名称\nmodules = [\n    \"numpy\", \"pandas\", \"random\", \"re\", \"time\", \"warnings\", \"pickle\",\n    \"sklearn\", \"joblib\", \"numba\", \"gensim\", \"matplotlib\", \"seaborn\",\n    \"geopy\", \"openpyxl\", \"tensorflow\",\"tqdm\"\n]\n\nfor module in modules:\n    install_and_import(module)","outputs":[{"output_type":"stream","name":"stdout","text":"numpy 已经安装\npandas 已经安装\nrandom 已经安装\nre 已经安装\ntime 已经安装\nwarnings 已经安装\npickle 已经安装\nsklearn 已经安装\njoblib 已经安装\nnumba 已经安装\ngensim 未安装，正在安装...\nCollecting gensim\n  Obtaining dependency information for gensim from https://files.pythonhosted.org/packages/e3/43/4feed7d79a69d886197a83389b6728ecaaa8839e51472da1228a818a69a7/gensim-4.3.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading gensim-4.3.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\nRequirement already satisfied: numpy<2.0,>=1.18.5 in /opt/conda/lib/python3.9/site-packages (from gensim) (1.24.4)\nRequirement already satisfied: scipy<1.14.0,>=1.7.0 in /opt/conda/lib/python3.9/site-packages (from gensim) (1.11.2)\nCollecting smart-open>=1.8.1 (from gensim)\n  Obtaining dependency information for smart-open>=1.8.1 from https://files.pythonhosted.org/packages/7a/18/9a8d9f01957aa1f8bbc5676d54c2e33102d247e146c1a3679d3bd5cc2e3a/smart_open-7.1.0-py3-none-any.whl.metadata\n  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.9/site-packages (from smart-open>=1.8.1->gensim) (1.15.0)\nDownloading gensim-4.3.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.6/26.6 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: smart-open, gensim\nSuccessfully installed gensim-4.3.3 smart-open-7.1.0\n"}],"execution_count":3},{"cell_type":"code","metadata":{"id":"AEAD957B50724284AA9E4FF2DDDF9CE5","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 基础模块\nimport numpy as np\nimport pandas as pd\nimport random\nimport re\nimport time\nimport warnings\nimport pickle\n\n# 数据处理与预处理模块\nfrom sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer, StandardScaler, PowerTransformer, PolynomialFeatures\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, cross_val_predict\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.decomposition import PCA, IncrementalPCA\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_selection import SelectKBest, f_regression, SelectFromModel\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\n# 机器学习模型模块\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\nfrom sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error,r2_score\nfrom sklearn.neighbors import BallTree\n\n# 并行与加速模块\nfrom joblib import Parallel, delayed\nfrom sklearn.utils import parallel_backend\nfrom numba import njit\n\n# 自然语言处理模块\nfrom gensim.models import Word2Vec\n\n# 数据可视化模块\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib.font_manager as fm\n\n# 地理计算模块\nfrom geopy.distance import geodesic\n\n# Excel 处理模块\nfrom openpyxl import Workbook\nfrom openpyxl.utils import get_column_letter\nfrom openpyxl.styles import Alignment\n\n# 深度学习模块\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Dense\nprint(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n\n# 其他模块\nimport joblib\nfrom tqdm import tqdm\n","outputs":[],"execution_count":4},{"cell_type":"code","metadata":{"id":"BCF399CB6AA645C68FED2BA462FBCA3D","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 加载训练集和测试集\ndf = pd.read_csv('/home/mw/input/quant4533/ruc_Class25Q1_train.csv')\npredict = pd.read_csv('/home/mw/input/quant4533/ruc_Class25Q1_test.csv')\n\n# 加载小区详细数据和租价数据\ndetails = pd.read_csv('/home/mw/input/quant4533/ruc_Class25Q1_details.csv')\nrent = pd.read_csv('/home/mw/input/quant4533/ruc_Class25Q1_rent.csv')","outputs":[],"execution_count":5},{"cell_type":"code","metadata":{"id":"E8363413199E458683604F9F0C5A1F25","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 查看训练数据集的前几行\ndf.head()","outputs":[],"execution_count":6},{"cell_type":"code","metadata":{"id":"73488A1D09884A4F8C1858237F99D76A","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"#查看数据类型\ndf.info()","outputs":[],"execution_count":7},{"cell_type":"code","metadata":{"id":"3DE7603F534149F7B10DB498FCF11CFB","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 检查训练数据集每列的缺失值情况\ndf.isnull().sum()","outputs":[],"execution_count":8},{"cell_type":"code","metadata":{"id":"3B3688560E8D47749319E186014B83A1","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"from sklearn.model_selection import train_test_split\n# X 是特征，y 是目标变量\nX = df.drop(columns=['价格'])  # 特征列\ny = df['价格']  # 目标列（例如房价、分类标签等）\n\n# 使用 train_test_split 进行划分，80% 训练集，20% 测试集\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=111)\n\n# 确保分割后的数据有相同的行数\nprint(f\"X_train行数: {X_train.shape[0]}, y_train行数: {y_train.shape[0]}\")\nprint(f\"X_test行数: {X_test.shape[0]}, y_test行数: {y_test.shape[0]}\")\n\n# 如果行数一致但索引不同，可以重置索引\nX_train = X_train.reset_index(drop=True)\nX_test = X_test.reset_index(drop=True)\ny_train = y_train.reset_index(drop=True)\ny_test = y_test.reset_index(drop=True)\n\n# 查看训练集和测试集的大小\nprint(f\"训练集大小: {X_train.shape}\")\nprint(f\"测试集大小: {X_test.shape}\")\n\n# 预测集\nX_predict = predict","outputs":[],"execution_count":9},{"cell_type":"code","metadata":{"id":"5FD33AB0993F40DE8B62F8EFAAB509B4","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 基于IQR的异常值检测和处理\ndef handle_outliers(X_data, y_data, threshold=3):\n    # 计算目标变量的IQR\n    Q1 = y_data.quantile(0.25)\n    Q3 = y_data.quantile(0.75)\n    IQR = Q3 - Q1\n    \n    # 定义边界\n    lower_bound = Q1 - threshold * IQR\n    upper_bound = Q3 + threshold * IQR\n    \n    # 找出非异常样本的索引\n    mask = (y_data >= lower_bound) & (y_data <= upper_bound)\n    \n    # 记录异常值数量\n    print(f\"在{len(y_data)}个样本中识别出{(~mask).sum()}个异常值\")\n    \n    # 返回过滤后的数据集\n    return X_data[mask], y_data[mask]\n\n# 应用异常值处理\nX_train, y_train = handle_outliers(X_train, y_train, threshold=3.5)","outputs":[],"execution_count":10},{"cell_type":"code","metadata":{"id":"B0F64F3A484E4E5FBC3433A10014A838","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 查看小区详细信息数据集的前几行\ndetails.head()","outputs":[],"execution_count":11},{"cell_type":"code","metadata":{"id":"24FA32340DA14D48A416DB26D4735A7E","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 检查训练数据集每列的缺失值情况\ndetails.isnull().sum()","outputs":[],"execution_count":12},{"cell_type":"code","metadata":{"id":"95B8CCC25EAC4EAABE0F1F76D52F8417","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 查看租价数据集的前几行\nrent.head()","outputs":[],"execution_count":13},{"cell_type":"code","metadata":{"id":"AC9A9E7C04754ABDB2B9134BBE4E8C32","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 检查训练数据集每列的缺失值情况\nrent.isnull().sum()","outputs":[],"execution_count":14},{"cell_type":"markdown","metadata":{"id":"D95015F58DC84D84A7683C312C2C8F20","notebookId":"67ec17035302e998c321293b","runtime":{"status":"default","execution_status":null,"is_visible":false},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"}},"source":"# 特征工程"},{"cell_type":"code","metadata":{"id":"C4F604A22B4F4EBFACBAE24F333AD03F","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 创建新数据框以存放处理后的数据\nX_train_cleaned = pd.DataFrame(index=X_train.index)\nX_test_cleaned = pd.DataFrame(index=X_test.index)\nX_predict_cleaned = pd.DataFrame(index=X_predict.index)","outputs":[],"execution_count":15},{"cell_type":"code","metadata":{"id":"CB61742179BA4118997C8FE167109DC9","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 导入数据\nfor col in ['区域', '板块', '小区名称', '城市', '交易权属', '房屋用途', '产权所属']:\n    X_train_cleaned[col] = X_train[col]\n    X_test_cleaned[col] = X_test[col]\n    X_predict_cleaned[col] = X_predict[col]\n\n# 补充部分列的缺失值\ndef fill_missing_values(df, df_cleaned, column, fill_value='未知'):\n    # 填补缺失值\n    df[column] = df[column].fillna(fill_value)\n    # 将处理后的列放入清洗后的数据框中\n    df_cleaned[column] = df[column]\n\nfor col in ['建筑结构', '装修情况', '别墅类型']:\n    fill_missing_values(X_train, X_train_cleaned, col)\n    fill_missing_values(X_test, X_test_cleaned, col)\n    fill_missing_values(X_predict, X_predict_cleaned, col)\n","outputs":[],"execution_count":16},{"cell_type":"code","metadata":{"id":"706611813CD94F7A82777AAAA367B77F","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 1. 先将经纬度转换为弧度，以便于使用BallTree\nX_train['lat_rad'] = np.radians(X_train['lat'])\nX_train['lon_rad'] = np.radians(X_train['lon'])\n\nX_test['lat_rad'] = np.radians(X_test['lat'])\nX_test['lon_rad'] = np.radians(X_test['lon'])\n\nX_predict['lat_rad'] = np.radians(X_predict['lat'])\nX_predict['lon_rad'] = np.radians(X_predict['lon'])\n\n# 2. 使用训练集中有环线信息的数据构建BallTree\ntrain_with_ring = X_train[X_train['环线'].notnull()].copy()\ncoords_train_with_ring = np.vstack((train_with_ring['lat_rad'], train_with_ring['lon_rad'])).T\ntree_train_with_ring = BallTree(coords_train_with_ring, metric='haversine')\n\n# 3. 创建辅助函数，用于填补缺失的环线数据\ndef fill_missing_ring_using_balltree(row, df_with_ring, tree_with_ring, lat_col='lat', lon_col='lon', ring_col='环线'):\n    # 如果当前行有环线数据，直接返回原值\n    if pd.notnull(row[ring_col]):\n        return row[ring_col]\n    \n    # 当前行的经纬度（转换为弧度）\n    current_location_rad = np.radians([row[lat_col], row[lon_col]]).reshape(1, -1)\n    \n    # 查找最近的小区，限定在有环线数据的小区范围内\n    dist, idx = tree_with_ring.query(current_location_rad, k=1)  # 只找一个最近的小区\n    nearest_idx = idx[0][0]  # 取出最近小区的索引\n    \n    # 返回最近小区的环线值\n    return df_with_ring.iloc[nearest_idx][ring_col]\n\n# 4. 填补训练集中的缺失值（使用训练集内的最近邻小区数据填补）\nX_train_cleaned['环线'] = X_train.apply(\n    lambda row: fill_missing_ring_using_balltree(row, train_with_ring, tree_train_with_ring), axis=1\n)\n\n# 5. 填补测试集中的缺失值（使用训练集中的最近邻小区数据填补）\nX_test_cleaned['环线'] = X_test.apply(\n    lambda row: fill_missing_ring_using_balltree(row, train_with_ring, tree_train_with_ring), axis=1\n)\n\nX_predict_cleaned['环线'] = X_predict.apply(\n    lambda row: fill_missing_ring_using_balltree(row, train_with_ring, tree_train_with_ring), axis=1\n)\n\n# 6. 删除临时添加的经纬度弧度列（lat_rad 和 lon_rad）\nX_train.drop(columns=['lat_rad', 'lon_rad'], inplace=True)\nX_test.drop(columns=['lat_rad', 'lon_rad'], inplace=True)","outputs":[],"execution_count":17},{"cell_type":"code","metadata":{"id":"C79C42781DF945049A9E0AD80E1A1CE1","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 消除链式赋值的警告\npd.options.mode.chained_assignment = None\n\n# 处理“配备电梯”列：根据“梯户比例”判断\ndef process_elevator(df, df_cleaned, elevator_col, ratio_col):\n    # 根据“梯户比例”列是否有值判断是否配备电梯\n    df[elevator_col] = df[ratio_col].notna().map({True: '有', False: '无'})\n    fill_missing_values(df, df_cleaned, elevator_col, '无')\n\n# 应用“配备电梯”列的处理函数\nprocess_elevator(X_train, X_train_cleaned, '配备电梯', '梯户比例')\nprocess_elevator(X_test, X_test_cleaned, '配备电梯', '梯户比例')\nprocess_elevator(X_predict, X_predict_cleaned, '配备电梯', '梯户比例')","outputs":[],"execution_count":18},{"cell_type":"code","metadata":{"id":"AF0F48F1780A4A169B8A381903BF1D99","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 定义标准的八个方向\nstandard_directions = ['东', '南', '西', '北', '东南', '东北', '西南', '西北']\n\n# 定义一个方向映射规则，将“南东”标准化为“东南”\ndirection_mapping = {\n    '南东': '东南',\n    '北东': '东北',\n    '南西': '西南',\n    '北西': '西北',\n    '东南': '东南',\n    '东北': '东北',\n    '西南': '西南',\n    '西北': '西北'\n}\n\n# 优化房屋朝向处理\ndef clean_directions_optimized(series):\n    # 用空格分割各个方向\n    direction_split = series.str.split()\n    \n    # 通过替换将“南东”等非标准化的方向转换为标准方向\n    for key, value in direction_mapping.items():\n        direction_split = direction_split.apply(lambda x: [value if d == key else d for d in x])\n    \n    # 将方向列表去重，并通过 MultiLabelBinarizer 生成布尔特征\n    mlb = MultiLabelBinarizer(classes=standard_directions)\n    return pd.DataFrame(mlb.fit_transform(direction_split), columns=mlb.classes_, index=series.index)\n\n# 应用优化后的函数到房屋朝向列，并将结果添加\nX_train_cleaned = pd.concat([X_train_cleaned, clean_directions_optimized(X_train['房屋朝向'])], axis=1)\nX_test_cleaned = pd.concat([X_test_cleaned, clean_directions_optimized(X_test['房屋朝向'])], axis=1)\nX_predict_cleaned = pd.concat([X_predict_cleaned, clean_directions_optimized(X_predict['房屋朝向'])], axis=1)\n\n# 优化房屋优势处理，去除空白字符\ndef process_advantages_optimized(series):\n    # 按“、”分割房屋优势，去除空格和空字符串\n    advantage_split = series.fillna('').apply(lambda x: [item.strip() for item in x.split('、') if item.strip()])\n    \n    # 通过 MultiLabelBinarizer 生成布尔特征\n    mlb = MultiLabelBinarizer()\n    return pd.DataFrame(mlb.fit_transform(advantage_split), columns=mlb.classes_, index=series.index)\n\n# 应用优化后的函数到房屋优势列，并将结果添加\nX_train_cleaned = pd.concat([X_train_cleaned, process_advantages_optimized(X_train['房屋优势'])], axis=1)\nX_test_cleaned = pd.concat([X_test_cleaned, process_advantages_optimized(X_test['房屋优势'])], axis=1)\nX_predict_cleaned = pd.concat([X_predict_cleaned, process_advantages_optimized(X_predict['房屋优势'])], axis=1)\n","outputs":[],"execution_count":19},{"cell_type":"code","metadata":{"id":"BA99495B3AA644579A0152E13C1542E7","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 1. 定义处理“房屋年限”的函数\ndef process_house_age(age_info):\n    if age_info == '满五年':\n        return 5\n    elif age_info == '满两年':\n        return 2\n    elif age_info == '未满两年':\n        return 0\n    else:\n        return None  # 如果是缺失值或不匹配，返回 None\n\n# 2. 处理训练集的“房屋年限”列\nX_train_cleaned['房屋年限'] = X_train['房屋年限'].apply(process_house_age)\n\n# 3. 计算训练集中“房屋年限”的中位数（用于填补缺失值）\ntrain_median_age = X_train_cleaned['房屋年限'].median()\n\n# 4. 处理测试集的“房屋年限”列\nX_test_cleaned['房屋年限'] = X_test['房屋年限'].apply(process_house_age)\nX_predict_cleaned['房屋年限'] = X_predict['房屋年限'].apply(process_house_age)\n\n\n# 5. 填补训练集中的缺失值\nX_train_cleaned['房屋年限'] = X_train_cleaned['房屋年限'].fillna(train_median_age)\n\n# 6. 填补测试集中的缺失值，使用训练集的中位数\nX_test_cleaned['房屋年限'] = X_test_cleaned['房屋年限'].fillna(train_median_age)\nX_predict_cleaned['房屋年限'] = X_predict_cleaned['房屋年限'].fillna(train_median_age)\n","outputs":[],"execution_count":20},{"cell_type":"code","metadata":{"id":"33D66BDE44F0495392560DB4D5F46B60","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 处理缺失值，确保所有数据为字符串类型\nfor col in ['核心卖点', '户型介绍', '周边配套', '交通出行']:\n    X_train[col] = X_train[col].fillna('未知').astype(str)\n    X_test[col] = X_test[col].fillna('未知').astype(str)\n    X_predict[col] = X_predict[col].fillna('未知').astype(str)\n\n# 定义文本清理函数\ndef clean_text(text):\n    text = re.sub(r'[^\\w\\s]', '', text)  # 去除标点符号\n    text = text.lower()  # 转为小写\n    return text\n\n# 应用文本清理函数\nfor col in ['核心卖点', '户型介绍', '周边配套', '交通出行']:\n    X_train[col] = X_train[col].apply(clean_text)\n    X_test[col] = X_test[col].apply(clean_text)\n    X_predict[col] = X_predict[col].apply(clean_text)\n\n# 将文本列转换为单词列表\nfor col in ['核心卖点', '户型介绍', '周边配套', '交通出行']:\n    X_train[col] = X_train[col].apply(lambda x: x.split())\n    X_test[col] = X_test[col].apply(lambda x: x.split())\n    X_predict[col] = X_predict[col].apply(lambda x: x.split())\n\n# 合并训练集所有列，创建训练语料库\nsentences_train = X_train['核心卖点'].tolist() + X_train['户型介绍'].tolist() + X_train['周边配套'].tolist() + X_train['交通出行'].tolist()\n\n# 训练Word2Vec模型（仅基于训练集）\nw2v_model = Word2Vec(sentences_train, vector_size=100, window=5, min_count=1, workers=4)\n\n# 保存Word2Vec模型\nw2v_model.save(\"word2vec_model.model\")\n\n# 载入模型以验证保存是否成功\nw2v_model = Word2Vec.load(\"word2vec_model.model\")\n\n# 获取训练好的词向量\nword_vectors = w2v_model.wv\n\n# 定义函数，将文本行转化为词向量的平均值\ndef get_average_word2vec(text, model, vector_size):\n    feature_vector = np.zeros((vector_size,), dtype='float32')\n    num_words = 0\n    for word in text:\n        if word in model:\n            num_words += 1\n            feature_vector = np.add(feature_vector, model[word])\n    if num_words > 0:\n        feature_vector = np.divide(feature_vector, num_words)\n    return feature_vector.tolist()  # 将NumPy数组转换为Python列表\n\n# 为训练集和测试集每个列生成词向量特征\nX_train_backup = X_train.copy()  # 确保有数据副本\nX_test_backup = X_test.copy()\nX_predict_backup = X_predict.copy()\n\nfor col in ['核心卖点', '户型介绍', '周边配套', '交通出行']:\n    X_train_backup[f'{col}_word2vec'] = X_train[col].apply(lambda x: get_average_word2vec(x, word_vectors, 100))\n    X_test_backup[f'{col}_word2vec'] = X_test[col].apply(lambda x: get_average_word2vec(x, word_vectors, 100))\n    X_predict_backup[f'{col}_word2vec'] = X_predict[col].apply(lambda x: get_average_word2vec(x, word_vectors, 100))\n\n# 拆分嵌入向量为独立的列\nword2vec_features = ['核心卖点_word2vec', '户型介绍_word2vec', '周边配套_word2vec', '交通出行_word2vec']\n\nfor feature in word2vec_features:\n    # 对训练集进行处理\n    vectors_train = pd.DataFrame(X_train_backup[feature].tolist(), index=X_train_backup.index)\n    vectors_train.columns = [f'{feature}_{i}' for i in range(100)]  # 命名每个列\n    X_train_cleaned = pd.concat([X_train_cleaned, vectors_train], axis=1)\n    \n    # 对测试集进行处理\n    vectors_test = pd.DataFrame(X_test_backup[feature].tolist(), index=X_test_backup.index)\n    vectors_test.columns = [f'{feature}_{i}' for i in range(100)]  # 命名每个列\n    X_test_cleaned = pd.concat([X_test_cleaned, vectors_test], axis=1)\n\n    vectors_predict = pd.DataFrame(X_predict_backup[feature].tolist(), index=X_predict_backup.index)\n    vectors_predict.columns = [f'{feature}_{i}' for i in range(100)]  # 命名每个列\n    X_predict_cleaned = pd.concat([X_predict_cleaned, vectors_predict], axis=1)\n","outputs":[],"execution_count":21},{"cell_type":"code","metadata":{"id":"DAF0775AF6ED4BE7854A861EA1186A97","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 定义需要虚拟变量化的定性变量\ncategorical_columns = [\n    '环线', '建筑结构', '装修情况', '配备电梯',\n    '别墅类型', '交易权属', '房屋用途', '产权所属'\n]\n\n# 对训练集和测试集的指定列进行虚拟变量化，并替换原列\nfor col in categorical_columns:\n    # 对训练集进行虚拟变量化，并用虚拟变量替换原列\n    dummies_train = pd.get_dummies(X_train_cleaned[col], prefix=col, drop_first=True)\n    X_train_cleaned = pd.concat([X_train_cleaned.drop(columns=[col]), dummies_train], axis=1)\n    \n    # 对测试集进行虚拟变量化，并用虚拟变量替换原列\n    dummies_test = pd.get_dummies(X_test_cleaned[col], prefix=col, drop_first=True)\n    X_test_cleaned = pd.concat([X_test_cleaned.drop(columns=[col]), dummies_test], axis=1)\n\n    dummies_predict = pd.get_dummies(X_predict_cleaned[col], prefix=col, drop_first=True)\n    X_predict_cleaned = pd.concat([X_predict_cleaned.drop(columns=[col]), dummies_predict], axis=1)\n\n\n# 保证测试集和训练集列一致（如果有不匹配列，测试集中缺少的列用0填充）\nX_test_cleaned = X_test_cleaned.reindex(columns=X_train_cleaned.columns, fill_value=0)\nX_predict_cleaned = X_predict_cleaned.reindex(columns=X_train_cleaned.columns, fill_value=0)\n","outputs":[],"execution_count":22},{"cell_type":"code","metadata":{"id":"8F0543FA107D442A905AFC94E22D2E31","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"for col in ['lon', 'lat', '年份']:\n    X_train_cleaned[col] = X_train[col]\n    X_test_cleaned[col] = X_test[col]\n    X_predict_cleaned[col] = X_predict[col]\n","outputs":[],"execution_count":23},{"cell_type":"code","metadata":{"id":"4A186E6357324EBAB474654A15763171","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 1. 去掉\"建筑面积\"和\"套内面积\"中的 \"㎡\" 并转换为浮点数\nX_train_cleaned['建筑面积'] = X_train['建筑面积'].astype(str).str.replace('㎡', '').astype(float)\nX_train_cleaned['套内面积'] = X_train['套内面积'].astype(str).str.replace('㎡', '').astype(float)\n\nX_test_cleaned['建筑面积'] = X_test['建筑面积'].astype(str).str.replace('㎡', '').astype(float)\nX_test_cleaned['套内面积'] = X_test['套内面积'].astype(str).str.replace('㎡', '').astype(float)\n\nX_predict_cleaned['建筑面积'] = X_predict['建筑面积'].astype(str).str.replace('㎡', '').astype(float)\nX_predict_cleaned['套内面积'] = X_predict['套内面积'].astype(str).str.replace('㎡', '').astype(float)\n\n# 2. 在训练集中计算套内面积与建筑面积的比例\nX_train_cleaned['面积比例'] = X_train_cleaned['套内面积'] / X_train_cleaned['建筑面积']\n\n# 3. 计算训练集的平均比例\naverage_ratio = X_train_cleaned['面积比例'].mean()\n\n# 4. 使用建筑面积乘以训练集的平均比例填充训练集和测试集中的缺失套内面积\n\n# 填充训练集中的缺失套内面积\nX_train_cleaned['套内面积'] = X_train_cleaned.apply(\n    lambda row: row['建筑面积'] * average_ratio if pd.isnull(row['套内面积']) else row['套内面积'], axis=1\n)\n\n# 填充测试集中的缺失套内面积\nX_test_cleaned['套内面积'] = X_test_cleaned.apply(\n    lambda row: row['建筑面积'] * average_ratio if pd.isnull(row['套内面积']) else row['套内面积'], axis=1\n)\n\nX_predict_cleaned['套内面积'] = X_predict_cleaned.apply(\n    lambda row: row['建筑面积'] * average_ratio if pd.isnull(row['套内面积']) else row['套内面积'], axis=1\n)\n\n# 5. 删除临时的面积比例列\nX_train_cleaned.drop(columns=['面积比例'], inplace=True)\n\n","outputs":[],"execution_count":24},{"cell_type":"code","metadata":{"id":"431B4AFE26D84E0E8B871E03D0C25D61","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 1. 定义提取房屋户型信息的函数\ndef extract_room_info(house_type):\n    # 检查输入是否为字符串，非字符串的情况返回默认值\n    if not isinstance(house_type, str):\n        return {'室': 0, '厅': 0, '厨': 0, '卫': 0}\n    \n    # 使用正则表达式提取室、厅、厨、卫的数据\n    room_data = re.findall(r'(\\d+)室|(\\d+)厅|(\\d+)厨|(\\d+)卫', house_type)\n    \n    # 默认初始值为0\n    room_count = {'室': 0, '厅': 0, '厨': 0, '卫': 0}\n    \n    # 提取匹配的数据\n    for match in room_data:\n        for i, category in enumerate(['室', '厅', '厨', '卫']):\n            if match[i]:\n                room_count[category] = int(match[i])\n    \n    return room_count\n\n# 2. 处理训练集的房屋户型列\n# 将房屋户型中的缺失值填充为空字符串，避免正则表达式报错\nX_train['房屋户型'] = X_train['房屋户型'].fillna('')\n\n# 创建新列，将提取出的数据放入新列\nX_train_cleaned['室'] = X_train['房屋户型'].apply(lambda x: extract_room_info(x)['室'])\nX_train_cleaned['厅'] = X_train['房屋户型'].apply(lambda x: extract_room_info(x)['厅'])\nX_train_cleaned['厨'] = X_train['房屋户型'].apply(lambda x: extract_room_info(x)['厨'])\nX_train_cleaned['卫'] = X_train['房屋户型'].apply(lambda x: extract_room_info(x)['卫'])\n\n# 3. 填充训练集中的缺失值\n# 对“室”和“厅”使用训练集的中位数填充\nX_train_cleaned['室'] = X_train_cleaned['室'].fillna(X_train_cleaned['室'].median())\nX_train_cleaned['厅'] = X_train_cleaned['厅'].fillna(X_train_cleaned['厅'].median())\n\n# 对“厨”和“卫”使用常见值（如1）填充\nX_train_cleaned['厨'] = X_train_cleaned['厨'].fillna(1)\nX_train_cleaned['卫'] = X_train_cleaned['卫'].fillna(1)\n\n# 4. 处理测试集的房屋户型列，使用训练集的数据处理测试集\n# 填充测试集中的缺失值，避免报错\nX_test['房屋户型'] = X_test['房屋户型'].fillna('')\nX_predict['房屋户型'] = X_predict['房屋户型'].fillna('')\n\n# 创建新列，将提取出的数据放入新列\nfor col in ['室','厅','厨','卫']:\n    X_test_cleaned[col] = X_test['房屋户型'].apply(lambda x: extract_room_info(x)[col])  \n    X_predict_cleaned[col] = X_predict['房屋户型'].apply(lambda x: extract_room_info(x)[col])  \n\n# 5. 使用训练集的中位数和常见值填充测试集的缺失值\nX_test_cleaned['室'] = X_test_cleaned['室'].fillna(X_train_cleaned['室'].median())\nX_test_cleaned['厅'] = X_test_cleaned['厅'].fillna(X_train_cleaned['厅'].median())\nX_test_cleaned['厨'] = X_test_cleaned['厨'].fillna(1)  # 使用常见值1填充\nX_test_cleaned['卫'] = X_test_cleaned['卫'].fillna(1)  # 使用常见值1填充\n\nX_predict_cleaned['室'] = X_predict_cleaned['室'].fillna(X_train_cleaned['室'].median())\nX_predict_cleaned['厅'] = X_predict_cleaned['厅'].fillna(X_train_cleaned['厅'].median())\nX_predict_cleaned['厨'] = X_predict_cleaned['厨'].fillna(1)  # 使用常见值1填充\nX_predict_cleaned['卫'] = X_predict_cleaned['卫'].fillna(1)  # 使用常见值1填充\n\n# 查看结果\nprint(X_train_cleaned[['室', '厅', '厨', '卫']].head())\nprint(X_test_cleaned[['室', '厅', '厨', '卫']].head())\nprint(X_predict_cleaned[['室', '厅', '厨', '卫']].head())\n","outputs":[],"execution_count":25},{"cell_type":"code","metadata":{"id":"A2A1AB6D82574D2FBC2A52AA20264197","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"print(f\"X_train行数: {len(X_train)}, X_predict行数: {len(X_predict)}\")\nprint(f\"X_train_cleaned行数: {len(X_train_cleaned)}, X_predict_cleaned行数: {len(X_predict_cleaned)}\")","outputs":[],"execution_count":26},{"cell_type":"code","metadata":{"id":"28EEDADD856B445ABBD3727EB580494B","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 1. 定义处理楼层信息的函数\ndef process_floor(floor_info):\n    # 正则表达式提取楼层描述和总层数\n    match = re.match(r'(低楼层|中楼层|高楼层|地下室|顶层|底层) \\(共(\\d+)层\\)', floor_info)\n    \n    if match:\n        floor_type = match.group(1)  # 获取楼层类型（高、中、低、地下室）\n        total_floors = int(match.group(2))  # 总层数\n        \n        if floor_type == '高楼层':\n            return total_floors * 5 / 6, total_floors\n        elif floor_type == '中楼层':\n            return total_floors * 3 / 6, total_floors\n        elif floor_type == '低楼层':\n            return total_floors * 1 / 6, total_floors\n        elif floor_type == '顶层':\n            return total_floors, total_floors\n        elif floor_type == '底层':\n            return 1, total_floors\n        elif floor_type == '地下室':\n            return -1, total_floors  # 地下室直接返回-1\n    else:\n        return None, None  # 如果数据格式不符合预期，返回None\n\n# 2. 处理训练集的“所在楼层”列\n# 应用处理函数，提取楼层数值和总层数\nX_train_cleaned['楼层数值'], X_train_cleaned['总层数'] = zip(*X_train['所在楼层'].apply(process_floor))\n\n# 3. 处理测试集的“所在楼层”列\n# 应用处理函数，提取楼层数值和总层数\nX_test_cleaned['楼层数值'], X_test_cleaned['总层数'] = zip(*X_test['所在楼层'].apply(process_floor))\nX_predict_cleaned['楼层数值'], X_predict_cleaned['总层数'] = zip(*X_predict['所在楼层'].apply(process_floor))\n","outputs":[],"execution_count":27},{"cell_type":"code","metadata":{"id":"765D195194B741B9A114E2648F5CFF47","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 1. 定义中文数字到阿拉伯数字的映射\nchinese_num_map = {\n    '零': 0, '一': 1, '二': 2, '三': 3, '四': 4, '五': 5, '六': 6, '七': 7, '八': 8, '九': 9,\n    '十': 10, '百': 100, '千': 1000, '万': 10000\n}\n\n# 2. 将中文数字转换为阿拉伯数字\ndef chinese_to_arabic(chinese_digits):\n    result = 0\n    unit = 1\n    for char in reversed(chinese_digits):\n        if char in chinese_num_map:\n            num = chinese_num_map[char]\n            if num >= 10:  # 是十、百、千等倍数\n                unit = num\n            else:\n                result += num * unit\n        else:\n            unit = 1  # 重置倍数单位\n    return result\n\n# 3. 处理“梯户比例”列，提取中文的梯数和户数，并计算比例\ndef extract_elevator_house_ratio(ratio_info):\n    # 使用正则表达式提取梯数和户数，中文格式如“一梯一千零二十二户”\n    match = re.match(r'([零一二三四五六七八九十百千万]+)梯([零一二三四五六七八九十百千万]+)户', ratio_info)\n    \n    if match:\n        elevators = chinese_to_arabic(match.group(1))  # 将中文梯数转换为阿拉伯数字\n        households = chinese_to_arabic(match.group(2))  # 将中文户数转换为阿拉伯数字\n        if elevators > 0:\n            return households / elevators  # 计算梯户比例\n    return None  # 如果格式不匹配或梯数为0，则返回None\n\n# 4. 处理训练集的“梯户比例”列\nX_train_cleaned['梯户比例'] = X_train['梯户比例'].apply(\n    lambda x: extract_elevator_house_ratio(x) if isinstance(x, str) else None\n)\n\n# 5. 计算训练集中梯户比例的均值（用于填补缺失值）\ntrain_mean_ratio = X_train_cleaned['梯户比例'].mean()\n\n# 6. 处理测试集的“梯户比例”列，使用训练集的均值填补缺失值\nX_test_cleaned['梯户比例'] = X_test['梯户比例'].apply(\n    lambda x: extract_elevator_house_ratio(x) if isinstance(x, str) else None\n)\n\nX_predict_cleaned['梯户比例'] = X_predict['梯户比例'].apply(\n    lambda x: extract_elevator_house_ratio(x) if isinstance(x, str) else None\n)\n\n# 7. 填补训练集中的缺失值\nX_train_cleaned['梯户比例'] = X_train_cleaned['梯户比例'].fillna(train_mean_ratio)\n\n# 8. 填补测试集中的缺失值，使用训练集的均值\nX_test_cleaned['梯户比例'] = X_test_cleaned['梯户比例'].fillna(train_mean_ratio)\nX_predict_cleaned['梯户比例'] = X_predict_cleaned['梯户比例'].fillna(train_mean_ratio)\n\n","outputs":[],"execution_count":28},{"cell_type":"code","metadata":{"id":"3074C64048574E8E8944FE7DA2D759FD","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 查看处理后的结果\nprint(X_train_cleaned.head())\nprint(X_test_cleaned.head())\nprint(X_predict_cleaned.head())","outputs":[],"execution_count":29},{"cell_type":"code","metadata":{"id":"CE50614A5AD5422E97D9B2157DE321FD","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 通用函数定义\ndef extract_number(text, suffix=''):\n    if not isinstance(text, str):\n        return None\n    # 移除后缀并提取数字\n    if suffix and text.endswith(suffix):\n        text = text[:-len(suffix)]\n    # 尝试提取数字\n    try:\n        return float(re.sub(r'[^\\d.]', '', text))\n    except:\n        return None\n\ndef extract_year(year_info):\n    if not isinstance(year_info, str):\n        return None\n    \n    # 提取年份范围（如\"1970-1979年\"）\n    range_match = re.match(r'(\\d{4})-(\\d{4})年', year_info)\n    if range_match:\n        start_year = int(range_match.group(1))\n        end_year = int(range_match.group(2))\n        return (start_year + end_year) // 2  # 取中点年份\n    \n    # 提取具体年份（如\"2010年\"）\n    exact_match = re.match(r'(\\d{4})年', year_info)\n    if exact_match:\n        return int(exact_match.group(1))\n    \n    return None\n\n\ndef match_community_features_fixed(df, community_features, community_columns):\n    \"\"\"\n    将小区特征匹配到数据框中，确保不增加行数\n    \n    参数:\n    df - 要添加特征的数据框\n    community_features - 包含小区特征的数据框\n    community_columns - 要匹配的特征列名列表\n    \n    返回:\n    添加了特征的数据框，保持原始行数和索引\n    \"\"\"\n    # 创建结果DataFrame，直接复制原始DataFrame\n    result_df = df.copy()\n    \n    # 为每个要添加的特征列创建默认值（使用中位数）\n    for col in community_columns:\n        # 先在结果DataFrame中创建列，使用NaN初始化\n        result_df[col] = np.nan\n    \n    # 1. 直接遍历每一行，进行精确匹配\n    for idx, row in result_df.iterrows():\n        # 在community_features中查找匹配的记录\n        matched_records = community_features[\n            (community_features['城市'] == row['城市']) & \n            (community_features['名称'] == row['小区名称'])\n        ]\n        \n        if len(matched_records) > 0:\n            # 如果找到匹配，使用第一条记录的值（避免多条匹配）\n            for col in community_columns:\n                if col in matched_records.columns:\n                    result_df.loc[idx, col] = matched_records.iloc[0][col]\n    \n    # 2. 对仍然有缺失值的记录，使用经纬度找最近的记录\n    missing_mask = result_df[community_columns[0]].isna()\n    missing_count = missing_mask.sum()\n    \n    if missing_count > 0:\n        print(f\"精确匹配后仍有 {missing_count} 条记录需要通过经纬度匹配\")\n        \n        # 筛选出有完整特征的记录作为参考\n        reference = community_features.dropna(subset=community_columns)\n        \n        # 创建BallTree加速最近邻搜索（如果行数较多）\n        if len(reference) > 1000:\n            try:\n                from sklearn.neighbors import BallTree\n                coords = np.radians(reference[['coord_y', 'coord_x']].values)\n                tree = BallTree(coords, metric='haversine')\n                use_balltree = True\n                print(\"使用BallTree加速搜索\")\n            except:\n                use_balltree = False\n                print(\"无法使用BallTree，将使用逐行计算\")\n        else:\n            use_balltree = False\n        \n        # 遍历所有缺失值记录\n        for idx in result_df[missing_mask].index:\n            row = result_df.loc[idx]\n            \n            # 对于没有经纬度的记录，跳过\n            if pd.isna(row['lon']) or pd.isna(row['lat']):\n                continue\n                \n            # 筛选同城市的小区\n            city_communities = reference[reference['城市'] == row['城市']]\n            \n            if len(city_communities) > 0:\n                if use_balltree:\n                    # 使用BallTree查找最近的小区\n                    query_point = np.radians([[row['lat'], row['lon']]])\n                    dist, indices = tree.query(query_point, k=1)\n                    nearest = reference.iloc[indices[0][0]]\n                else:\n                    # 计算欧氏距离\n                    city_communities['distance'] = np.sqrt(\n                        (city_communities['coord_x'] - row['lon'])**2 + \n                        (city_communities['coord_y'] - row['lat'])**2\n                    )\n                    \n                    # 找到距离最小的记录\n                    nearest_idx = city_communities['distance'].idxmin()\n                    nearest = city_communities.loc[nearest_idx]\n                \n                # 更新缺失的特征值\n                for col in community_columns:\n                    result_df.loc[idx, col] = nearest[col]\n    \n    # 3. 确保没有任何列丢失\n    for col in df.columns:\n        if col not in result_df.columns:\n            result_df[col] = df[col]\n    \n    # 4. 最终检查缺失值，使用全局中位数填充\n    for col in community_columns:\n        if result_df[col].isna().any():\n            # 计算全局中位数\n            global_median = community_features[col].median()\n            # 填充缺失值\n            result_df[col] = result_df[col].fillna(global_median)\n            print(f\"列 {col} 使用全局中位数 {global_median} 填充了 {result_df[col].isna().sum()} 个缺失值\")\n    \n    # 5. 验证结果行数\n    if len(result_df) != len(df):\n        print(f\"警告: 函数返回行数 {len(result_df)} 与输入行数 {len(df)} 不一致，这不应该发生！\")\n    \n    return result_df\n\n# 处理小区详情数据集\ndetails_processed = details.copy()\n\n\n# 处理建筑年代\ndetails_processed['建筑年代数值'] = details_processed['建筑年代'].apply(extract_year)\n\n# 计算板块和城市的建筑年代中位数\nplate_year_median = details_processed.groupby(['城市', '板块'])['建筑年代数值'].median().reset_index()\nplate_year_median.columns = ['城市', '板块', '板块建筑年代中位数']\n\ncity_year_median = details_processed.groupby('城市')['建筑年代数值'].median().reset_index()\ncity_year_median.columns = ['城市', '城市建筑年代中位数']\n\n# 计算全局建筑年代中位数\nglobal_year_median = details_processed['建筑年代数值'].median()\n\n# 将中位数合并回details数据集并填充缺失值\ndetails_processed = pd.merge(details_processed, plate_year_median, on=['城市', '板块'], how='left')\ndetails_processed = pd.merge(details_processed, city_year_median, on='城市', how='left')\n\ndetails_processed['建筑年代数值'] = details_processed['建筑年代数值'].fillna(details_processed['板块建筑年代中位数'])\ndetails_processed['建筑年代数值'] = details_processed['建筑年代数值'].fillna(details_processed['城市建筑年代中位数'])\ndetails_processed['建筑年代数值'] = details_processed['建筑年代数值'].fillna(global_year_median)\n\n# 确定当前年份并计算楼龄\ncurrent_year = max(X_train['年份'].max(), X_test['年份'].max(), X_predict['年份'].max())\ndetails_processed['楼龄'] = current_year - details_processed['建筑年代数值']\n\n# 准备小区特征数据框\ncommunity_features = details_processed[['城市', '名称', 'coord_x', 'coord_y', '楼龄']]\n\n# 处理建筑年代特征\nyear_columns = ['楼龄']\nprint(\"开始处理建筑年代特征...\")\nprint(f\"处理前训练集行数: {len(X_train_cleaned)}\")\nprint(f\"处理前测试集行数: {len(X_test_cleaned)}\")\nprint(f\"处理前预测集行数: {len(X_predict_cleaned)}\")\n\nX_train_cleaned = match_community_features_fixed(X_train_cleaned, community_features, year_columns)\nX_test_cleaned = match_community_features_fixed(X_test_cleaned, community_features, year_columns)\nX_predict_cleaned = match_community_features_fixed(X_predict_cleaned, community_features, year_columns)\n\nprint(f\"处理后训练集行数: {len(X_train_cleaned)}\")\nprint(f\"处理后测试集行数: {len(X_test_cleaned)}\")\nprint(f\"处理后预测集行数: {len(X_predict_cleaned)}\")\n","outputs":[],"execution_count":30},{"cell_type":"code","metadata":{"id":"B2A93FDEFB624B46837493232B488D17","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 处理房屋总数和楼栋总数\ndetails_processed['房屋总数数值'] = details_processed['房屋总数'].apply(lambda x: extract_number(x, '户'))\ndetails_processed['楼栋总数数值'] = details_processed['楼栋总数'].apply(lambda x: extract_number(x, '栋'))\n\n# 准备要匹配的小区特征\ncommunity_features = details_processed[['城市', '名称', 'coord_x', 'coord_y', \n                                      '房屋总数数值', '楼栋总数数值']].copy()\n\n# 处理房屋总数和楼栋总数特征\nhousing_columns = ['房屋总数数值', '楼栋总数数值']\n\n# 保存原始长度，用于验证\ntrain_len_before = len(X_train_cleaned)\ntest_len_before = len(X_test_cleaned)\npredict_len_before = len(X_predict_cleaned)\n\nX_train_cleaned = match_community_features_fixed(X_train_cleaned, community_features, housing_columns)\nX_test_cleaned = match_community_features_fixed(X_test_cleaned, community_features, housing_columns)\nX_predict_cleaned = match_community_features_fixed(X_predict_cleaned, community_features, housing_columns)\n\n# 验证长度是否变化\nprint(f\"处理房屋总数和楼栋总数前后长度变化:\")\nprint(f\"训练集: {train_len_before} -> {len(X_train_cleaned)}\")\nprint(f\"测试集: {test_len_before} -> {len(X_test_cleaned)}\")\nprint(f\"预测集: {predict_len_before} -> {len(X_predict_cleaned)}\")","outputs":[],"execution_count":31},{"cell_type":"code","metadata":{"id":"FDCE65D8C2C44AFA930F33FA3D1BF8B4","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 处理绿化率\ndetails_processed['绿化率数值'] = details_processed['绿 化 率'].apply(lambda x: extract_number(x, '%'))\n\n# 计算板块和城市的绿化率中位数\nplate_green_median = details_processed.groupby(['城市', '板块'])['绿化率数值'].median().reset_index()\nplate_green_median.columns = ['城市', '板块', '板块绿化率中位数']\n\ncity_green_median = details_processed.groupby('城市')['绿化率数值'].median().reset_index()\ncity_green_median.columns = ['城市', '城市绿化率中位数']\n\n# 计算全局绿化率中位数\nglobal_green_median = details_processed['绿化率数值'].median()\n\n# 将中位数合并回details数据集并填充缺失值\ndetails_processed = pd.merge(details_processed, plate_green_median, on=['城市', '板块'], how='left')\ndetails_processed = pd.merge(details_processed, city_green_median, on='城市', how='left')\n\ndetails_processed['绿化率数值'] = details_processed['绿化率数值'].fillna(details_processed['板块绿化率中位数'])\ndetails_processed['绿化率数值'] = details_processed['绿化率数值'].fillna(details_processed['城市绿化率中位数'])\ndetails_processed['绿化率数值'] = details_processed['绿化率数值'].fillna(global_green_median)\n\n# 处理容积率 - 该列已经是数值类型，只需处理缺失值\n# 计算板块和城市的容积率中位数\nplate_vol_median = details_processed.groupby(['城市', '板块'])['容 积 率'].median().reset_index()\nplate_vol_median.columns = ['城市', '板块', '板块容积率中位数']\n\ncity_vol_median = details_processed.groupby('城市')['容 积 率'].median().reset_index()\ncity_vol_median.columns = ['城市', '城市容积率中位数']\n\n# 计算全局容积率中位数\nglobal_vol_median = details_processed['容 积 率'].median()\n\n# 将中位数合并回details数据集并填充缺失值\ndetails_processed = pd.merge(details_processed, plate_vol_median, on=['城市', '板块'], how='left')\ndetails_processed = pd.merge(details_processed, city_vol_median, on='城市', how='left')\n\ndetails_processed['容积率数值'] = details_processed['容 积 率'].fillna(details_processed['板块容积率中位数'])\ndetails_processed['容积率数值'] = details_processed['容积率数值'].fillna(details_processed['城市容积率中位数'])\ndetails_processed['容积率数值'] = details_processed['容积率数值'].fillna(global_vol_median)\n\n# 更新小区特征数据框，加入绿化率和容积率\ncommunity_features = community_features.copy()\ncommunity_features['绿化率数值'] = details_processed['绿化率数值']\ncommunity_features['容积率数值'] = details_processed['容积率数值']\n\n# 处理绿化率和容积率特征\nrate_columns = ['绿化率数值', '容积率数值']\n\n# 保存原始长度，用于验证\ntrain_len_before = len(X_train_cleaned)\ntest_len_before = len(X_test_cleaned)\npredict_len_before = len(X_predict_cleaned)\n\nX_train_cleaned = match_community_features_fixed(X_train_cleaned, community_features, rate_columns)\nX_test_cleaned = match_community_features_fixed(X_test_cleaned, community_features, rate_columns)\nX_predict_cleaned = match_community_features_fixed(X_predict_cleaned, community_features, rate_columns)\n\n# 验证长度是否变化\nprint(f\"处理绿化率容积率前后长度变化:\")\nprint(f\"训练集: {train_len_before} -> {len(X_train_cleaned)}\")\nprint(f\"测试集: {test_len_before} -> {len(X_test_cleaned)}\")\nprint(f\"预测集: {predict_len_before} -> {len(X_predict_cleaned)}\")","outputs":[],"execution_count":32},{"cell_type":"code","metadata":{"id":"25238E6DBB67474DB0F3961A6489D728","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 处理停车位\n# 按房屋总数规模分组，用于填充停车位缺失值\ndef categorize_community_size(house_count):\n    \"\"\"根据房屋总数定义小区规模\"\"\"\n    if pd.isna(house_count):\n        return None\n    elif house_count < 100:\n        return \"小型\"\n    elif house_count < 500:\n        return \"中型\"\n    else:\n        return \"大型\"\n\n# 创建小区规模字段\ndetails_processed['小区规模'] = details_processed['房屋总数数值'].apply(categorize_community_size)\n\n# 按小区规模和城市分组计算停车位中位数\nsize_parking_median = details_processed.groupby(['城市', '小区规模'])['停车位'].median().reset_index()\nsize_parking_median.columns = ['城市', '小区规模', '规模停车位中位数']\n\n# 计算城市停车位中位数\ncity_parking_median = details_processed.groupby('城市')['停车位'].median().reset_index()\ncity_parking_median.columns = ['城市', '城市停车位中位数']\n\n# 计算全局停车位中位数\nglobal_parking_median = details_processed['停车位'].median()\n\n# 将中位数合并回details数据集并填充缺失值\ndetails_processed = pd.merge(details_processed, size_parking_median, on=['城市', '小区规模'], how='left')\ndetails_processed = pd.merge(details_processed, city_parking_median, on='城市', how='left')\n\ndetails_processed['停车位数值'] = details_processed['停车位'].fillna(details_processed['规模停车位中位数'])\ndetails_processed['停车位数值'] = details_processed['停车位数值'].fillna(details_processed['城市停车位中位数'])\ndetails_processed['停车位数值'] = details_processed['停车位数值'].fillna(global_parking_median)\n\n\n# 处理停车费用\ndef extract_parking_fee(fee_info):\n    if not isinstance(fee_info, str):\n        return None\n    \n    # 如果是\"暂无\"或类似无意义值，返回None\n    if fee_info in ['暂无', '无', '-', '/', '——', '免费']:\n        return 0\n    \n    # 尝试提取数值\n    try:\n        # 提取所有数字\n        numbers = re.findall(r'\\d+', fee_info)\n        if numbers:\n            # 如果有多个数字，取第一个\n            return float(numbers[0])\n        return None\n    except:\n        return None\n\ndetails_processed['停车费用数值'] = details_processed['停车费用'].apply(extract_parking_fee)\n\n# 按小区规模和城市分组计算停车费中位数\nsize_fee_median = details_processed.groupby(['城市', '小区规模'])['停车费用数值'].median().reset_index()\nsize_fee_median.columns = ['城市', '小区规模', '规模停车费中位数']\n\n# 计算城市停车费中位数\ncity_fee_median = details_processed.groupby('城市')['停车费用数值'].median().reset_index()\ncity_fee_median.columns = ['城市', '城市停车费中位数']\n\n# 计算全局停车费中位数\nglobal_fee_median = details_processed['停车费用数值'].median()\n\n# 将中位数合并回details数据集并填充缺失值\ndetails_processed = pd.merge(details_processed, size_fee_median, on=['城市', '小区规模'], how='left')\ndetails_processed = pd.merge(details_processed, city_fee_median, on='城市', how='left')\n\ndetails_processed['停车费用数值'] = details_processed['停车费用数值'].fillna(details_processed['规模停车费中位数'])\ndetails_processed['停车费用数值'] = details_processed['停车费用数值'].fillna(details_processed['城市停车费中位数'])\ndetails_processed['停车费用数值'] = details_processed['停车费用数值'].fillna(global_fee_median)\n\n# 更新小区特征数据框，加入停车位和停车费\ncommunity_features = community_features.copy()\ncommunity_features['停车位数值'] = details_processed['停车位数值']\ncommunity_features['停车费用数值'] = details_processed['停车费用数值']\n\n# 处理停车位和停车费特征\nparking_columns = ['停车位数值', '停车费用数值']\n\n# 保存原始长度，用于验证\ntrain_len_before = len(X_train_cleaned)\ntest_len_before = len(X_test_cleaned)\npredict_len_before = len(X_predict_cleaned)\n\nX_train_cleaned = match_community_features_fixed(X_train_cleaned, community_features, parking_columns)\nX_test_cleaned = match_community_features_fixed(X_test_cleaned, community_features, rate_columns)\nX_predict_cleaned = match_community_features_fixed(X_predict_cleaned, community_features, rate_columns)\n\n# 验证长度是否变化\nprint(f\"处理停车位停车费前后长度变化:\")\nprint(f\"训练集: {train_len_before} -> {len(X_train_cleaned)}\")\nprint(f\"测试集: {test_len_before} -> {len(X_test_cleaned)}\")\nprint(f\"预测集: {predict_len_before} -> {len(X_predict_cleaned)}\")","outputs":[],"execution_count":33},{"cell_type":"code","metadata":{"id":"9681DB13DDF44BA3AA9AC8106E1814A8","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 1. 处理租价数据，计算每平米租金\ndef extract_area(area_str):\n    \"\"\"从面积字符串中提取数值\"\"\"\n    if not isinstance(area_str, str):\n        return None\n    \n    # 提取数字部分\n    try:\n        return float(re.sub(r'[^\\d.]', '', area_str))\n    except:\n        return None\n\n# 提取租赁数据中的面积数值\nrent['面积数值'] = rent['面积'].apply(extract_area)\n\n# 计算每平米月租金\nrent['每平米月租金'] = rent.apply(\n    lambda row: row['价格'] / row['面积数值'] if pd.notna(row['面积数值']) and row['面积数值'] > 0 else None,\n    axis=1\n)\n\n# 2. 按小区分组计算每平米租金中位数\n# 先按城市和小区名称分组\nrent_by_community = rent.groupby(['城市', '小区名称'])['每平米月租金'].median().reset_index()\nrent_by_community.columns = ['城市', '小区名称', '每平米月租金中位数']\n\n# 3. 添加经纬度信息用于后续匹配\n# 从租赁数据中提取经纬度信息\ncommunity_coords_rent = rent.groupby(['城市', '小区名称']).agg({\n    'lon': 'mean',\n    'lat': 'mean'\n}).reset_index()\n\n# 合并经纬度信息到特征数据框\nrent_features = pd.merge(\n    rent_by_community,\n    community_coords_rent,\n    on=['城市', '小区名称'],\n    how='left'\n)\n\n# 4. 处理租金特征的缺失值\n# 按城市分组计算中位数\ncity_rent_medians = rent_features.groupby('城市')['每平米月租金中位数'].median().reset_index()\ncity_rent_medians.columns = ['城市', '城市每平米月租金中位数']\n\n# 计算全局中位数\nglobal_rent_median = rent_features['每平米月租金中位数'].median()\n\n# 填充缺失值\nrent_features = pd.merge(rent_features, city_rent_medians, on='城市', how='left')\nrent_features['每平米月租金中位数'] = rent_features['每平米月租金中位数'].fillna(rent_features['城市每平米月租金中位数'])\nrent_features['每平米月租金中位数'] = rent_features['每平米月租金中位数'].fillna(global_rent_median)\n\n# 确保经纬度列名一致\nrent_features = rent_features[['城市', '小区名称', 'lon', 'lat', '每平米月租金中位数']]\n\n# 5. 使用之前定义的匹配函数进行特征合并\n# 修改match_community_features函数以适应当前使用场景\ndef match_community_features(df, community_features, community_column):\n    \"\"\"\n    将小区特征匹配到数据框中，使用经纬度找最近的小区\n    \n    参数:\n    df - 要添加特征的数据框\n    community_features - 包含小区特征的数据框\n    community_column - 要匹配的特征列名\n    \n    返回:\n    添加了特征的数据框\n    \"\"\"\n    # 创建结果数据框的副本，以免修改原始数据\n    result_df = df.copy()\n    \n    # 1. 先按城市和小区名称精确匹配\n    matched_df = pd.merge(\n        result_df, \n        community_features[['城市', '小区名称', community_column]], \n        left_on=['城市', '小区名称'], \n        right_on=['城市', '小区名称'], \n        how='left'\n    )\n    \n    # 2. 对未匹配上的记录，用经纬度找最近的小区\n    missing_mask = matched_df[community_column].isna()\n    \n    if missing_mask.any():\n        # 筛选出有完整特征的记录作为参考\n        reference = community_features.dropna(subset=[community_column, 'lon', 'lat'])\n        \n        # 对每个未匹配的记录找最近的小区\n        for idx in matched_df[missing_mask].index:\n            row = matched_df.loc[idx]\n            \n            # 筛选同城市的小区\n            city_communities = reference[reference['城市'] == row['城市']]\n            \n            if len(city_communities) > 0:\n                # 计算欧氏距离\n                city_communities['distance'] = np.sqrt(\n                    (city_communities['lon'] - row['lon'])**2 + \n                    (city_communities['lat'] - row['lat'])**2\n                )\n                \n                # 找到距离最小的记录\n                nearest_idx = city_communities['distance'].idxmin()\n                nearest = city_communities.loc[nearest_idx]\n                \n                # 更新缺失的特征值\n                matched_df.loc[idx, community_column] = nearest[community_column]\n    \n    # 3. 对仍然缺失的值，使用城市级别中位数填充\n    still_missing = matched_df[community_column].isna()\n    \n    if still_missing.any():\n        for city in matched_df['城市'].unique():\n            if city in city_rent_medians['城市'].values:\n                city_median = city_rent_medians[city_rent_medians['城市'] == city]['城市每平米月租金中位数'].values[0]\n                city_mask = (matched_df['城市'] == city) & matched_df[community_column].isna()\n                matched_df.loc[city_mask, community_column] = city_median\n    \n    # 4. 最后使用全局中位数填充剩余缺失值\n    matched_df[community_column] = matched_df[community_column].fillna(global_rent_median)\n    \n    return matched_df\n\n# 6. 应用匹配函数\nprint(\"开始处理训练集...\")\nX_train_cleaned = match_community_features(X_train_cleaned, rent_features, '每平米月租金中位数')\n\nprint(\"开始处理测试集...\")\nX_test_cleaned = match_community_features(X_test_cleaned, rent_features, '每平米月租金中位数')\n\nprint(\"开始处理预测集...\")\nX_predict_cleaned = match_community_features(X_predict_cleaned, rent_features, '每平米月租金中位数')\n","outputs":[],"execution_count":34},{"cell_type":"code","metadata":{"id":"A67EB236B15A466DA5080A5FD7EC1C5B","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"print(f\"原始X_predict行数: {len(X_train)}\")\nprint(f\"处理后X_predict_cleaned行数: {len(X_train_cleaned)}\")","outputs":[],"execution_count":35},{"cell_type":"code","metadata":{"id":"C9CA0B85D00D4CF4B39827312A9CD816","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 设置新数据框临时存储数据\ndf_train_time = pd.DataFrame()\ndf_test_time = pd.DataFrame()\ndf_predict_time = pd.DataFrame()\n\n# 定义周期性转换函数\ndef create_cyclic_features(df, column, period):\n    df[f'{column}_sin'] = np.sin(2 * np.pi * df[column] / period)\n    df[f'{column}_cos'] = np.cos(2 * np.pi * df[column] / period)\n\n# 转换“交易时间”和“上次交易”列为日期格式\nX_train['交易时间'] = pd.to_datetime(X_train['交易时间'], errors='coerce')\nX_test['交易时间'] = pd.to_datetime(X_test['交易时间'], errors='coerce')\nX_predict['交易时间'] = pd.to_datetime(X_predict['交易时间'], errors='coerce')\n\nX_train['上次交易'] = pd.to_datetime(X_train['上次交易'], errors='coerce')\nX_test['上次交易'] = pd.to_datetime(X_test['上次交易'], errors='coerce')\nX_predict['上次交易'] = pd.to_datetime(X_predict['上次交易'], errors='coerce')\n\n# 提取时间特征（交易时间）\ndf_train_time['交易年份'] = X_train['交易时间'].dt.year\ndf_train_time['交易月份'] = X_train['交易时间'].dt.month\ndf_train_time['交易季度'] = X_train['交易时间'].dt.quarter\n\ndf_test_time['交易年份'] = X_test['交易时间'].dt.year\ndf_test_time['交易月份'] = X_test['交易时间'].dt.month\ndf_test_time['交易季度'] = X_test['交易时间'].dt.quarter\n\ndf_predict_time['交易年份'] = X_predict['交易时间'].dt.year\ndf_predict_time['交易月份'] = X_predict['交易时间'].dt.month\ndf_predict_time['交易季度'] = X_predict['交易时间'].dt.quarter\n\n# 对月份和季度进行周期性转换\ncreate_cyclic_features(df_train_time, '交易月份', 12)\ncreate_cyclic_features(df_train_time, '交易季度', 4)\n\ncreate_cyclic_features(df_test_time, '交易月份', 12)\ncreate_cyclic_features(df_test_time, '交易季度', 4)\n\ncreate_cyclic_features(df_predict_time, '交易月份', 12)\ncreate_cyclic_features(df_predict_time, '交易季度', 4)\n\n# 处理上次交易列，生成是否有上次交易记录的标记列\ndf_train_time['有上次交易'] = X_train['上次交易'].notnull().astype(int)\ndf_test_time['有上次交易'] = X_test['上次交易'].notnull().astype(int)\ndf_predict_time['有上次交易'] = X_predict['上次交易'].notnull().astype(int)\n\n# 对于有交易记录的行，继续提取和转换时间特征\ndf_train_time['上次交易年份'] = X_train['上次交易'].dt.year.fillna(0)  # 无交易填充为0\ndf_train_time['上次交易月份'] = X_train['上次交易'].dt.month.fillna(0)\ndf_train_time['上次交易季度'] = X_train['上次交易'].dt.quarter.fillna(0)\n\ndf_test_time['上次交易年份'] = X_test['上次交易'].dt.year.fillna(0)\ndf_test_time['上次交易月份'] = X_test['上次交易'].dt.month.fillna(0)\ndf_test_time['上次交易季度'] = X_test['上次交易'].dt.quarter.fillna(0)\n\ndf_predict_time['上次交易年份'] = X_predict['上次交易'].dt.year.fillna(0)\ndf_predict_time['上次交易月份'] = X_predict['上次交易'].dt.month.fillna(0)\ndf_predict_time['上次交易季度'] = X_predict['上次交易'].dt.quarter.fillna(0)\n\n# 对上次交易的月份和季度进行周期性转换，排除无交易记录的行\ncreate_cyclic_features(df_train_time, '上次交易月份', 12)\ncreate_cyclic_features(df_train_time, '上次交易季度', 4)\n\ncreate_cyclic_features(df_test_time, '上次交易月份', 12)\ncreate_cyclic_features(df_test_time, '上次交易季度', 4)\n\ncreate_cyclic_features(df_predict_time, '上次交易月份', 12)\ncreate_cyclic_features(df_predict_time, '上次交易季度', 4)\n\n# 保留与建模相关的列（年份、周期性特征，和是否有上次交易记录的标记）\nX_train_cleaned[\n    ['交易年份', '交易月份_sin', '交易月份_cos', '交易季度_sin', '交易季度_cos', \n     '有上次交易', '上次交易年份', '上次交易月份_sin', '上次交易月份_cos', \n     '上次交易季度_sin', '上次交易季度_cos']\n] = df_train_time[\n    ['交易年份', '交易月份_sin', '交易月份_cos', '交易季度_sin', '交易季度_cos', \n     '有上次交易', '上次交易年份', '上次交易月份_sin', '上次交易月份_cos', \n     '上次交易季度_sin', '上次交易季度_cos']\n]\n\nX_test_cleaned[\n    ['交易年份', '交易月份_sin', '交易月份_cos', '交易季度_sin', '交易季度_cos', \n     '有上次交易', '上次交易年份', '上次交易月份_sin', '上次交易月份_cos', \n     '上次交易季度_sin', '上次交易季度_cos']\n] = df_test_time[\n    ['交易年份', '交易月份_sin', '交易月份_cos', '交易季度_sin', '交易季度_cos', \n     '有上次交易', '上次交易年份', '上次交易月份_sin', '上次交易月份_cos', \n     '上次交易季度_sin', '上次交易季度_cos']\n]\n\nX_predict_cleaned[\n    ['交易年份', '交易月份_sin', '交易月份_cos', '交易季度_sin', '交易季度_cos', \n     '有上次交易', '上次交易年份', '上次交易月份_sin', '上次交易月份_cos', \n     '上次交易季度_sin', '上次交易季度_cos']\n] = df_predict_time[\n    ['交易年份', '交易月份_sin', '交易月份_cos', '交易季度_sin', '交易季度_cos', \n     '有上次交易', '上次交易年份', '上次交易月份_sin', '上次交易月份_cos', \n     '上次交易季度_sin', '上次交易季度_cos']\n]\n\n\n# 查看处理后的结果\nprint(X_train_cleaned.head())\nprint(X_test_cleaned.head())\n","outputs":[],"execution_count":36},{"cell_type":"code","metadata":{"id":"981C0B9169FD4003BE32A1E473E3410D","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"print(X_train_cleaned.isnull().sum())\nprint(X_test_cleaned.isnull().sum())\nprint(X_predict_cleaned.isnull().sum())","outputs":[],"execution_count":37},{"cell_type":"code","metadata":{"id":"3780DE5A4EDD4C408953713F4A9AD6AA","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 修复代码 - 处理上次交易和当前交易时间特征的缺失值\n\n# 1. 处理上次交易时间特征的缺失值\nfor col in ['上次交易年份', '上次交易月份_sin', '上次交易月份_cos', '上次交易季度_sin', '上次交易季度_cos']:\n    # 对于已经标记为无上次交易的记录，使用默认值填充\n    X_train_cleaned[col] = X_train_cleaned[col].fillna(0)\n\n# 2. 处理当前交易时间特征的缺失值 (这是之前缺失的部分)\nfor col in ['交易年份', '交易月份_sin', '交易月份_cos', '交易季度_sin', '交易季度_cos']:\n    # 使用合适的默认值填充\n    if col == '交易年份':\n        # 使用数据集的年份中位数填充\n        median_year = X_train_cleaned['交易年份'].median()\n        X_train_cleaned[col] = X_train_cleaned[col].fillna(median_year)\n\n    elif col.endswith('_cos'):\n        # cos(0) = 1 作为默认值，相当于第一个月或第一个季度\n        X_train_cleaned[col] = X_train_cleaned[col].fillna(1)\n\n    else:\n        # sin(0) = 0 作为默认值\n        X_train_cleaned[col] = X_train_cleaned[col].fillna(0)\n\n\n# 3. 确保有上次交易标记列没有缺失值\nX_train_cleaned['有上次交易'] = X_train_cleaned['有上次交易'].fillna(0)\n\n\n# 4. 检查修复后的结果\nprint(\"修复后训练集缺失值:\")\nprint(X_train_cleaned[['有上次交易', '上次交易年份', '上次交易月份_sin', '交易年份', '交易月份_sin', '交易季度_sin']].isnull().sum())\nprint(\"\\n修复后测试集缺失值:\")\nprint(X_test_cleaned[['有上次交易', '上次交易年份', '上次交易月份_sin', '交易年份', '交易月份_sin', '交易季度_sin']].isnull().sum())\nprint(\"\\n修复后预测集缺失值:\")\nprint(X_predict_cleaned[['有上次交易', '上次交易年份', '上次交易月份_sin', '交易年份', '交易月份_sin', '交易季度_sin']].isnull().sum())\n\n# 5. 检查全局缺失值情况\nprint(\"\\n各数据集整体缺失值情况：\")\nprint(f\"训练集缺失值总数: {X_train_cleaned.isnull().sum().sum()}\")\nprint(f\"测试集缺失值总数: {X_test_cleaned.isnull().sum().sum()}\")\nprint(f\"预测集缺失值总数: {X_predict_cleaned.isnull().sum().sum()}\")","outputs":[],"execution_count":38},{"cell_type":"code","metadata":{"id":"9CCDA33DC3D94A649DBFFE5858E8275B","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 1. 处理分类变量\n# 定义需要虚拟变量化的定性变量\ncategorical_columns = ['城市', '区域', '板块']\n\n# 对训练集和测试集的指定列进行虚拟变量化，并替换原列\nfor col in categorical_columns:\n    # 对训练集进行虚拟变量化，并用虚拟变量替换原列\n    dummies_train = pd.get_dummies(X_train_cleaned[col], prefix=col, drop_first=True)\n    X_train_cleaned = pd.concat([X_train_cleaned.drop(columns=[col]), dummies_train], axis=1)\n    \n    # 对测试集进行虚拟变量化，并用虚拟变量替换原列\n    dummies_test = pd.get_dummies(X_test_cleaned[col], prefix=col, drop_first=True)\n    X_test_cleaned = pd.concat([X_test_cleaned.drop(columns=[col]), dummies_test], axis=1)\n\n    dummies_predict = pd.get_dummies(X_predict_cleaned[col], prefix=col, drop_first=True)\n    X_predict_cleaned = pd.concat([X_predict_cleaned.drop(columns=[col]), dummies_predict], axis=1)\n\n\n# 保证测试集和训练集列一致（如果有不匹配列，测试集中缺少的列用0填充）\nX_test_cleaned = X_test_cleaned.reindex(columns=X_train_cleaned.columns, fill_value=0)\nX_predict_cleaned = X_predict_cleaned.reindex(columns=X_train_cleaned.columns, fill_value=0)\n\n# 将所有布尔列转换为整数\nbool_columns = X_train_cleaned.select_dtypes(include=['bool']).columns\nfor df in [X_train_cleaned, X_test_cleaned, X_predict_cleaned]:\n    df[bool_columns] = df[bool_columns].astype(int)\n    \n# 删除小区名称列\nX_train_cleaned = X_train_cleaned.drop(columns=['小区名称'])\nX_test_cleaned = X_test_cleaned.drop(columns=['小区名称'])\nX_predict_cleaned = X_predict_cleaned.drop(columns=['小区名称'])\n\n# 查看替换后的数据框结构\nprint(X_train_cleaned.head())\nprint(X_test_cleaned.head())\nprint(X_predict_cleaned.head())","outputs":[],"execution_count":39},{"cell_type":"code","metadata":{"id":"0CED14B9A4E349A1ADECE041E3DF7CC1","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":true,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 基于领域知识创建交互项和多项式特征\n\n# 首先，确保数据中没有重复列名\nprint(\"当前数据集中的列数:\", len(X_train_cleaned.columns))\nprint(\"当前数据集中的唯一列数:\", len(set(X_train_cleaned.columns)))\n\n# 由于没有重复列，直接复制DataFrame以避免性能警告\nX_train_no_dupes = X_train_cleaned.copy()\nX_test_no_dupes = X_test_cleaned.copy()\nX_predict_no_dupes = X_predict_cleaned.copy()\n\n# 使用处理后的数据框\nX_train_cleaned = X_train_no_dupes\nX_test_cleaned = X_test_no_dupes\nX_predict_cleaned = X_predict_no_dupes\n\nprint(\"处理后的数据集中的列数:\", len(X_train_cleaned.columns))\n\n# 选择用于创建交互项的最重要数值特征\nkey_features = ['建筑面积', '套内面积', '室', '厅', '卫', '楼龄', '梯户比例',\n                '楼层数值', '总层数', '每平米月租金中位数', 'lon', 'lat']\n\n# 过滤掉可能不在数据集中的关键特征\nkey_features = [f for f in key_features if f in X_train_cleaned.columns]\n\n# 确保所有特征为数值类型并处理缺失值\nfor feature in key_features:\n    for df in [X_train_cleaned, X_test_cleaned, X_predict_cleaned]:\n        df[feature] = pd.to_numeric(df[feature], errors='coerce')\n        df[feature] = df[feature].fillna(df[feature].median())\n\nif len(key_features) >= 2:\n    # 限制特征数量，避免生成太多多项式特征\n    if len(key_features) > 4:\n        # 选择最重要的特征，这里使用前4个作为示例\n        key_features = key_features[:4]\n    \n    print(f\"使用的关键特征: {key_features}\")\n    \n    # 提取关键特征\n    X_key_features_train = X_train_cleaned[key_features]\n    X_key_features_test = X_test_cleaned[key_features]\n    X_key_features_predict = X_predict_cleaned[key_features]\n    \n    # 创建多项式特征（仅交互项）\n    from sklearn.preprocessing import PolynomialFeatures\n    poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n    \n    # 转换数据\n    poly_features_train = poly.fit_transform(X_key_features_train)\n    poly_features_test = poly.transform(X_key_features_test)\n    poly_features_predict = poly.transform(X_key_features_predict)\n    \n    # 获取特征名称\n    feature_names = poly.get_feature_names_out(key_features)\n    # 添加前缀\n    poly_feature_names = [f'poly_{name}' for name in feature_names]\n    \n    # 创建DataFrame\n    poly_features_train_df = pd.DataFrame(poly_features_train, columns=poly_feature_names, index=X_train_cleaned.index)\n    poly_features_test_df = pd.DataFrame(poly_features_test, columns=poly_feature_names, index=X_test_cleaned.index)\n    poly_features_predict_df = pd.DataFrame(poly_features_predict, columns=poly_feature_names, index=X_predict_cleaned.index)\n    \n    # 连接特征\n    X_train_cleaned = pd.concat([X_train_cleaned, poly_features_train_df], axis=1)\n    X_test_cleaned = pd.concat([X_test_cleaned, poly_features_test_df], axis=1)\n    X_predict_cleaned = pd.concat([X_predict_cleaned, poly_features_predict_df], axis=1)\n    \n    print(f\"添加了{poly_features_train_df.shape[1]}个多项式和交互特征\")\n\n# 添加领域特征，更安全的实现方式\n# 每平米价格\nif '建筑面积' in X_train_cleaned.columns and '每平米月租金中位数' in X_train_cleaned.columns:\n    try:\n        X_train_cleaned['租金估值'] = X_train_cleaned['建筑面积'] * X_train_cleaned['每平米月租金中位数']\n        X_test_cleaned['租金估值'] = X_test_cleaned['建筑面积'] * X_test_cleaned['每平米月租金中位数']\n        X_predict_cleaned['租金估值'] = X_predict_cleaned['建筑面积'] * X_predict_cleaned['每平米月租金中位数']\n        print(\"成功添加：租金估值\")\n    except Exception as e:\n        print(f\"添加租金估值时出错: {e}\")\n\n# 房间密度\nif '室' in X_train_cleaned.columns and '建筑面积' in X_train_cleaned.columns:\n    try:\n        # 避免除以零\n        X_train_cleaned['房间密度'] = X_train_cleaned['室'] / X_train_cleaned['建筑面积'].replace(0, float('nan'))\n        X_test_cleaned['房间密度'] = X_test_cleaned['室'] / X_test_cleaned['建筑面积'].replace(0, float('nan'))\n        X_predict_cleaned['房间密度'] = X_predict_cleaned['室'] / X_predict_cleaned['建筑面积'].replace(0, float('nan'))\n        \n        # 填充可能出现的无穷值或NaN\n        for df in [X_train_cleaned, X_test_cleaned, X_predict_cleaned]:\n            df['房间密度'].replace([float('inf'), float('-inf')], float('nan'), inplace=True)\n            df['房间密度'].fillna(df['房间密度'].median(), inplace=True)\n            \n        print(\"成功添加：房间密度\")\n    except Exception as e:\n        print(f\"添加房间密度时出错: {e}\")\n\n# 相对楼层\nif '楼层数值' in X_train_cleaned.columns and '总层数' in X_train_cleaned.columns:\n    try:\n        # 避免除以零\n        X_train_cleaned['相对楼层'] = X_train_cleaned['楼层数值'] / X_train_cleaned['总层数'].replace(0, float('nan'))\n        X_test_cleaned['相对楼层'] = X_test_cleaned['楼层数值'] / X_test_cleaned['总层数'].replace(0, float('nan'))\n        X_predict_cleaned['相对楼层'] = X_predict_cleaned['楼层数值'] / X_predict_cleaned['总层数'].replace(0, float('nan'))\n        \n        # 填充可能出现的无穷值或NaN\n        for df in [X_train_cleaned, X_test_cleaned, X_predict_cleaned]:\n            df['相对楼层'].replace([float('inf'), float('-inf')], float('nan'), inplace=True)\n            df['相对楼层'].fillna(df['相对楼层'].median(), inplace=True)\n            \n        print(\"成功添加：相对楼层\")\n    except Exception as e:\n        print(f\"添加相对楼层时出错: {e}\")\n\n# 得房率\nif '套内面积' in X_train_cleaned.columns and '建筑面积' in X_train_cleaned.columns:\n    try:\n        # 避免除以零\n        X_train_cleaned['得房率'] = X_train_cleaned['套内面积'] / X_train_cleaned['建筑面积'].replace(0, float('nan'))\n        X_test_cleaned['得房率'] = X_test_cleaned['套内面积'] / X_test_cleaned['建筑面积'].replace(0, float('nan'))\n        X_predict_cleaned['得房率'] = X_predict_cleaned['套内面积'] / X_predict_cleaned['建筑面积'].replace(0, float('nan'))\n        \n        # 限制在合理范围内（得房率通常不超过1）\n        for df in [X_train_cleaned, X_test_cleaned, X_predict_cleaned]:\n            df['得房率'].replace([float('inf'), float('-inf')], float('nan'), inplace=True)\n            df['得房率'] = df['得房率'].clip(0, 1)  # 限制在0-1之间\n            df['得房率'].fillna(df['得房率'].median(), inplace=True)\n            \n        print(\"成功添加：得房率\")\n    except Exception as e:\n        print(f\"添加得房率时出错: {e}\")\n\nprint(\"所有特征处理完成\")","outputs":[],"execution_count":40},{"cell_type":"code","metadata":{"id":"338F9542716841178AE28E355E31E040","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 获取原始y_train的索引\noriginal_indices = y_train.index\n\n# 如果X_train_cleaned包含这些索引（即使顺序不同），则可以重新对齐\nif set(original_indices).issubset(set(X_train_cleaned.index)):\n    X_train_cleaned = X_train_cleaned.loc[original_indices]\n    print(\"已重新对齐X_train_cleaned到y_train的索引\")\nelse:\n    # 找出哪些索引丢失了\n    missing_indices = set(original_indices) - set(X_train_cleaned.index)\n    print(f\"有{len(missing_indices)}个在y_train中的索引在X_train_cleaned中丢失\")","outputs":[],"execution_count":41},{"cell_type":"code","metadata":{"id":"9DADBCCA8AA142DAA55D52FD9DDED3ED","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"print(len(X_train_cleaned))\nprint(len(X_test_cleaned))\nprint(len(X_predict_cleaned))\n\nprint(len(y_train))\nprint(len(y_test))\n","outputs":[],"execution_count":42},{"cell_type":"code","metadata":{"id":"75645156E7AD4B02854315CBFE548F75","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 检查测试集的索引情况\nprint(f\"X_test_cleaned 索引是否有重复: {X_test_cleaned.index.duplicated().any()}\")\nprint(f\"y_test 索引是否有重复: {y_test.index.duplicated().any()}\")\n\n# 比较 X_test_cleaned 和 y_test 的索引\nprint(f\"X_test_cleaned 和 y_test 索引相同的数量: {len(set(X_test_cleaned.index) & set(y_test.index))}\")\nprint(f\"X_test_cleaned 中多出的索引数量: {len(set(X_test_cleaned.index) - set(y_test.index))}\")\n\n# 使用 y_test 的索引重新对齐 X_test_cleaned\nif set(y_test.index).issubset(set(X_test_cleaned.index)):\n    X_test_cleaned = X_test_cleaned.loc[y_test.index]\n    print(\"已重新对齐 X_test_cleaned 到 y_test 的索引\")\nelse:\n    # 使用两者共同的索引\n    common_indices_test = X_test_cleaned.index.intersection(y_test.index)\n    X_test_cleaned = X_test_cleaned.loc[common_indices_test]\n    y_test = y_test.loc[common_indices_test]\n    print(f\"使用交集重新对齐后，X_test_cleaned: {len(X_test_cleaned)}, y_test: {len(y_test)}\")","outputs":[],"execution_count":43},{"cell_type":"code","metadata":{"id":"4F7DBA5C2CDF4A5E840D7B246EDE5A2C","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 在完成数据清洗和特征工程后，添加这段代码来查看样本量\nprint(\"数据处理后的样本量统计：\")\nprint(f\"处理后训练集样本量: {len(X_train_cleaned)}\")\nprint(f\"处理后测试集样本量: {len(X_test_cleaned)}\")\nprint(f\"处理后预测集样本量: {len(X_predict_cleaned)}\")\n\n# 检查是否有缺失值导致样本减少\nprint(\"\\n各数据集缺失值情况：\")\nprint(f\"训练集缺失值: {X_train_cleaned.isnull().sum().sum()}\")\nprint(f\"测试集缺失值: {X_test_cleaned.isnull().sum().sum()}\")\nprint(f\"预测集缺失值: {X_predict_cleaned.isnull().sum().sum()}\")","outputs":[],"execution_count":44},{"cell_type":"code","metadata":{"id":"A0051B46CA134A43BEDAEE5DFDCAA395","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 1. 定义需要标准化的定量特征列\nquantitative_columns = [\n    'lon', 'lat', '年份', '建筑面积', '套内面积', '室', '厅', '厨', '卫',\n    '楼层数值', '总层数', '梯户比例', '交易年份', '交易月份_sin', '交易月份_cos',\n    '交易季度_sin', '交易季度_cos', '上次交易年份', '上次交易月份_sin',\n    '上次交易月份_cos', '上次交易季度_sin', '上次交易季度_cos'\n]\n\n# 2. 添加已创建的领域特征\ndomain_features = [\n    '租金估值', '房间密度', '相对楼层', '得房率'\n]\n# 过滤存在的列\ndomain_features = [col for col in domain_features if col in X_train_cleaned.columns]\n\n# 3. 识别交互项和多项式特征\npoly_features = [col for col in X_train_cleaned.columns if col.startswith('poly_')]\n\n# 4. 识别Word2Vec特征\nword2vec_cols = [col for col in X_train_cleaned.columns if \n                any(col.startswith(f\"{feature}_word2vec_\") for feature in \n                   ['核心卖点', '户型介绍', '周边配套', '交通出行']) or\n                any(col.startswith(f\"{feature}\") and '_word2vec_' in col for feature in \n                   ['核心卖点', '户型介绍', '周边配套', '交通出行'])]\n\n# 5. 合并所有需要标准化的列\nnumeric_cols = [col for col in quantitative_columns if col in X_train_cleaned.columns]\ncols_to_standardize = numeric_cols + domain_features + poly_features + word2vec_cols\n\nprint(f\"将要标准化的特征数量: {len(cols_to_standardize)}\")\n\n# 6. 初始化标准化器并拟合训练集\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X_train_cleaned[cols_to_standardize])\n\n# 7. 对数据集进行标准化\nX_train_standardized = X_train_cleaned.copy()\nX_test_standardized = X_test_cleaned.copy()\nX_predict_standardized = X_predict_cleaned.copy()\n\nX_train_standardized[cols_to_standardize] = scaler.transform(X_train_cleaned[cols_to_standardize])\nX_test_standardized[cols_to_standardize] = scaler.transform(X_test_cleaned[cols_to_standardize])\nX_predict_standardized[cols_to_standardize] = scaler.transform(X_predict_cleaned[cols_to_standardize])\n\n# 8. 打印标准化后的前五行\nprint(\"标准化后的训练集前五行:\")\nprint(X_train_standardized[cols_to_standardize].head())","outputs":[],"execution_count":45},{"cell_type":"code","metadata":{"id":"B2F4995D10DB427C832C6BE9709D32F6","notebookId":"67ec17035302e998c321293b","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 储存数据，以待后续使用\nX_train_cleaned.to_csv('/home/mw/temp/X_train_cleaned.csv', index=False, encoding='utf-8-sig')\nX_test_cleaned.to_csv('/home/mw/temp/X_test_cleaned.csv', index=False, encoding='utf-8-sig')\nX_predict_cleaned.to_csv('/home/mw/temp/X_predict_cleaned.csv', index=False, encoding='utf-8-sig')\n\nprint(\"\\n数据已成功保存到 /home/mw/temp/ 目录下\")\n\n# 存储对应的y值\ny_train.to_csv('/home/mw/temp/y_train.csv', index=False)\ny_test.to_csv('/home/mw/temp/y_test.csv', index=False)\n\nprint(\"标签数据也已保存\")","outputs":[],"execution_count":46}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":0}