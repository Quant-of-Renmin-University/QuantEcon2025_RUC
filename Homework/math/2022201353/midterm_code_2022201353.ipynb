{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "586495ac-7f38-4608-9562-d4dadfece13c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cn2an'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m  \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcn2an\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV, KFold\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_scorer\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cn2an'"
     ]
    }
   ],
   "source": [
    "import  pandas as pd\n",
    "import re\n",
    "import cn2an\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import make_scorer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 1. 数据加载与合并\n",
    "train = pd.read_csv('ruc_Class25Q1_train.csv')\n",
    "test = pd.read_csv('ruc_Class25Q1_test.csv')\n",
    "details = pd.read_csv('ruc_Class25Q1_details.csv')\n",
    "rent = pd.read_csv('ruc_Class25Q1_rent.csv')\n",
    "# 合并小区详细信息\n",
    "train = train.merge(details, how='left',\n",
    "                    left_on=['小区名称', '区域', '城市'],\n",
    "                    right_on=['名称', '区县', '城市'])\n",
    "\n",
    "test = test.merge(details, how='left',\n",
    "                  left_on=['小区名称', '区域', '城市'],\n",
    "                  right_on=['名称', '区县', '城市'])\n",
    "\n",
    "#生成城市独热变量X1\n",
    "X_1 = pd.get_dummies(train['城市'], prefix='X_1', dtype=int, drop_first=True)\n",
    "\n",
    "#生成楼层变量X2\n",
    "def parse_floor(floor_str):\n",
    "    match = re.search(r'^(.+?)\\s*\\(共(\\d+)层\\)$', floor_str)\n",
    "    if match:\n",
    "        desc = match.group(1).strip()  # 楼层描述（中楼层/顶层/底层等）\n",
    "        total = int(match.group(2))    # 总楼层数\n",
    "        return desc, total\n",
    "    return None, None  # 处理格式错误的情况\n",
    "\n",
    "def get_floor_value(desc, total):\n",
    "    # 将输入转换为Series（如果是单个值也会被转换）\n",
    "    desc_series = pd.Series(desc).astype(str).str.strip()\n",
    "    total_series = pd.Series(total).fillna(1).astype(int)\n",
    "    result = pd.Series(np.nan, index=desc_series.index)\n",
    "    # 处理地下室（优先级最高）\n",
    "    basement_mask = desc_series.str.contains(\"地下室\", na=False)\n",
    "    result[basement_mask] = 0.0\n",
    "    # 确保总层数至少为1\n",
    "    total_series = total_series.clip(lower=1)\n",
    "    # 处理其他楼层类型\n",
    "    masks = {\n",
    "        \"底层\": (1 / total_series).round(4),\n",
    "        \"顶层\": 1.0,\n",
    "        \"低楼层\": ((1 + total_series / 3) / (2 * total_series)).round(4),\n",
    "        \"中楼层\": ((total_series / 3) + (2 * total_series / 3) ) / (2 * total_series).round(4),\n",
    "        \"高楼层\": ((2 * total_series / 3 + total_series) / (2 * total_series)).round(4)\n",
    "    }\n",
    "    for pattern, value in masks.items():\n",
    "        mask = desc_series.str.contains(pattern, na=False) & ~basement_mask\n",
    "        result[mask] = value if isinstance(value, (int, float)) else value[mask]\n",
    "    # 填充默认值（未匹配任何模式的情况）\n",
    "    result.fillna(0.5, inplace=True)\n",
    "    return result.values  # 返回numpy数组\n",
    "parsed_data_2 = [parse_floor(item) for item in train['所在楼层']]\n",
    "X_2_df = pd.DataFrame(parsed_data_2, columns=['desc', 'total'])\n",
    "X_2 = get_floor_value(X_2_df['desc'], X_2_df['total'])\n",
    "X_2 = pd.Series(get_floor_value(X_2_df['desc'], X_2_df['total']), name='楼层系数')\n",
    "\n",
    "#生成户型变量X3\n",
    "def parse_layout(layout_str):\n",
    "    # 类型检查 + 缺失值处理\n",
    "    if pd.isna(layout_str) or not isinstance(layout_str, str):\n",
    "        return {\n",
    "            'bedrooms': 0,\n",
    "            'living_rooms': 0,\n",
    "            'kitchens': 0,\n",
    "            'bathrooms': 0\n",
    "        }\n",
    "    # 统一术语\n",
    "    layout_str = str(layout_str).replace(\"房间\", \"室\")\n",
    "    # 正则匹配\n",
    "    pattern = r'(\\d+)室(\\d+)厅(\\d+)厨(\\d+)卫'\n",
    "    match = re.search(pattern, layout_str)\n",
    "    if match:\n",
    "        return {\n",
    "            'bedrooms': int(match.group(1)),\n",
    "            'living_rooms': int(match.group(2)),\n",
    "            'kitchens': int(match.group(3)),\n",
    "            'bathrooms': int(match.group(4))\n",
    "        }\n",
    "    else:\n",
    "        # 处理简写格式\n",
    "        alt_match = re.search(r'(\\d+)室?.*?(\\d+)卫', layout_str)\n",
    "        return {\n",
    "            'bedrooms': int(alt_match.group(1)) if alt_match else 0,\n",
    "            'living_rooms': 1 if '厅' in layout_str else 0,\n",
    "            'kitchens': 1 if '厨' in layout_str else 0,\n",
    "            'bathrooms': int(alt_match.group(2)) if alt_match else 0\n",
    "        }\n",
    "parsed_data_3 = [parse_layout(item) for item in train['房屋户型']]\n",
    "X_3 = pd.DataFrame([x for x in parsed_data_3 if x is not None])\n",
    "\n",
    "#生成得房率变量X4，缺失处用城市平均得房率替代\n",
    "def clean_area(series):\n",
    "    # 移除所有非数字字符（包括㎡等单位）\n",
    "    return (\n",
    "        series.astype(str)\n",
    "        .str.replace(r'[^\\d.]', '', regex=True)  # 只保留数字和点\n",
    "        .replace('', np.nan)  # 空字符串转为NaN\n",
    "        .astype(float)  # 转换为浮点数\n",
    "    )\n",
    "def calculate_efficiency(df):\n",
    "    # 基础计算\n",
    "    df['得房率'] = df['套内面积'] / df['建筑面积']\n",
    "    # 计算城市平均值\n",
    "    city_avg = df.groupby('城市')['得房率'].mean()\n",
    "    # 填充缺失值\n",
    "    df['得房率_修正'] = df.apply(\n",
    "        lambda row: city_avg[row['城市']] if pd.isna(row['得房率']) else row['得房率'],\n",
    "        axis=1\n",
    "    )\n",
    "    # 处理城市标记缺失的情况（用全局平均值）\n",
    "    global_avg = df['得房率'].mean()\n",
    "    df['得房率_修正'] = df['得房率_修正'].fillna(global_avg)\n",
    "    return df\n",
    "train['建筑面积'] = clean_area(train['建筑面积'])\n",
    "train['套内面积'] = clean_area(train['套内面积'])\n",
    "X_4 = calculate_efficiency(train)\n",
    "\n",
    "#生成房屋朝向变量X5，朝南标记为1，其余为0\n",
    "def process_direction(df):\n",
    "    # 基础朝南标记\n",
    "    df_value = df.str.contains('南').astype(int)\n",
    "    return df_value\n",
    "X_5 = process_direction(train['房屋朝向'])\n",
    "\n",
    "#生成装修情况变量X6,发现缺失值都是地下室，那么直接标记为1，等同毛坯\n",
    "def process_renovation(df):\n",
    "    # 基础编码\n",
    "    df_re = df.map({\n",
    "        '毛坯': 0,\n",
    "        '简装': 0.5,\n",
    "        '精装': 1,\n",
    "        '其它': 0.1\n",
    "    }).fillna(0)  # 缺失值填充为1\n",
    "    return df_re\n",
    "X_6 = process_renovation(train['装修情况'])\n",
    "\n",
    "#生成梯户比X7，公式为户/梯\n",
    "def parse_ratio(text):\n",
    "    if pd.isna(text):\n",
    "        return 0  # 直接返回0\n",
    "\n",
    "    try:\n",
    "        ti = cn2an.cn2an(text.split('梯')[0], \"smart\")  # 梯数\n",
    "        hu = cn2an.cn2an(text.split('户')[0].split('梯')[1], \"smart\")  # 户数\n",
    "        return round(hu / ti, 2) if ti != 0 else 0\n",
    "    except:\n",
    "        return 0  # 解析失败也返回0\n",
    "X_7 = train['梯户比例'].apply(parse_ratio)\n",
    "\n",
    "#生成变量X8，是否电梯\n",
    "def process_elevator(df):\n",
    "    return (df == '有').fillna(0).astype(int)\n",
    "X_8 = process_elevator(train['配备电梯'])\n",
    "\n",
    "#生成变量X9,别墅类型\n",
    "def villa_value(df):\n",
    "    filled = df.fillna('NA').astype(str)\n",
    "    return np.select(\n",
    "        condlist=[\n",
    "            filled.str.contains('拼'),\n",
    "            filled.str.contains('排'),\n",
    "            filled.str.contains('独')\n",
    "        ],\n",
    "        choicelist=[1.0, 2.0, 3.0],\n",
    "        default=0.0\n",
    "    )\n",
    "X_9 = villa_value(train['别墅类型'])\n",
    "\n",
    "#生成变量X10，房屋用途\n",
    "housing_keywords = [\n",
    "    '普通住宅', '公寓/住宅', '公寓', '公寓（住宅）', '公寓/公寓', '住宅式公寓',\n",
    "    '别墅', '四合院', '平房', '老公寓', '新式里弄', '花园洋房'\n",
    "]\n",
    "X_10 = train['房屋用途'].isin(housing_keywords).astype(int)\n",
    "\n",
    "#生成变量X11，交易权属\n",
    "property_score_map = {\n",
    "    '商品房': 1.00,\n",
    "    '私产': 0.95,\n",
    "    '已购公房': 0.70,\n",
    "    '房改房': 0.65,\n",
    "    '央产房': 0.60,\n",
    "    '一类经济适用房': 0.45,\n",
    "    '限价商品房': 0.40,\n",
    "    '自住型商品房': 0.38,\n",
    "    '二类经济适用房': 0.30,\n",
    "    '使用权': 0.05,\n",
    "    '集资房': 0.20,  # 归为其他\n",
    "    '拆迁还建房': 0.20,\n",
    "    '动迁安置房': 0.20,\n",
    "    '售后公房': 0.20,\n",
    "    '定向安置房': 0.20\n",
    "}\n",
    "def encode_property_type(df_col):\n",
    "    # 处理缺失值（用最低分填充）\n",
    "    filled = df_col.fillna('其他')\n",
    "    encoded = filled.map(property_score_map)\n",
    "    return encoded.fillna(0.20)\n",
    "X_11 = encode_property_type(train['交易权属'])\n",
    "\n",
    "#X12， 房屋年限\n",
    "年限映射 = {\n",
    "    '满五年': 1.0,\n",
    "    '满两年': 0.5,\n",
    "    '未满两年': 0\n",
    "}\n",
    "def year_value(series):\n",
    "    return series.map(年限映射).fillna(0)\n",
    "X_12 = year_value(train['房屋年限'])\n",
    "\n",
    "#X13, 产权所属\n",
    "def encode_ownership(df):\n",
    "    # 基础编码\n",
    "    df_own = df.eq('非共有').astype(int)\n",
    "    return df_own\n",
    "X_13 = encode_ownership(train['产权所属'])\n",
    "\n",
    "#X14, 文本数据处理\n",
    "def process_property_text(df):\n",
    "    \"\"\"文本特征处理器（仅返回生成的评分列）\"\"\"\n",
    "    # 创建副本避免修改原数据\n",
    "    df_processed = df.copy()\n",
    "    # 预处理\n",
    "    df_processed['周边配套'] = df_processed['周边配套'].fillna('').astype(str)\n",
    "    df_processed['交通出行'] = df_processed['交通出行'].fillna('').astype(str)\n",
    "    # 配套设施评分\n",
    "    def facility_score(text):\n",
    "        if not text.strip():\n",
    "            return 0.0\n",
    "        facility_weights = {'医院': 0.4, '超市': 0.2, '公园': 0.1, '学校': 0.3}\n",
    "        score = sum(v for k, v in facility_weights.items() if k in text)\n",
    "        return min(score, 1)\n",
    "    # 交通评分\n",
    "    def transport_score(text):\n",
    "        if not text.strip():\n",
    "            return 0.0\n",
    "        metro_lines = len(re.findall(r'\\d+号线', text))\n",
    "        metro_bonus = 0.5 * min(metro_lines, 4) / 4\n",
    "        transfer = 1 if ('换乘' in text) or ('交汇' in text) else 0\n",
    "        bus = 1 if ('公交' in text) or bool(re.search(r'\\b\\d{2,4}路\\b', text)) else 0\n",
    "        return min(metro_bonus + transfer * 0.2 + bus * 0.3, 1)\n",
    "    scores = pd.DataFrame({\n",
    "        '配套评分': df_processed['周边配套'].apply(facility_score),\n",
    "        '交通评分': df_processed['交通出行'].apply(transport_score)\n",
    "    })\n",
    "    return scores\n",
    "X_14 = process_property_text(train)\n",
    "\n",
    "#X15,区域\n",
    "X_15 = pd.get_dummies(train['区域'], prefix='X_15', dtype=int, drop_first=True)\n",
    "\n",
    "#X16,板块\n",
    "X_16 = pd.get_dummies(train['板块_x'], prefix='X_16', dtype=int, drop_first=True)\n",
    "\n",
    "#X17,建筑年代，因许多时间为区间，因此计算区间上界到2020的年限\n",
    "def extract_end_year(s):\n",
    "    if pd.isna(s):\n",
    "        return None\n",
    "    years = re.findall(r\"\\d+\", s)\n",
    "    end_year = max(map(int, years))\n",
    "    end_year = min(end_year, 2020)  # 处理超2020的情况\n",
    "    return end_year\n",
    "end = train[\"建筑年代\"].apply(extract_end_year)\n",
    "# 填补缺失值（用中位数）\n",
    "median_age = end.median()\n",
    "end = end.fillna(median_age)\n",
    "# 计算房龄\n",
    "X_17 = 2020 - end\n",
    "\n",
    "#X18,户栋比\n",
    "train[\"房屋数\"] = train[\"房屋总数\"].str.extract(r\"(\\d+)\").astype(float)\n",
    "train[\"楼栋数\"] = train[\"楼栋总数\"].str.extract(r\"(\\d+)\").astype(float)\n",
    "X_18 = pd.DataFrame({\"户栋比\": train[\"房屋数\"]/train[\"楼栋数\"]})\n",
    "median_hudongbi = X_18.median()\n",
    "X_18 = X_18.fillna(median_hudongbi)\n",
    "\n",
    "#X19,绿化率\n",
    "def clean_percent(s):\n",
    "    if pd.isna(s):\n",
    "        return None\n",
    "    match = re.search(r\"(\\d+)%\", str(s))\n",
    "    return min(float(match.group(1)) / 100, 1) if match else None  # 限制最大值为1\n",
    "X_19 = train[\"绿 化 率\"].apply(clean_percent)\n",
    "median_value = X_19.median()\n",
    "X_19 = X_19.fillna(median_value)\n",
    "\n",
    "#X20，环线\n",
    "train['城市_环线'] = train['城市'].astype(str) + '_' + train['环线'].fillna('缺失')  # 处理缺失值\n",
    "X_20 = pd.get_dummies(train['城市_环线'], prefix='X_20', dtype=int, drop_first=True)\n",
    "\n",
    "#X21,停车位\n",
    "train[\"停车位\"] = train[\"停车位\"].fillna(0)\n",
    "q95 = train[train[\"停车位\"] > 0][\"停车位\"].quantile(0.95)\n",
    "X_21 = np.where(train[\"停车位\"] > q95, q95, train[\"停车位\"])\n",
    "X_21 = np.log1p(X_21)\n",
    "\n",
    "#X22，楼层系数与是否电梯的交互项\n",
    "X_22 = X_2 * X_8\n",
    "\n",
    "#X24,建筑面积\n",
    "X_23 = clean_area(train['建筑面积'])\n",
    "\n",
    "# 2. 特征整合与预处理\n",
    "# -------------------------------------------------\n",
    "# 将离散生成的特征整合为DataFrame\n",
    "feature_components = [\n",
    "    X_1.add_prefix('城市_'),\n",
    "    X_2,\n",
    "    X_3.add_prefix('户型_'),\n",
    "    X_4['得房率_修正'],\n",
    "    X_5,\n",
    "    X_6,\n",
    "    X_7,\n",
    "    X_8,\n",
    "    pd.DataFrame(X_9, columns=['别墅类型']),\n",
    "    X_10,\n",
    "    X_11,\n",
    "    X_12,\n",
    "    X_13,\n",
    "    X_14,\n",
    "    X_15.add_prefix('区域_'),\n",
    "    X_16.add_prefix('板块_'),\n",
    "    X_17,\n",
    "    X_18,\n",
    "    X_19,\n",
    "    X_20.add_prefix('环线_'),\n",
    "    pd.DataFrame(X_21, columns=['停车位']),\n",
    "    pd.DataFrame(X_22, columns=['交互项:楼层系数与是否电梯']),\n",
    "    X_23\n",
    "]\n",
    "# 横向拼接所有特征\n",
    "X = pd.concat(feature_components, axis=1)\n",
    "\n",
    "# 3. 数据标准化\n",
    "# -------------------------------------------------\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# ==== 新增部分：目标变量对数变换 & 标准化 ====\n",
    "y_original = train['价格']\n",
    "y_log = np.log(y_original)  # 先取自然对数\n",
    "scaler_y = StandardScaler()\n",
    "y_scaled = scaler_y.fit_transform(y_log.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# ==== 数据划分使用对数标准化后的y ====\n",
    "X_train, X_val, y_train_scaled, y_val_scaled = train_test_split(\n",
    "    X_scaled, y_scaled, test_size=0.2, random_state=111)\n",
    "\n",
    "\n",
    "# 4. 测试集特征处理（复用训练集的处理逻辑）\n",
    "# -------------------------------------------------\n",
    "def preprocess_test_data(test_df, details_df, train_city_avg=None):\n",
    "    \"\"\"预处理测试集数据\"\"\"\n",
    "    # 城市独热编码（需与训练集列对齐）\n",
    "    X_test_1 = pd.get_dummies(test['城市'], prefix='X_1', dtype=int)\n",
    "    missing_cols_1 = set(X_1.columns) - set(X_test_1.columns)\n",
    "    for col in missing_cols_1:\n",
    "        X_test_1[col] = 0\n",
    "    X_test_1 = X_test_1[X_1.columns]\n",
    "    # 楼层系数\n",
    "    parsed_test_2 = [parse_floor(item) for item in test['所在楼层']]\n",
    "    X_test_2_df = pd.DataFrame(parsed_test_2, columns=['desc', 'total'])\n",
    "    X_test_2 = pd.Series(\n",
    "        get_floor_value(X_test_2_df['desc'], X_test_2_df['total']),\n",
    "        name='楼层系数'\n",
    "    )\n",
    "    parsed_test_3 = [parse_layout(item) for item in test['房屋户型']]\n",
    "    X_test_3 = pd.DataFrame([x for x in parsed_test_3 if x is not None])\n",
    "    # 得房率（使用训练集的城市平均值）\n",
    "    test['建筑面积'] = clean_area(test['建筑面积'])\n",
    "    test['套内面积'] = clean_area(test['套内面积'])\n",
    "    test['得房率'] = test['套内面积'] / test['建筑面积']\n",
    "    # 使用训练集的城市平均值\n",
    "    test['得房率_修正'] = test.apply(\n",
    "        lambda row: train_city_avg.get(row['城市'], 0.75) if pd.isna(row['得房率']) else row['得房率'],\n",
    "        axis=1\n",
    "    )\n",
    "    X_test_4 = test['得房率_修正']\n",
    "    X_test_5 = process_direction(test['房屋朝向'])\n",
    "    X_test_6 = process_renovation(test['装修情况'])\n",
    "    X_test_7 = test['梯户比例'].apply(parse_ratio)\n",
    "    X_test_8 = process_elevator(test['配备电梯'])\n",
    "    X_test_9 = villa_value(test['别墅类型'])\n",
    "    X_test_10 = test['房屋用途'].isin(housing_keywords).astype(int)\n",
    "    X_test_11 = encode_property_type(test['交易权属'])\n",
    "    X_test_12 = year_value(test['房屋年限'])\n",
    "    X_test_13 = encode_ownership(test['产权所属'])\n",
    "    X_test_14 = process_property_text(test)\n",
    "    X_test_15 = pd.get_dummies(test['区域'], prefix='X_15', dtype=int)\n",
    "    missing_cols_15 = set(X_15.columns) - set(X_test_15.columns)\n",
    "    for col in missing_cols_15:\n",
    "        X_test_15[col] = 0\n",
    "    X_test_15 = X_test_15[X_15.columns]\n",
    "    X_test_16 = pd.get_dummies(test['板块_x'], prefix='X_16', dtype=int)\n",
    "    missing_cols_16 = set(X_16.columns) - set(X_test_16.columns)\n",
    "    for col in missing_cols_16:\n",
    "        X_test_16[col] = 0\n",
    "    X_test_16 = X_test_16[X_16.columns]\n",
    "    end_test = test[\"建筑年代\"].apply(extract_end_year)\n",
    "    end_test = end_test.fillna(median_age)\n",
    "    X_test_17 = 2020 - end_test\n",
    "    test[\"房屋数\"] = test[\"房屋总数\"].str.extract(r\"(\\d+)\").astype(float)\n",
    "    test[\"楼栋数\"] = test[\"楼栋总数\"].str.extract(r\"(\\d+)\").astype(float)\n",
    "    X_test_18 = pd.DataFrame({\"户栋比\": test[\"房屋数\"]/test[\"楼栋数\"]})\n",
    "    X_test_18 = X_test_18.fillna(median_hudongbi)\n",
    "    X_test_19 = test[\"绿 化 率\"].apply(clean_percent)\n",
    "    X_test_19 = X_test_19.fillna(median_value)\n",
    "    test['城市_环线'] = test['城市'].astype(str) + '_' + test['环线'].fillna('缺失')\n",
    "    X_test_20 = pd.get_dummies(test['城市_环线'], prefix='X_20', dtype=int, drop_first=True)\n",
    "    test[\"停车位\"] = test[\"停车位\"].fillna(0)\n",
    "    X_test_21 = np.where(test[\"停车位\"] > q95, q95, test[\"停车位\"])\n",
    "    X_test_21 = np.log1p(X_test_21)\n",
    "    X_test_22 = X_test_2 * X_test_8\n",
    "    X_test_23 = clean_area(test['建筑面积'])\n",
    "\n",
    "    # 整合特征\n",
    "    feature_components_test = [\n",
    "        X_test_1.add_prefix('城市_'),\n",
    "        X_test_2,\n",
    "        X_test_3.add_prefix('户型_'),\n",
    "        X_test_4,\n",
    "        X_test_5,\n",
    "        X_test_6,\n",
    "        X_test_7,\n",
    "        X_test_8,\n",
    "        pd.DataFrame(X_test_9, columns=['别墅类型']),\n",
    "        X_test_10,\n",
    "        X_test_11,\n",
    "        X_test_12,\n",
    "        X_test_13,\n",
    "        X_test_14,\n",
    "        X_test_15.add_prefix('区域_'),\n",
    "        X_test_16.add_prefix('板块_'),\n",
    "        X_test_17,\n",
    "        X_test_18,\n",
    "        X_test_19,\n",
    "        X_test_20.add_prefix('环线_'),\n",
    "        pd.DataFrame(X_test_21, columns=['停车位']),\n",
    "        pd.DataFrame(X_test_22, columns=['交互项:楼层系数与是否电梯']),\n",
    "        X_test_23\n",
    "    ]\n",
    "\n",
    "    return pd.concat(feature_components_test, axis=1)\n",
    "\n",
    "# 获取训练集的得房率城市平均值（用于填充测试集缺失值）\n",
    "train_city_avg = X_4.groupby(train['城市'])['得房率_修正'].mean().to_dict()\n",
    "# 处理测试集数据\n",
    "X_test = preprocess_test_data(test, details, train_city_avg)\n",
    "\n",
    "# 5.测试集数据标准化（使用训练集的scaler）\n",
    "# -------------------------------------------------\n",
    "X_test_scaled = scaler.transform(X_test)  # 注意：使用训练集的scaler\n",
    "\n",
    "# 6. 模型训练与评估\n",
    "# -------------------------------------------------\n",
    "# 定义模型配置\n",
    "models_config = {\n",
    "    'OLS': {\n",
    "        'model': LinearRegression(),\n",
    "        'params': {},\n",
    "    },\n",
    "    'Lasso': {\n",
    "        'model': Lasso(max_iter=10000),\n",
    "        'params': {\n",
    "            'alpha': [0.001]\n",
    "        }\n",
    "    },\n",
    "    'Ridge': {\n",
    "        'model': Ridge(),\n",
    "        'params': {\n",
    "            'alpha': [1000]\n",
    "        }\n",
    "    },\n",
    "    'ElasticNet': {\n",
    "        'model': ElasticNet(max_iter=10000),\n",
    "        'params': {\n",
    "            'alpha': [0.01],\n",
    "            'l1_ratio': [0.005]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def inverse_transform(y_scaled):\n",
    "    \"\"\"逆变换步骤：标准化逆变换 -> 指数变换\"\"\"\n",
    "    y_log = scaler_y.inverse_transform(y_scaled.reshape(-1, 1)).flatten()\n",
    "    return np.exp(y_log)\n",
    "def inverse_mae(y_true_scaled, y_pred_scaled):\n",
    "    y_true = inverse_transform(y_true_scaled)\n",
    "    y_pred = inverse_transform(y_pred_scaled)\n",
    "    return mean_absolute_error(y_true, y_pred)\n",
    "def inverse_rmse(y_true_scaled, y_pred_scaled):\n",
    "    y_true = inverse_transform(y_true_scaled)\n",
    "    y_pred = inverse_transform(y_pred_scaled)\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "scoring = {\n",
    "    'MAE': make_scorer(inverse_mae),\n",
    "    'RMSE': make_scorer(inverse_rmse)\n",
    "}\n",
    "\n",
    "# ==== 修改部分：模型训练和评估流程 ====\n",
    "performance_report = []\n",
    "results = {}\n",
    "\n",
    "for model_name in models_config:\n",
    "    print(f\"\\n=== 训练 {model_name} ===\")\n",
    "    config = models_config[model_name]\n",
    "    metrics = {'Model': model_name}\n",
    "\n",
    "    if model_name == 'OLS':\n",
    "        # 样本内评估\n",
    "        model = config['model'].fit(X_train, y_train_scaled)\n",
    "        y_train_pred_scaled = model.predict(X_train)\n",
    "        metrics['In-sample MAE'] = inverse_mae(y_train_scaled, y_train_pred_scaled)\n",
    "        metrics['In-sample RMSE'] = inverse_rmse(y_train_scaled, y_train_pred_scaled)\n",
    "\n",
    "        # 交叉验证（需要重新实现以包含逆变换）\n",
    "        kf = KFold(n_splits=6, shuffle=True, random_state=111)\n",
    "        cv_mae_scores = []\n",
    "        cv_rmse_scores = []\n",
    "        for train_idx, val_idx in kf.split(X_scaled):\n",
    "            model_cv = LinearRegression().fit(X_scaled[train_idx], y_scaled[train_idx])\n",
    "            y_pred_scaled = model_cv.predict(X_scaled[val_idx])\n",
    "            cv_mae_scores.append(inverse_mae(y_scaled[val_idx], y_pred_scaled))\n",
    "            cv_rmse_scores.append(inverse_rmse(y_scaled[val_idx], y_pred_scaled))\n",
    "        metrics['CV MAE'] = np.mean(cv_mae_scores)\n",
    "        metrics['CV RMSE'] = np.mean(cv_rmse_scores)\n",
    "\n",
    "        # 验证集评估\n",
    "        y_val_pred_scaled = model.predict(X_val)\n",
    "        metrics['Out-sample MAE'] = inverse_mae(y_val_scaled, y_val_pred_scaled)\n",
    "        metrics['Out-sample RMSE'] = inverse_rmse(y_val_scaled, y_val_pred_scaled)\n",
    "\n",
    "    else:\n",
    "        # 网格搜索（使用自定义评分）\n",
    "        gscv = GridSearchCV(\n",
    "            estimator=config['model'],\n",
    "            param_grid=config['params'],\n",
    "            cv=6,\n",
    "            scoring=scoring,\n",
    "            refit='RMSE',\n",
    "            return_train_score=True,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        gscv.fit(X_scaled, y_scaled)\n",
    "\n",
    "        # 获取最佳模型\n",
    "        best_model = gscv.best_estimator_\n",
    "        results[model_name] = {\n",
    "            'model': gscv.best_estimator_,\n",
    "            'params': gscv.best_params_\n",
    "        }\n",
    "        print(f\"{model_name}训练完成，最佳参数: {gscv.best_params_}\")\n",
    "\n",
    "        # 样本内评估\n",
    "        y_train_pred_scaled = best_model.predict(X_scaled)\n",
    "        metrics['In-sample MAE'] = inverse_mae(y_scaled, y_train_pred_scaled)\n",
    "        metrics['In-sample RMSE'] = inverse_rmse(y_scaled, y_train_pred_scaled)\n",
    "\n",
    "        # 交叉验证结果\n",
    "        metrics['CV MAE'] = gscv.cv_results_['mean_test_MAE'][gscv.best_index_]\n",
    "        metrics['CV RMSE'] = gscv.cv_results_['mean_test_RMSE'][gscv.best_index_]\n",
    "\n",
    "        # 验证集评估\n",
    "        y_val_pred_scaled = best_model.predict(X_val)\n",
    "        metrics['Out-sample MAE'] = inverse_mae(y_val_scaled, y_val_pred_scaled)\n",
    "        metrics['Out-sample RMSE'] = inverse_rmse(y_val_scaled, y_val_pred_scaled)\n",
    "\n",
    "    # 计算Score\n",
    "    weighted_error = 0.3 * metrics['CV MAE'] + 0.4 * metrics['Out-sample MAE'] + 0.3 * metrics['Out-sample RMSE']\n",
    "    metrics['Score'] = ((1 - weighted_error / (weighted_error.max() * 1.2)).clip(0, 1) * 100).round(2)\n",
    "    performance_report.append(metrics)\n",
    "\n",
    "\n",
    "# 5. 生成报告表格\n",
    "# -------------------------------------------------\n",
    "report_df = pd.DataFrame(performance_report)\n",
    "columns_order = ['Model', 'In-sample MAE', 'In-sample RMSE',\n",
    "                 'Out-sample MAE', 'Out-sample RMSE',\n",
    "                 'CV MAE', 'CV RMSE', 'Score']\n",
    "report_df = report_df[columns_order]\n",
    "\n",
    "print(\"\\n=== 性能报告 ===\")\n",
    "print(report_df.to_markdown(index=False))\n",
    "\n",
    "# 6. 异常值处理与预测数量\n",
    "# -------------------------------------------------\n",
    "def calculate_and_save(model_name, predictions_scaled):\n",
    "    \"\"\"使用原始量级计算异常值\"\"\"\n",
    "    predictions = inverse_transform(predictions_scaled)\n",
    "\n",
    "    q1 = np.percentile(predictions, 25)\n",
    "    q3 = np.percentile(predictions, 75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "    is_outlier = (predictions < lower_bound) | (predictions > upper_bound)\n",
    "    outlier_count = sum(is_outlier)\n",
    "\n",
    "    # 保存原始量级预测结果\n",
    "    result_df = test[['ID']].copy()\n",
    "    result_df['Price'] = np.round(predictions, 2)\n",
    "    result_df.to_csv(f'predictions_{model_name}.csv', index=False)\n",
    "\n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'outlier_count': outlier_count,\n",
    "        'outlier_ratio': f\"{outlier_count / len(predictions):.2%}\",\n",
    "        'lower_bound': round(lower_bound, 2),\n",
    "        'upper_bound': round(upper_bound, 2),\n",
    "        'predictions': predictions\n",
    "    }\n",
    "\n",
    "# 预测测试集并保存结果\n",
    "outlier_stats = []\n",
    "for model_name in models_config:\n",
    "    if model_name in results:\n",
    "        pred_scaled = results[model_name]['model'].predict(X_test_scaled)\n",
    "    else:\n",
    "        model = models_config[model_name]['model'].fit(X_scaled, y_scaled)\n",
    "        pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "    stats = calculate_and_save(model_name, pred_scaled)\n",
    "    outlier_stats.append(stats)\n",
    "    print(f\"{model_name}异常值统计:\")\n",
    "    print(f\"  异常值数量: {stats['outlier_count']}/{len(stats['predictions'])}\")\n",
    "    print(f\"  异常值比例: {stats['outlier_ratio']}\")\n",
    "    print(f\"  正常值范围: [{stats['lower_bound']}, {stats['upper_bound']}]\")\n",
    "\n",
    "# 生成异常值综合报告\n",
    "outlier_report = pd.DataFrame(outlier_stats)[\n",
    "    ['model', 'outlier_count', 'outlier_ratio', 'lower_bound', 'upper_bound']\n",
    "]\n",
    "outlier_report.to_csv('outliers_summary.csv', index=False)\n",
    "print(\"\\n各模型异常值统计已保存到 outliers_summary.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eec420a-6003-4bde-ab1a-499d2fcc59b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
