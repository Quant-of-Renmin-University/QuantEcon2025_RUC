{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4e622f5-e95f-49bf-bf11-4ada6dae18c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "数据加载中...\n",
      "主数据加载成功\n",
      "   训练集: (84133, 32)\n",
      "   测试集: (14786, 32)\n",
      "小区数据: (3100, 27)\n",
      "租金数据: (84150, 23)\n",
      "\n",
      "高级特征工程...\n",
      "基础特征提取...\n",
      "   处理前 - 训练集: 84133, 测试集: 14786\n",
      "   处理后 - 训练集: 84133, 测试集: 14786\n",
      "外部数据融合...\n",
      "合并租金数据失败: '城市'\n",
      "合并租金数据失败: '城市'\n",
      "   融合后 - 训练集: 91613, 测试集: 16110\n",
      " 测试集长度变化: 14786 -> 16110\n",
      "   进行去重处理...\n",
      "   去重后测试集长度: 14786\n",
      "   重排序后测试集长度: 14786\n",
      "高级组合特征...\n",
      "   最终 - 训练集: 91613, 测试集: 14786\n",
      "训练集特征数: 123\n",
      "测试集特征数: 123\n",
      "共同特征数: 122\n",
      "排除特征数: 8\n",
      "可用特征数: 118\n",
      "最终使用特征数: 118\n",
      "\n",
      "特征统计:\n",
      "   总特征数: 118\n",
      "   数值特征: 78\n",
      "   分类特征: 40\n",
      "\n",
      "🔍 异常值处理...\n",
      "   原始训练样本: 91613\n",
      "   清洗后训练样本: 82562\n",
      "   移除比例: 9.9%\n",
      "   测试集保持不变: 14786 样本\n",
      "\n",
      " 数据预处理...\n",
      "高级预处理开始...\n",
      "训练集形状: (66049, 118)\n",
      "测试集形状: (16513, 118)\n",
      "数值特征数量: 78\n",
      "分类特征数量: 40\n",
      "成功处理数值特征: 44/78\n",
      "成功处理分类特征: 40/40\n",
      "预处理完成:\n",
      "  训练集最终形状: (66049, 118)\n",
      "  测试集最终形状: (16513, 118)\n",
      "  训练集缺失值: 0\n",
      "  测试集缺失值: 0\n",
      "高级预处理开始...\n",
      "训练集形状: (66049, 118)\n",
      "测试集形状: (14786, 118)\n",
      "数值特征数量: 78\n",
      "分类特征数量: 40\n",
      "成功处理数值特征: 44/78\n",
      "成功处理分类特征: 40/40\n",
      "预处理完成:\n",
      "  训练集最终形状: (66049, 118)\n",
      "  测试集最终形状: (14786, 118)\n",
      "  训练集缺失值: 0\n",
      "  测试集缺失值: 0\n",
      "预处理后长度检查:\n",
      "  训练集: 66049\n",
      "  验证集: 16513\n",
      "  测试集: 14786\n",
      "  原始测试ID: 14786\n",
      "修正后测试集长度: 14786\n",
      "\n",
      " 进行特征选择...\n",
      "原始特征数: 118\n",
      "移除低方差特征后: 99\n",
      "统计特征选择后: 60\n",
      "前10个最重要特征:\n",
      "   feature         score\n",
      "25    城市_x  11829.424588\n",
      "6     城市_y  10431.567383\n",
      "33      环线   5886.250807\n",
      "7     建筑面积   4615.035210\n",
      "23  物业办公电话   4050.487322\n",
      "29     燃气费   3743.267821\n",
      "52     开发商   3474.560479\n",
      "16    产权描述   3199.300901\n",
      "21  面积_大户型   3067.677356\n",
      "11      卫数   2907.763921\n",
      "特征选择后长度检查:\n",
      "  训练集: (66049, 60)\n",
      "  验证集: (16513, 60)\n",
      "  测试集: (14786, 60)\n",
      "\n",
      "模型训练开始...\n",
      "==================================================\n",
      "\n",
      "训练模型: Ridge\n",
      "Ridge:\n",
      "   测试MAE: 821873\n",
      "   测试R2: 0.3195\n",
      "   CV MAE: 625688 ± 5206\n",
      "\n",
      "训练模型: Lasso\n",
      "Lasso:\n",
      "   测试MAE: 821234\n",
      "   测试R2: 0.3202\n",
      "   CV MAE: 625967 ± 5260\n",
      "\n",
      "训练模型: ElasticNet\n",
      "ElasticNet:\n",
      "   测试MAE: 835449\n",
      "   测试R2: 0.3042\n",
      "   CV MAE: 625737 ± 4735\n",
      "\n",
      "训练模型: RandomForest\n",
      "RandomForest:\n",
      "   测试MAE: 527563\n",
      "   测试R2: 0.6913\n",
      "   CV MAE: 151444 ± 889\n",
      "\n",
      "训练模型: ExtraTrees\n",
      "ExtraTrees:\n",
      "   测试MAE: 566096\n",
      "   测试R2: 0.6407\n",
      "   CV MAE: 185335 ± 871\n",
      "\n",
      "训练模型: GradientBoosting\n",
      "GradientBoosting:\n",
      "   测试MAE: 535431\n",
      "   测试R2: 0.6724\n",
      "   CV MAE: 151230 ± 1376\n",
      "\n",
      "训练模型: XGBoost\n",
      "XGBoost:\n",
      "   测试MAE: 458439\n",
      "   测试R2: 0.7436\n",
      "   CV MAE: 139764 ± 1378\n",
      "\n",
      "训练模型: LightGBM\n",
      "LightGBM:\n",
      "   测试MAE: 408081\n",
      "   测试R2: 0.7977\n",
      "   CV MAE: 174182 ± 2764\n",
      "\n",
      "模型性能排行榜:\n",
      "================================================================================\n",
      "              模型         测试MAE     测试R2        CV_MAE      CV_STD\n",
      "         XGBoost 458439.281250 0.743577 139764.100000 1378.406514\n",
      "GradientBoosting 535430.629126 0.672427 151229.841326 1375.795186\n",
      "    RandomForest 527563.454492 0.691323 151443.527376  888.609256\n",
      "        LightGBM 408080.661345 0.797723 174182.090712 2763.824365\n",
      "      ExtraTrees 566096.015792 0.640694 185334.928031  870.775145\n",
      "           Ridge 821873.405735 0.319544 625687.612079 5206.204263\n",
      "      ElasticNet 835448.761436 0.304165 625737.326833 4734.529310\n",
      "           Lasso 821233.555564 0.320236 625966.845223 5259.916266\n",
      "\n",
      "🔗 创建元学习集成...\n",
      "  生成 Ridge 的元特征...\n",
      "  生成 Lasso 的元特征...\n",
      "  生成 ElasticNet 的元特征...\n",
      "  生成 RandomForest 的元特征...\n",
      "  生成 ExtraTrees 的元特征...\n",
      "  生成 GradientBoosting 的元特征...\n",
      "  生成 XGBoost 的元特征...\n",
      "  生成 LightGBM 的元特征...\n",
      "元学习集成完成:\n",
      "   使用模型: Ridge, Lasso, ElasticNet, RandomForest, ExtraTrees, GradientBoosting, XGBoost, LightGBM\n",
      "   验证MAE: 540126\n",
      "   验证R2: 0.6622\n",
      "\n",
      "最终预测生成...\n",
      "最佳单一模型: XGBoost\n",
      "预测长度检查:\n",
      "  预测结果: 14786\n",
      "  原始测试ID: 14786\n",
      "🔗 应用元学习集成...\n",
      "元特征长度检查: 14786 vs 14786\n",
      "使用集成预测 (最佳模型80% + 元学习20%)\n",
      "\n",
      "创建提交文件...\n",
      "最终长度检查:\n",
      "  预测结果: 14786\n",
      "  测试集ID: 14786\n",
      "\n",
      "预测完成!\n",
      "==================================================\n",
      "预测统计:\n",
      "   样本数量: 14786\n",
      "   价格范围: 192377 - 6171747\n",
      "   平均价格: 2335562\n",
      "   中位价格: 1876648\n",
      "   标准差: 1464797\n",
      "\n",
      "文件保存: high_performance_submission.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor, ExtraTreesRegressor\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, RobustScaler, QuantileTransformer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, RFE\n",
    "from sklearn.decomposition import PCA\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 尝试导入高性能模型\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    HAS_XGB = True\n",
    "except:\n",
    "    HAS_XGB = False\n",
    "    print(\"⚠️  XGBoost未安装，将跳过XGBoost模型\")\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    HAS_LGB = True\n",
    "except:\n",
    "    HAS_LGB = False\n",
    "    print(\"⚠️  LightGBM未安装，将跳过LightGBM模型\")\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "def advanced_feature_engineering(df, is_training=True, training_stats=None):\n",
    "    \"\"\"高级特征工程 - 添加训练/测试集标识\"\"\"\n",
    "    data = df.copy()\n",
    "    \n",
    "    # 如果是训练集，记录统计信息；如果是测试集，使用训练集的统计信息\n",
    "    if training_stats is None:\n",
    "        training_stats = {}\n",
    "    \n",
    "    # 通用面积提取函数\n",
    "    def extract_area(area_str):\n",
    "        if pd.isna(area_str):\n",
    "            return np.nan\n",
    "        try:\n",
    "            numbers = re.findall(r'\\d+\\.?\\d*', str(area_str))\n",
    "            if len(numbers) >= 2:\n",
    "                return (float(numbers[0]) + float(numbers[1])) / 2\n",
    "            elif len(numbers) == 1:\n",
    "                return float(numbers[0])\n",
    "        except:\n",
    "            pass\n",
    "        return np.nan\n",
    "    \n",
    "    # 1. 建筑面积处理\n",
    "    if '建筑面积' in data.columns:\n",
    "        data['建筑面积'] = data['建筑面积'].apply(extract_area)\n",
    "        # 更保守的异常值处理\n",
    "        data.loc[(data['建筑面积'] > 800) | (data['建筑面积'] < 15), '建筑面积'] = np.nan\n",
    "    \n",
    "    # 2. 套内面积\n",
    "    if '套内面积' in data.columns:\n",
    "        data['套内面积'] = data['套内面积'].apply(extract_area)\n",
    "        data.loc[(data['套内面积'] > 800) | (data['套内面积'] < 15), '套内面积'] = np.nan\n",
    "        \n",
    "        # 计算得房率\n",
    "        if '建筑面积' in data.columns:\n",
    "            data['得房率'] = data['套内面积'] / data['建筑面积']\n",
    "            data['得房率'] = data['得房率'].clip(0.5, 1.0)  # 合理范围\n",
    "    \n",
    "    # 3. 户型信息\n",
    "    if '房屋户型' in data.columns:\n",
    "        def extract_room_info(room_str):\n",
    "            if pd.isna(room_str):\n",
    "                return 2, 1, 1\n",
    "            \n",
    "            room_str = str(room_str)\n",
    "            \n",
    "            room_match = re.search(r'(\\d+)室', room_str)\n",
    "            rooms = int(room_match.group(1)) if room_match else 2\n",
    "            \n",
    "            hall_match = re.search(r'(\\d+)厅', room_str)\n",
    "            halls = int(hall_match.group(1)) if hall_match else 1\n",
    "            \n",
    "            bath_match = re.search(r'(\\d+)卫', room_str)\n",
    "            baths = int(bath_match.group(1)) if bath_match else 1\n",
    "            \n",
    "            rooms = max(1, min(rooms, 8))\n",
    "            halls = max(0, min(halls, 4))\n",
    "            baths = max(1, min(baths, 4))\n",
    "            \n",
    "            return rooms, halls, baths\n",
    "        \n",
    "        room_info = data['房屋户型'].apply(extract_room_info)\n",
    "        data['室数'] = [info[0] for info in room_info]\n",
    "        data['厅数'] = [info[1] for info in room_info]\n",
    "        data['卫数'] = [info[2] for info in room_info]\n",
    "        data['总房间数'] = data['室数'] + data['厅数'] + data['卫数']\n",
    "        \n",
    "        # 户型类型编码\n",
    "        data['户型类型'] = data['室数'].astype(str) + '室' + data['厅数'].astype(str) + '厅'\n",
    "        \n",
    "        # 房间配比特征\n",
    "        data['室厅比'] = data['室数'] / (data['厅数'] + 1)\n",
    "        data['室卫比'] = data['室数'] / data['卫数']\n",
    "    \n",
    "    # 4. 楼层信息\n",
    "    if '所在楼层' in data.columns:\n",
    "        def extract_floor_info(floor_str):\n",
    "            if pd.isna(floor_str):\n",
    "                return 5, 20, 0.25\n",
    "            \n",
    "            floor_str = str(floor_str)\n",
    "            patterns = [\n",
    "                r'第?(\\d+)层.*共(\\d+)层',\n",
    "                r'(\\d+)/(\\d+)',\n",
    "                r'(\\d+)层.*(\\d+)层'\n",
    "            ]\n",
    "            \n",
    "            for pattern in patterns:\n",
    "                match = re.search(pattern, floor_str)\n",
    "                if match:\n",
    "                    try:\n",
    "                        current = int(match.group(1))\n",
    "                        total = int(match.group(2))\n",
    "                        if 1 <= current <= total <= 100:\n",
    "                            ratio = current / total\n",
    "                            return current, total, ratio\n",
    "                    except:\n",
    "                        continue\n",
    "            \n",
    "            return 5, 20, 0.25\n",
    "        \n",
    "        floor_info = data['所在楼层'].apply(extract_floor_info)\n",
    "        data['当前楼层'] = [info[0] for info in floor_info]\n",
    "        data['总楼层'] = [info[1] for info in floor_info]\n",
    "        data['楼层比例'] = [info[2] for info in floor_info]\n",
    "        \n",
    "        # 楼层分类（更细致）\n",
    "        data['楼层类型_底层'] = (data['楼层比例'] <= 0.2).astype(int)\n",
    "        data['楼层类型_低层'] = ((data['楼层比例'] > 0.2) & (data['楼层比例'] <= 0.4)).astype(int)\n",
    "        data['楼层类型_中层'] = ((data['楼层比例'] > 0.4) & (data['楼层比例'] <= 0.7)).astype(int)\n",
    "        data['楼层类型_高层'] = ((data['楼层比例'] > 0.7) & (data['楼层比例'] < 0.9)).astype(int)\n",
    "        data['楼层类型_顶层'] = (data['楼层比例'] >= 0.9).astype(int)\n",
    "        \n",
    "        # 楼层价值评分（一般中高层最贵）\n",
    "        data['楼层价值'] = np.where(\n",
    "            (data['楼层比例'] >= 0.3) & (data['楼层比例'] <= 0.8), 1, 0\n",
    "        )\n",
    "    \n",
    "    # 5. 朝向特征（更全面）\n",
    "    if '房屋朝向' in data.columns:\n",
    "        data['朝南'] = data['房屋朝向'].str.contains('南', na=False).astype(int)\n",
    "        data['朝北'] = data['房屋朝向'].str.contains('北', na=False).astype(int)\n",
    "        data['朝东'] = data['房屋朝向'].str.contains('东', na=False).astype(int)\n",
    "        data['朝西'] = data['房屋朝向'].str.contains('西', na=False).astype(int)\n",
    "        data['南北通透'] = ((data['朝南'] == 1) & (data['朝北'] == 1)).astype(int)\n",
    "        data['东西通透'] = ((data['朝东'] == 1) & (data['朝西'] == 1)).astype(int)\n",
    "        \n",
    "        # 朝向评分（南>东>北>西）\n",
    "        orientation_score = 0\n",
    "        orientation_score += data['朝南'] * 4\n",
    "        orientation_score += data['朝东'] * 3\n",
    "        orientation_score += data['朝北'] * 2\n",
    "        orientation_score += data['朝西'] * 1\n",
    "        data['朝向评分'] = orientation_score\n",
    "        \n",
    "        # 通透性评分\n",
    "        data['通透性'] = data['南北通透'] * 2 + data['东西通透'] * 1\n",
    "    \n",
    "    # 6. 装修情况\n",
    "    if '装修情况' in data.columns:\n",
    "        decoration_map = {\n",
    "            '豪华装修': 5, '精装修': 4, '中装修': 3, \n",
    "            '简装修': 2, '毛坯房': 1, '其他': 2\n",
    "        }\n",
    "        data['装修评分'] = data['装修情况'].fillna('其他').map(decoration_map).fillna(2)\n",
    "    \n",
    "    # 7. 环线特征\n",
    "    if '环线' in data.columns:\n",
    "        def parse_ring(ring_str):\n",
    "            if pd.isna(ring_str):\n",
    "                return 5\n",
    "            \n",
    "            ring_str = str(ring_str).lower()\n",
    "            ring_map = {\n",
    "                '一环': 1, '内环': 1, '二环': 2, '三环': 3, \n",
    "                '四环': 4, '五环': 5, '六环': 6\n",
    "            }\n",
    "            \n",
    "            for key, value in ring_map.items():\n",
    "                if key in ring_str:\n",
    "                    return value\n",
    "            \n",
    "            numbers = re.findall(r'\\d+', ring_str)\n",
    "            if numbers:\n",
    "                return min(int(numbers[0]), 8)\n",
    "            \n",
    "            return 5\n",
    "        \n",
    "        data['环线数值'] = data['环线'].apply(parse_ring)\n",
    "        # 环线价值（越靠内越贵，但非线性）\n",
    "        data['环线价值'] = np.exp(-(data['环线数值'] - 1) * 0.3)\n",
    "    \n",
    "    # 8. 时间特征\n",
    "    if '交易时间' in data.columns:\n",
    "        data['交易时间'] = pd.to_datetime(data['交易时间'], errors='coerce')\n",
    "        data['交易年份'] = data['交易时间'].dt.year.fillna(2023)\n",
    "        data['交易月份'] = data['交易时间'].dt.month.fillna(6)\n",
    "        data['交易季度'] = data['交易时间'].dt.quarter.fillna(2)\n",
    "        \n",
    "        # 季节性特征（房地产有明显季节性）\n",
    "        data['是否旺季'] = data['交易月份'].isin([3, 4, 5, 9, 10, 11]).astype(int)\n",
    "        data['是否年底'] = data['交易月份'].isin([11, 12]).astype(int)\n",
    "        \n",
    "        # 年份热编码 - 使用固定年份避免训练测试集特征不一致\n",
    "        common_years = [2020, 2021, 2022, 2023, 2024]\n",
    "        for year in common_years:\n",
    "            data[f'年份_{year}'] = (data['交易年份'] == year).astype(int)\n",
    "        \n",
    "        # 删除原始时间列，避免类型问题\n",
    "        data = data.drop(['交易时间'], axis=1)\n",
    "    \n",
    "    # 9. 房龄特征\n",
    "    if '年份' in data.columns:\n",
    "        data['年份'] = pd.to_numeric(data['年份'], errors='coerce')\n",
    "        data['年份'] = data['年份'].fillna(data['年份'].median())\n",
    "        \n",
    "        if '交易年份' in data.columns:\n",
    "            data['房龄'] = data['交易年份'] - data['年份']\n",
    "            data['房龄'] = data['房龄'].clip(0, 100)\n",
    "            \n",
    "            # 房龄分档（非线性贬值）\n",
    "            data['房龄_新房'] = (data['房龄'] <= 2).astype(int)\n",
    "            data['房龄_次新'] = ((data['房龄'] > 2) & (data['房龄'] <= 5)).astype(int)\n",
    "            data['房龄_中等'] = ((data['房龄'] > 5) & (data['房龄'] <= 10)).astype(int)\n",
    "            data['房龄_较旧'] = ((data['房龄'] > 10) & (data['房龄'] <= 20)).astype(int)\n",
    "            data['房龄_老房'] = (data['房龄'] > 20).astype(int)\n",
    "            \n",
    "            # 房龄价值衰减\n",
    "            data['房龄价值'] = np.exp(-data['房龄'] * 0.02)\n",
    "    \n",
    "    # 10. 电梯特征\n",
    "    if '有无电梯' in data.columns:\n",
    "        data['有电梯'] = (data['有无电梯'] == '有').astype(int)\n",
    "        \n",
    "        # 电梯必要性（高层更需要电梯）\n",
    "        if '总楼层' in data.columns:\n",
    "            data['电梯必要性'] = np.where(data['总楼层'] > 6, 1, 0)\n",
    "            data['电梯匹配度'] = data['有电梯'] * data['电梯必要性']\n",
    "    \n",
    "    return data, training_stats\n",
    "\n",
    "def advanced_external_merge(df, community_df, rent_df):\n",
    "    \"\"\"高级外部数据融合\"\"\"\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    def safe_extract_numeric(x):\n",
    "        if pd.isna(x):\n",
    "            return np.nan\n",
    "        try:\n",
    "            x_str = str(x).replace('%', '').replace('，', '').replace(',', '')\n",
    "            numbers = re.findall(r'\\d+\\.?\\d*', x_str)\n",
    "            if numbers:\n",
    "                return float(numbers[0])\n",
    "        except:\n",
    "            pass\n",
    "        return np.nan\n",
    "    \n",
    "    # 1. 小区数据融合（增强版）\n",
    "    if community_df is not None and len(community_df) > 0:\n",
    "        result_df['小区名称_clean'] = result_df['小区名称'].astype(str).str.strip()\n",
    "        community_df['名称_clean'] = community_df['名称'].astype(str).str.strip()\n",
    "        \n",
    "        # 处理小区特征\n",
    "        if '容 积 率' in community_df.columns:\n",
    "            community_df['容积率'] = community_df['容 积 率'].apply(safe_extract_numeric)\n",
    "            community_df['容积率'] = community_df['容积率'].fillna(2.5).clip(0.1, 10)\n",
    "            # 容积率分档\n",
    "            community_df['容积率_低密度'] = (community_df['容积率'] <= 1.5).astype(int)\n",
    "            community_df['容积率_中密度'] = ((community_df['容积率'] > 1.5) & (community_df['容积率'] <= 3.0)).astype(int)\n",
    "            community_df['容积率_高密度'] = (community_df['容积率'] > 3.0).astype(int)\n",
    "        \n",
    "        if '绿 化 率' in community_df.columns:\n",
    "            community_df['绿化率'] = community_df['绿 化 率'].apply(safe_extract_numeric)\n",
    "            community_df['绿化率'] = community_df['绿化率'].fillna(30).clip(0, 80) / 100\n",
    "            # 绿化率分档\n",
    "            community_df['绿化率_高'] = (community_df['绿化率'] >= 0.35).astype(int)\n",
    "            community_df['绿化率_中'] = ((community_df['绿化率'] >= 0.25) & (community_df['绿化率'] < 0.35)).astype(int)\n",
    "            community_df['绿化率_低'] = (community_df['绿化率'] < 0.25).astype(int)\n",
    "        \n",
    "        if '物 业 费' in community_df.columns:\n",
    "            community_df['物业费'] = community_df['物 业 费'].apply(safe_extract_numeric)\n",
    "            community_df['物业费'] = community_df['物业费'].fillna(community_df['物业费'].median())\n",
    "            # 物业费分档（通常物业费越高，小区品质越好）\n",
    "            community_df['物业费_档次'] = pd.cut(community_df['物业费'], \n",
    "                                             bins=[0, 2, 4, 6, np.inf], \n",
    "                                             labels=['低', '中', '高', '豪华']).astype(str)\n",
    "        \n",
    "        # 合并小区数据\n",
    "        try:\n",
    "            merge_cols = ['名称_clean', '城市']\n",
    "            feature_cols = [c for c in community_df.columns if c not in ['名称', '名称_clean']]\n",
    "            \n",
    "            merged = result_df.merge(\n",
    "                community_df[feature_cols + ['名称_clean']],\n",
    "                left_on='小区名称_clean',\n",
    "                right_on='名称_clean',\n",
    "                how='left'\n",
    "            )\n",
    "            result_df = merged\n",
    "        except Exception as e:\n",
    "            print(f\"合并小区数据失败: {e}\")\n",
    "    \n",
    "    # 2. 租金数据融合（增强版）\n",
    "    if rent_df is not None and len(rent_df) > 0 and '价格' in rent_df.columns:\n",
    "        try:\n",
    "            rent_df['价格'] = pd.to_numeric(rent_df['价格'], errors='coerce')\n",
    "            rent_df = rent_df.dropna(subset=['价格'])\n",
    "            \n",
    "            if len(rent_df) > 0:\n",
    "                # 按小区和城市统计租金\n",
    "                if '城市' in rent_df.columns:\n",
    "                    rent_stats = rent_df.groupby(['小区名称', '城市'])['价格'].agg([\n",
    "                        'mean', 'median', 'count', 'std', 'min', 'max'\n",
    "                    ]).reset_index()\n",
    "                    rent_stats.columns = ['小区名称', '城市', '平均租金', '租金中位数', '租金样本数', '租金标准差', '最低租金', '最高租金']\n",
    "                    merge_keys = ['小区名称', '城市']\n",
    "                else:\n",
    "                    rent_stats = rent_df.groupby('小区名称')['价格'].agg([\n",
    "                        'mean', 'median', 'count', 'std', 'min', 'max'\n",
    "                    ]).reset_index()\n",
    "                    rent_stats.columns = ['小区名称', '平均租金', '租金中位数', '租金样本数', '租金标准差', '最低租金', '最高租金']\n",
    "                    merge_keys = ['小区名称']\n",
    "                \n",
    "                # 计算租金特征\n",
    "                rent_stats['租金变异系数'] = rent_stats['租金标准差'] / (rent_stats['平均租金'] + 1)\n",
    "                rent_stats['租金区间'] = rent_stats['最高租金'] - rent_stats['最低租金']\n",
    "                \n",
    "                # 填充缺失值\n",
    "                for col in ['平均租金', '租金中位数', '租金标准差', '最低租金', '最高租金']:\n",
    "                    if col in rent_stats.columns:\n",
    "                        rent_stats[col] = rent_stats[col].fillna(rent_stats[col].median())\n",
    "                \n",
    "                rent_stats['租金样本数'] = rent_stats['租金样本数'].fillna(0)\n",
    "                rent_stats['租金变异系数'] = rent_stats['租金变异系数'].fillna(0)\n",
    "                \n",
    "                # 合并租金数据\n",
    "                result_df = result_df.merge(rent_stats, on=merge_keys, how='left')\n",
    "                \n",
    "                # 全局租金填充\n",
    "                global_rent_median = rent_stats['平均租金'].median()\n",
    "                result_df['平均租金'] = result_df['平均租金'].fillna(global_rent_median)\n",
    "                result_df['租金中位数'] = result_df['租金中位数'].fillna(global_rent_median)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"合并租金数据失败: {e}\")\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def create_advanced_features(df, is_training=True, training_stats=None):\n",
    "    \"\"\"创建高级组合特征 - 确保训练测试集一致性\"\"\"\n",
    "    data = df.copy()\n",
    "    \n",
    "    if training_stats is None:\n",
    "        training_stats = {}\n",
    "    \n",
    "    # 1. 面积相关组合特征\n",
    "    if '建筑面积' in data.columns:\n",
    "        if '总房间数' in data.columns:\n",
    "            data['每房间面积'] = data['建筑面积'] / (data['总房间数'] + 1)\n",
    "            \n",
    "        if '室数' in data.columns:\n",
    "            data['每室面积'] = data['建筑面积'] / (data['室数'] + 1)\n",
    "            \n",
    "        # 面积分档 - 使用训练集的分位数\n",
    "        if is_training:\n",
    "            area_quantiles = data['建筑面积'].quantile([0.25, 0.75])\n",
    "            training_stats['area_q25'] = area_quantiles[0.25]\n",
    "            training_stats['area_q75'] = area_quantiles[0.75]\n",
    "        \n",
    "        if 'area_q25' in training_stats and 'area_q75' in training_stats:\n",
    "            data['面积_小户型'] = (data['建筑面积'] <= training_stats['area_q25']).astype(int)\n",
    "            data['面积_中户型'] = ((data['建筑面积'] > training_stats['area_q25']) & \n",
    "                                (data['建筑面积'] <= training_stats['area_q75'])).astype(int)\n",
    "            data['面积_大户型'] = (data['建筑面积'] > training_stats['area_q75']).astype(int)\n",
    "    \n",
    "    # 2. 租售比特征（核心特征）\n",
    "    if '平均租金' in data.columns and '建筑面积' in data.columns:\n",
    "        data['月租售比'] = data['平均租金'] / (data['建筑面积'] + 1)\n",
    "        data['年租售比'] = data['月租售比'] * 12\n",
    "        \n",
    "        # 租售比分档 - 使用训练集的分位数\n",
    "        if is_training and data['年租售比'].std() > 0:\n",
    "            rent_ratio_quantiles = data['年租售比'].quantile([0.33, 0.67])\n",
    "            training_stats['rent_ratio_q33'] = rent_ratio_quantiles[0.33]\n",
    "            training_stats['rent_ratio_q67'] = rent_ratio_quantiles[0.67]\n",
    "        \n",
    "        if 'rent_ratio_q33' in training_stats and 'rent_ratio_q67' in training_stats:\n",
    "            data['租售比_低'] = (data['年租售比'] <= training_stats['rent_ratio_q33']).astype(int)\n",
    "            data['租售比_中'] = ((data['年租售比'] > training_stats['rent_ratio_q33']) & \n",
    "                              (data['年租售比'] <= training_stats['rent_ratio_q67'])).astype(int)\n",
    "            data['租售比_高'] = (data['年租售比'] > training_stats['rent_ratio_q67']).astype(int)\n",
    "    \n",
    "    # 3. 位置价值综合评分\n",
    "    location_score = 0\n",
    "    if '环线价值' in data.columns:\n",
    "        location_score += data['环线价值'] * 0.4\n",
    "    if '朝向评分' in data.columns:\n",
    "        location_score += data['朝向评分'] / 10 * 0.2  # 归一化\n",
    "    if '楼层价值' in data.columns:\n",
    "        location_score += data['楼层价值'] * 0.2\n",
    "    if '通透性' in data.columns:\n",
    "        location_score += data['通透性'] / 2 * 0.2  # 归一化\n",
    "    \n",
    "    data['位置价值综合'] = location_score\n",
    "    \n",
    "    # 4. 房屋品质评分\n",
    "    quality_score = 0\n",
    "    if '装修评分' in data.columns:\n",
    "        quality_score += data['装修评分'] / 5 * 0.3  # 归一化\n",
    "    if '房龄价值' in data.columns:\n",
    "        quality_score += data['房龄价值'] * 0.3\n",
    "    if '有电梯' in data.columns:\n",
    "        quality_score += data['有电梯'] * 0.2\n",
    "    if '得房率' in data.columns:\n",
    "        quality_score += (data['得房率'] - 0.7) * 0.2  # 得房率越高越好\n",
    "    \n",
    "    data['房屋品质综合'] = quality_score\n",
    "    \n",
    "    # 5. 小区环境评分\n",
    "    community_score = 0\n",
    "    if '绿化率' in data.columns:\n",
    "        community_score += data['绿化率'] * 0.4\n",
    "    if '容积率' in data.columns:\n",
    "        # 容积率越低越好（取倒数）\n",
    "        community_score += (1 / (data['容积率'] + 1)) * 0.3\n",
    "    if '物业费' in data.columns:\n",
    "        # 物业费标准化（通常适中最好）\n",
    "        if is_training:\n",
    "            median_fee = data['物业费'].median()\n",
    "            training_stats['median_fee'] = median_fee\n",
    "        \n",
    "        if 'median_fee' in training_stats:\n",
    "            median_fee = training_stats['median_fee']\n",
    "            community_score += (1 - abs(data['物业费'] - median_fee) / median_fee) * 0.3\n",
    "    \n",
    "    data['小区环境综合'] = community_score\n",
    "    \n",
    "    # 6. 户型合理性评分\n",
    "    if all(col in data.columns for col in ['室数', '厅数', '卫数', '建筑面积']):\n",
    "        # 标准户型比例\n",
    "        ideal_ratios = {\n",
    "            1: (40, 60), 2: (60, 90), 3: (90, 130), \n",
    "            4: (130, 180), 5: (180, 250)\n",
    "        }\n",
    "        \n",
    "        data['户型合理性'] = 0.5  # 默认值\n",
    "        \n",
    "        for rooms in range(1, 6):\n",
    "            if rooms in ideal_ratios:\n",
    "                min_area, max_area = ideal_ratios[rooms]\n",
    "                mask = data['室数'] == rooms\n",
    "                area_fit = ((data['建筑面积'] >= min_area) & \n",
    "                           (data['建筑面积'] <= max_area))\n",
    "                data.loc[mask & area_fit, '户型合理性'] = 1.0\n",
    "                data.loc[mask & ~area_fit, '户型合理性'] = 0.3\n",
    "    \n",
    "    # 7. 市场热度特征（基于租金样本数）\n",
    "    if '租金样本数' in data.columns:\n",
    "        data['市场热度'] = np.log1p(data['租金样本数'])  # 对数变换\n",
    "        \n",
    "        # 热度分档 - 使用训练集的分位数\n",
    "        if is_training and data['市场热度'].std() > 0:\n",
    "            heat_quantiles = data['市场热度'].quantile([0.33, 0.67])\n",
    "            training_stats['heat_q33'] = heat_quantiles[0.33]\n",
    "            training_stats['heat_q67'] = heat_quantiles[0.67]\n",
    "        \n",
    "        if 'heat_q33' in training_stats and 'heat_q67' in training_stats:\n",
    "            data['市场_冷门'] = (data['市场热度'] <= training_stats['heat_q33']).astype(int)\n",
    "            data['市场_一般'] = ((data['市场热度'] > training_stats['heat_q33']) & \n",
    "                              (data['市场热度'] <= training_stats['heat_q67'])).astype(int)\n",
    "            data['市场_热门'] = (data['市场热度'] > training_stats['heat_q67']).astype(int)\n",
    "    \n",
    "    return data, training_stats\n",
    "\n",
    "def advanced_preprocessing(X_train, X_test, feature_types):\n",
    "    \"\"\"高级预处理\"\"\"\n",
    "    X_train_processed = X_train.copy()\n",
    "    X_test_processed = X_test.copy()\n",
    "    \n",
    "    print(f\"高级预处理开始...\")\n",
    "    print(f\"训练集形状: {X_train_processed.shape}\")\n",
    "    print(f\"测试集形状: {X_test_processed.shape}\")\n",
    "    print(f\"数值特征数量: {len(feature_types['numeric'])}\")\n",
    "    print(f\"分类特征数量: {len(feature_types['categorical'])}\")\n",
    "    \n",
    "    # 1. 数值特征处理\n",
    "    numeric_features = feature_types['numeric']\n",
    "    processed_numeric = 0\n",
    "    \n",
    "    for feat in numeric_features:\n",
    "        if feat in X_train_processed.columns:\n",
    "            # 严格的数据类型检查\n",
    "            dtype = X_train_processed[feat].dtype\n",
    "            \n",
    "            # 跳过非数值类型\n",
    "            if dtype in ['object', 'datetime64[ns]', 'timedelta64[ns]', 'category']:\n",
    "                print(f\"  跳过非数值特征: {feat} (类型: {dtype})\")\n",
    "                continue\n",
    "            \n",
    "            # 转换为数值类型\n",
    "            try:\n",
    "                X_train_processed[feat] = pd.to_numeric(X_train_processed[feat], errors='coerce')\n",
    "                X_test_processed[feat] = pd.to_numeric(X_test_processed[feat], errors='coerce')\n",
    "            except:\n",
    "                print(f\"  无法转换为数值: {feat}\")\n",
    "                continue\n",
    "                \n",
    "            # 计算填充值（使用众数或中位数）\n",
    "            if X_train_processed[feat].nunique() <= 10:  # 离散数值特征\n",
    "                fill_value = X_train_processed[feat].mode()\n",
    "                fill_value = fill_value[0] if len(fill_value) > 0 else 0\n",
    "            else:  # 连续数值特征\n",
    "                fill_value = X_train_processed[feat].median()\n",
    "                if pd.isna(fill_value):\n",
    "                    fill_value = 0\n",
    "            \n",
    "            X_train_processed[feat] = X_train_processed[feat].fillna(fill_value)\n",
    "            X_test_processed[feat] = X_test_processed[feat].fillna(fill_value)\n",
    "            \n",
    "            # 温和的异常值处理（使用更大的倍数）\n",
    "            try:\n",
    "                std_val = X_train_processed[feat].std()\n",
    "                if pd.notna(std_val) and std_val > 0:\n",
    "                    Q1 = X_train_processed[feat].quantile(0.25)\n",
    "                    Q3 = X_train_processed[feat].quantile(0.75)\n",
    "                    IQR = Q3 - Q1\n",
    "                    \n",
    "                    if IQR > 0:\n",
    "                        lower_bound = Q1 - 5 * IQR  # 更宽松的界限\n",
    "                        upper_bound = Q3 + 5 * IQR\n",
    "                        \n",
    "                        X_train_processed[feat] = X_train_processed[feat].clip(lower_bound, upper_bound)\n",
    "                        X_test_processed[feat] = X_test_processed[feat].clip(lower_bound, upper_bound)\n",
    "                        processed_numeric += 1\n",
    "            except Exception as e:\n",
    "                print(f\"  异常值处理失败: {feat} - {e}\")\n",
    "                continue\n",
    "    \n",
    "    print(f\"成功处理数值特征: {processed_numeric}/{len(numeric_features)}\")\n",
    "    \n",
    "    # 2. 分类特征处理\n",
    "    le_dict = {}\n",
    "    categorical_features = feature_types['categorical']\n",
    "    processed_categorical = 0\n",
    "    \n",
    "    for feat in categorical_features:\n",
    "        if feat in X_train_processed.columns:\n",
    "            try:\n",
    "                # 填充缺失值\n",
    "                mode_val = X_train_processed[feat].mode()\n",
    "                fill_val = mode_val[0] if len(mode_val) > 0 else '其他'\n",
    "                \n",
    "                X_train_processed[feat] = X_train_processed[feat].fillna(fill_val).astype(str)\n",
    "                X_test_processed[feat] = X_test_processed[feat].fillna(fill_val).astype(str)\n",
    "                \n",
    "                # 处理低频类别\n",
    "                value_counts = X_train_processed[feat].value_counts()\n",
    "                rare_categories = value_counts[value_counts < 5].index  # 少于5个样本的类别\n",
    "                \n",
    "                X_train_processed[feat] = X_train_processed[feat].replace(rare_categories, '其他')\n",
    "                X_test_processed[feat] = X_test_processed[feat].replace(rare_categories, '其他')\n",
    "                \n",
    "                # 标签编码\n",
    "                le = LabelEncoder()\n",
    "                le.fit(X_train_processed[feat])\n",
    "                \n",
    "                X_train_processed[feat] = le.transform(X_train_processed[feat])\n",
    "                \n",
    "                def safe_transform(x):\n",
    "                    try:\n",
    "                        return le.transform([x])[0]\n",
    "                    except:\n",
    "                        return 0\n",
    "                \n",
    "                X_test_processed[feat] = X_test_processed[feat].apply(safe_transform)\n",
    "                le_dict[feat] = le\n",
    "                processed_categorical += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  分类特征处理失败: {feat} - {e}\")\n",
    "                continue\n",
    "    \n",
    "    print(f\"成功处理分类特征: {processed_categorical}/{len(categorical_features)}\")\n",
    "    \n",
    "    # 3. 最终数据清理\n",
    "    X_train_processed = X_train_processed.fillna(0)\n",
    "    X_test_processed = X_test_processed.fillna(0)\n",
    "    X_train_processed = X_train_processed.replace([np.inf, -np.inf], 0)\n",
    "    X_test_processed = X_test_processed.replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "    print(f\"预处理完成:\")\n",
    "    print(f\"  训练集最终形状: {X_train_processed.shape}\")\n",
    "    print(f\"  测试集最终形状: {X_test_processed.shape}\")\n",
    "    print(f\"  训练集缺失值: {X_train_processed.isnull().sum().sum()}\")\n",
    "    print(f\"  测试集缺失值: {X_test_processed.isnull().sum().sum()}\")\n",
    "    \n",
    "    return X_train_processed, X_test_processed, le_dict\n",
    "\n",
    "def feature_selection(X_train, y_train, feature_names, n_features=50):\n",
    "    \"\"\"特征选择\"\"\"\n",
    "    print(f\"\\n 进行特征选择...\")\n",
    "    print(f\"原始特征数: {X_train.shape[1]}\")\n",
    "    \n",
    "    # 1. 移除低方差特征\n",
    "    from sklearn.feature_selection import VarianceThreshold\n",
    "    var_selector = VarianceThreshold(threshold=0.01)\n",
    "    X_var = var_selector.fit_transform(X_train)\n",
    "    selected_features = [feature_names[i] for i in range(len(feature_names)) \n",
    "                        if var_selector.get_support()[i]]\n",
    "    \n",
    "    print(f\"移除低方差特征后: {len(selected_features)}\")\n",
    "    \n",
    "    # 2. 使用统计方法选择特征\n",
    "    k_best = SelectKBest(score_func=f_regression, k=min(n_features, len(selected_features)))\n",
    "    X_selected = k_best.fit_transform(X_var, y_train)\n",
    "    \n",
    "    # 获取最终选择的特征名\n",
    "    feature_scores = k_best.scores_\n",
    "    selected_indices = k_best.get_support(indices=True)\n",
    "    final_features = [selected_features[i] for i in selected_indices]\n",
    "    \n",
    "    print(f\"统计特征选择后: {len(final_features)}\")\n",
    "    \n",
    "    # 显示最重要的特征\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': final_features,\n",
    "        'score': [feature_scores[i] for i in selected_indices]\n",
    "    }).sort_values('score', ascending=False)\n",
    "    \n",
    "    print(f\"前10个最重要特征:\")\n",
    "    print(feature_importance.head(10))\n",
    "    \n",
    "    return var_selector, k_best, final_features\n",
    "\n",
    "def train_advanced_models(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"训练高级模型\"\"\"\n",
    "    \n",
    "    # 数据标准化\n",
    "    scaler = RobustScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    models = {}\n",
    "    \n",
    "    # 传统模型（优化参数）\n",
    "    models['Ridge'] = Ridge(alpha=5.0, random_state=42)\n",
    "    models['Lasso'] = Lasso(alpha=0.01, random_state=42, max_iter=5000)\n",
    "    models['ElasticNet'] = ElasticNet(alpha=0.01, l1_ratio=0.7, random_state=42, max_iter=5000)\n",
    "    \n",
    "    # 树模型（优化参数）\n",
    "    models['RandomForest'] = RandomForestRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=20,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        max_features='sqrt',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    models['ExtraTrees'] = ExtraTreesRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=20,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        max_features='sqrt',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    models['GradientBoosting'] = GradientBoostingRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        max_features='sqrt',\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # 高性能模型\n",
    "    if HAS_XGB:\n",
    "        models['XGBoost'] = xgb.XGBRegressor(\n",
    "            n_estimators=300,\n",
    "            max_depth=8,\n",
    "            learning_rate=0.05,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    \n",
    "    if HAS_LGB:\n",
    "        models['LightGBM'] = lgb.LGBMRegressor(\n",
    "            n_estimators=300,\n",
    "            max_depth=8,\n",
    "            learning_rate=0.05,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbose=-1\n",
    "        )\n",
    "    \n",
    "    results = []\n",
    "    trained_models = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n训练模型: {name}\")\n",
    "        \n",
    "        try:\n",
    "            # 选择输入数据\n",
    "            if name in ['Ridge', 'Lasso', 'ElasticNet']:\n",
    "                X_tr, X_te = X_train_scaled, X_test_scaled\n",
    "            else:\n",
    "                X_tr, X_te = X_train, X_test\n",
    "            \n",
    "            # 训练模型\n",
    "            model.fit(X_tr, y_train)\n",
    "            \n",
    "            # 预测\n",
    "            train_pred = model.predict(X_tr)\n",
    "            test_pred = model.predict(X_te)\n",
    "            \n",
    "            # 计算指标\n",
    "            train_mae = mean_absolute_error(y_train, train_pred)\n",
    "            test_mae = mean_absolute_error(y_test, test_pred)\n",
    "            train_r2 = r2_score(y_train, train_pred)\n",
    "            test_r2 = r2_score(y_test, test_pred)\n",
    "            \n",
    "            # 交叉验证\n",
    "            kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "            cv_scores = cross_val_score(model, X_tr, y_train, cv=kfold, scoring='neg_mean_absolute_error')\n",
    "            cv_mae = -cv_scores.mean()\n",
    "            cv_std = cv_scores.std()\n",
    "            \n",
    "            results.append({\n",
    "                '模型': name,\n",
    "                '训练MAE': train_mae,\n",
    "                '测试MAE': test_mae,\n",
    "                '训练R2': train_r2,\n",
    "                '测试R2': test_r2,\n",
    "                'CV_MAE': cv_mae,\n",
    "                'CV_STD': cv_std\n",
    "            })\n",
    "            \n",
    "            trained_models[name] = (model, scaler if name in ['Ridge', 'Lasso', 'ElasticNet'] else None)\n",
    "            \n",
    "            print(f\"{name}:\")\n",
    "            print(f\"   测试MAE: {test_mae:.0f}\")\n",
    "            print(f\"   测试R2: {test_r2:.4f}\")\n",
    "            print(f\"   CV MAE: {cv_mae:.0f} ± {cv_std:.0f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"{name} 训练失败: {str(e)}\")\n",
    "    \n",
    "    return pd.DataFrame(results), trained_models\n",
    "\n",
    "def create_meta_ensemble(trained_models, X_train, y_train, X_val, y_val):\n",
    "    \"\"\"创建元学习集成模型 - 修复版本\"\"\"\n",
    "    print(f\"\\n🔗 创建元学习集成...\")\n",
    "    \n",
    "    if len(trained_models) < 2:\n",
    "        print(\"  模型数量不足，跳过元学习\")\n",
    "        return None, None\n",
    "    \n",
    "    # 准备元特征\n",
    "    meta_features_train = []\n",
    "    meta_features_val = []\n",
    "    model_names = []\n",
    "    \n",
    "    for name, (model, scaler) in trained_models.items():\n",
    "        try:\n",
    "            print(f\"  生成 {name} 的元特征...\")\n",
    "            \n",
    "            if scaler:\n",
    "                X_tr_scaled = scaler.fit_transform(X_train)\n",
    "                X_val_scaled = scaler.transform(X_val)\n",
    "                \n",
    "                # 重新训练模型\n",
    "                model.fit(X_tr_scaled, y_train)\n",
    "                train_pred = model.predict(X_tr_scaled)\n",
    "                val_pred = model.predict(X_val_scaled)\n",
    "            else:\n",
    "                # 重新训练模型\n",
    "                model.fit(X_train, y_train)\n",
    "                train_pred = model.predict(X_train)\n",
    "                val_pred = model.predict(X_val)\n",
    "            \n",
    "            meta_features_train.append(train_pred)\n",
    "            meta_features_val.append(val_pred)\n",
    "            model_names.append(name)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  模型 {name} 生成元特征失败: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if len(meta_features_train) < 2:\n",
    "        print(\"  可用模型不足，跳过元学习\")\n",
    "        return None, None\n",
    "    \n",
    "    # 构建元特征矩阵\n",
    "    meta_X_train = np.column_stack(meta_features_train)\n",
    "    meta_X_val = np.column_stack(meta_features_val)\n",
    "    \n",
    "    # 训练元学习器（简单线性回归）\n",
    "    meta_model = Ridge(alpha=1.0)\n",
    "    meta_model.fit(meta_X_train, y_train)\n",
    "    \n",
    "    # 验证元模型\n",
    "    meta_pred = meta_model.predict(meta_X_val)\n",
    "    meta_mae = mean_absolute_error(y_val, meta_pred)\n",
    "    meta_r2 = r2_score(y_val, meta_pred)\n",
    "    \n",
    "    print(f\"元学习集成完成:\")\n",
    "    print(f\"   使用模型: {', '.join(model_names)}\")\n",
    "    print(f\"   验证MAE: {meta_mae:.0f}\")\n",
    "    print(f\"   验证R2: {meta_r2:.4f}\")\n",
    "    \n",
    "    return meta_model, model_names\n",
    "\n",
    "def main():\n",
    "    # 数据路径\n",
    "    train_path = \"ruc_Class25Q1_train.csv\"\n",
    "    test_path = \"ruc_Class25Q1_test.csv\"\n",
    "    community_path = \"ruc_Class25Q1_details.csv\"\n",
    "    rent_path = \"ruc_Class25Q1_rent.csv\"\n",
    "    \n",
    "    print(f\"\\n数据加载中...\")\n",
    "    \n",
    "    # 加载数据\n",
    "    try:\n",
    "        train_data = pd.read_csv(train_path)\n",
    "        test_data = pd.read_csv(test_path)\n",
    "        print(f\"主数据加载成功\")\n",
    "        print(f\"   训练集: {train_data.shape}\")\n",
    "        print(f\"   测试集: {test_data.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"主数据加载失败: {e}\")\n",
    "        return None, None\n",
    "    \n",
    "    # 加载辅助数据\n",
    "    community_data, rent_data = None, None\n",
    "    try:\n",
    "        community_data = pd.read_csv(community_path)\n",
    "        print(f\"小区数据: {community_data.shape}\")\n",
    "    except:\n",
    "        print(f\"小区数据加载失败\")\n",
    "    \n",
    "    try:\n",
    "        rent_data = pd.read_csv(rent_path)\n",
    "        print(f\"租金数据: {rent_data.shape}\")\n",
    "    except:\n",
    "        print(f\"租金数据加载失败\")\n",
    "    \n",
    "    # 保存测试集ID\n",
    "    original_test_ids = test_data['ID'].copy()\n",
    "    \n",
    "    print(f\"\\n高级特征工程...\")\n",
    "    \n",
    "    # 特征工程流水线 - 添加长度监控\n",
    "    print(\"基础特征提取...\")\n",
    "    print(f\"   处理前 - 训练集: {len(train_data)}, 测试集: {len(test_data)}\")\n",
    "    \n",
    "    train_processed, training_stats = advanced_feature_engineering(train_data, is_training=True)\n",
    "    test_processed, _ = advanced_feature_engineering(test_data, is_training=False, training_stats=training_stats)\n",
    "    \n",
    "    print(f\"   处理后 - 训练集: {len(train_processed)}, 测试集: {len(test_processed)}\")\n",
    "    \n",
    "    print(\"外部数据融合...\")\n",
    "    train_merged = advanced_external_merge(train_processed, community_data, rent_data)\n",
    "    test_merged = advanced_external_merge(test_processed, community_data, rent_data)\n",
    "    \n",
    "    print(f\"   融合后 - 训练集: {len(train_merged)}, 测试集: {len(test_merged)}\")\n",
    "    \n",
    "    # 如果测试集长度发生变化，去重处理\n",
    "    if len(test_merged) != len(test_data):\n",
    "        print(f\" 测试集长度变化: {len(test_data)} -> {len(test_merged)}\")\n",
    "        print(\"   进行去重处理...\")\n",
    "        \n",
    "        # 按ID去重，保持第一次出现的记录\n",
    "        if 'ID' in test_merged.columns:\n",
    "            test_merged = test_merged.drop_duplicates(subset=['ID'], keep='first')\n",
    "            print(f\"   去重后测试集长度: {len(test_merged)}\")\n",
    "            \n",
    "            # 确保ID顺序与原始一致\n",
    "            test_merged = test_merged.set_index('ID').reindex(original_test_ids).reset_index()\n",
    "            print(f\"   重排序后测试集长度: {len(test_merged)}\")\n",
    "    \n",
    "    print(\"高级组合特征...\")\n",
    "    train_final, feature_stats = create_advanced_features(train_merged, is_training=True)\n",
    "    test_final, _ = create_advanced_features(test_merged, is_training=False, training_stats=feature_stats)\n",
    "    \n",
    "    print(f\"   最终 - 训练集: {len(train_final)}, 测试集: {len(test_final)}\")\n",
    "    \n",
    "    # 最终确保测试集长度正确\n",
    "    if len(test_final) != len(original_test_ids):\n",
    "        print(f\"测试集长度仍然不匹配: {len(test_final)} vs {len(original_test_ids)}\")\n",
    "        \n",
    "        # 强制修正\n",
    "        if 'ID' in test_final.columns:\n",
    "            # 按原始ID顺序重建测试集\n",
    "            test_final_indexed = test_final.set_index('ID')\n",
    "            test_final = test_final_indexed.reindex(original_test_ids).reset_index()\n",
    "            \n",
    "            # 填充缺失行（如果有的话）\n",
    "            test_final = test_final.ffill().bfill().fillna(0)\n",
    "            print(f\"   修正后测试集长度: {len(test_final)}\")\n",
    "        else:\n",
    "            # 如果没有ID列，直接截取\n",
    "            test_final = test_final.iloc[:len(original_test_ids)]\n",
    "            print(f\"   截取后测试集长度: {len(test_final)}\")\n",
    "    \n",
    "    # 特征选择 - 确保训练集和测试集特征一致，并排除问题特征\n",
    "    train_features = set(train_final.columns)\n",
    "    test_features = set(test_final.columns)\n",
    "    common_features = list(train_features & test_features)\n",
    "    \n",
    "    # 排除不需要的列\n",
    "    exclude_columns = ['ID', '价格', 'Unnamed: 0', '交易时间', '小区名称', '名称'] + \\\n",
    "                     [col for col in common_features if col.endswith('_clean')]\n",
    "    \n",
    "    all_features = [col for col in common_features \n",
    "                   if col not in exclude_columns]\n",
    "    \n",
    "    print(f\"训练集特征数: {len(train_features)}\")\n",
    "    print(f\"测试集特征数: {len(test_features)}\")\n",
    "    print(f\"共同特征数: {len(common_features)}\")\n",
    "    print(f\"排除特征数: {len(exclude_columns)}\")\n",
    "    print(f\"可用特征数: {len(all_features)}\")\n",
    "    \n",
    "    # 分离数值和分类特征\n",
    "    numeric_features = []\n",
    "    categorical_features = []\n",
    "    \n",
    "    for col in all_features:\n",
    "        if col in train_final.columns:\n",
    "            if train_final[col].dtype in ['object']:\n",
    "                categorical_features.append(col)\n",
    "            else:\n",
    "                numeric_features.append(col)\n",
    "    \n",
    "    feature_types = {\n",
    "        'numeric': numeric_features,\n",
    "        'categorical': categorical_features\n",
    "    }\n",
    "    \n",
    "    # 准备训练数据 - 安全的特征选择\n",
    "    available_features_train = [col for col in all_features if col in train_final.columns]\n",
    "    available_features_test = [col for col in all_features if col in test_final.columns]\n",
    "    final_features = list(set(available_features_train) & set(available_features_test))\n",
    "    \n",
    "    print(f\"最终使用特征数: {len(final_features)}\")\n",
    "    \n",
    "    if len(final_features) == 0:\n",
    "        print(\"没有可用的共同特征!\")\n",
    "        return None, None\n",
    "    \n",
    "    X = train_final[final_features]\n",
    "    y = train_final['价格']\n",
    "    X_submit = test_final[final_features]\n",
    "    \n",
    "    print(f\"\\n特征统计:\")\n",
    "    print(f\"   总特征数: {len(all_features)}\")\n",
    "    print(f\"   数值特征: {len(numeric_features)}\")\n",
    "    print(f\"   分类特征: {len(categorical_features)}\")\n",
    "    \n",
    "    # 异常值处理（更温和）- 只对训练集进行\n",
    "    print(f\"\\n🔍 异常值处理...\")\n",
    "    Q1 = y.quantile(0.05)  # 更宽松的界限\n",
    "    Q3 = y.quantile(0.95)\n",
    "    mask = (y >= Q1) & (y <= Q3)\n",
    "    \n",
    "    X_clean = X[mask]\n",
    "    y_clean = y[mask]\n",
    "    \n",
    "    print(f\"   原始训练样本: {len(X)}\")\n",
    "    print(f\"   清洗后训练样本: {len(X_clean)}\")\n",
    "    print(f\"   移除比例: {(1 - len(X_clean)/len(X))*100:.1f}%\")\n",
    "    print(f\"   测试集保持不变: {len(X_submit)} 样本\")\n",
    "    \n",
    "    # 检查测试集长度是否匹配\n",
    "    if len(X_submit) != len(original_test_ids):\n",
    "        print(f\"测试集长度不匹配: {len(X_submit)} vs {len(original_test_ids)}\")\n",
    "        print(\"   尝试修正测试集长度...\")\n",
    "        \n",
    "        if len(X_submit) > len(original_test_ids):\n",
    "            # 如果测试集变长了，截取到原始长度\n",
    "            X_submit = X_submit.iloc[:len(original_test_ids)]\n",
    "            print(f\"   截取后测试集长度: {len(X_submit)}\")\n",
    "        else:\n",
    "            # 如果测试集变短了，用最后一行填充\n",
    "            last_row = X_submit.iloc[-1:] if len(X_submit) > 0 else pd.DataFrame()\n",
    "            while len(X_submit) < len(original_test_ids):\n",
    "                X_submit = pd.concat([X_submit, last_row], ignore_index=True)\n",
    "            print(f\"   填充后测试集长度: {len(X_submit)}\")\n",
    "    \n",
    "    # 最终确保长度匹配\n",
    "    assert len(X_submit) == len(original_test_ids), f\"修正后测试集长度仍不匹配: {len(X_submit)} vs {len(original_test_ids)}\"\n",
    "    \n",
    "    # 数据分割\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_clean, y_clean, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n 数据预处理...\")\n",
    "    X_train_processed, X_val_processed, le_dict = advanced_preprocessing(X_train, X_val, feature_types)\n",
    "    X_train_processed, X_submit_processed, _ = advanced_preprocessing(X_train_processed, X_submit, feature_types)\n",
    "    \n",
    "    # 长度检查\n",
    "    print(f\"预处理后长度检查:\")\n",
    "    print(f\"  训练集: {len(X_train_processed)}\")\n",
    "    print(f\"  验证集: {len(X_val_processed)}\")  \n",
    "    print(f\"  测试集: {len(X_submit_processed)}\")\n",
    "    print(f\"  原始测试ID: {len(original_test_ids)}\")       \n",
    "    print(f\"修正后测试集长度: {len(X_submit_processed)}\")\n",
    "    \n",
    "    # 特征选择\n",
    "    var_selector, k_best, selected_features = feature_selection(\n",
    "        X_train_processed, y_train, X_train_processed.columns, n_features=60\n",
    "    )\n",
    "    \n",
    "    # 应用特征选择\n",
    "    X_train_selected = k_best.transform(var_selector.transform(X_train_processed))\n",
    "    X_val_selected = k_best.transform(var_selector.transform(X_val_processed))\n",
    "    X_submit_selected = k_best.transform(var_selector.transform(X_submit_processed))\n",
    "    \n",
    "    # 特征选择后长度检查\n",
    "    print(f\"特征选择后长度检查:\")\n",
    "    print(f\"  训练集: {X_train_selected.shape}\")\n",
    "    print(f\"  验证集: {X_val_selected.shape}\")\n",
    "    print(f\"  测试集: {X_submit_selected.shape}\")\n",
    "    \n",
    "    # 确保测试集行数正确\n",
    "    assert X_submit_selected.shape[0] == len(original_test_ids), f\"特征选择后长度不匹配: {X_submit_selected.shape[0]} vs {len(original_test_ids)}\"\n",
    "    \n",
    "    print(f\"\\n模型训练开始...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 训练高级模型\n",
    "    results_df, trained_models = train_advanced_models(\n",
    "        X_train_selected, X_val_selected, y_train, y_val\n",
    "    )\n",
    "    \n",
    "    # 显示结果\n",
    "    if len(results_df) > 0:\n",
    "        print(f\"\\n模型性能排行榜:\")\n",
    "        print(\"=\" * 80)\n",
    "        results_sorted = results_df.sort_values('CV_MAE')\n",
    "        print(results_sorted[['模型', '测试MAE', '测试R2', 'CV_MAE', 'CV_STD']].to_string(index=False))\n",
    "        \n",
    "        # 创建元学习集成\n",
    "        meta_model, meta_model_names = create_meta_ensemble(\n",
    "            trained_models, X_train_selected, y_train, X_val_selected, y_val\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n最终预测生成...\")\n",
    "        \n",
    "        # 选择最佳模型\n",
    "        best_model_name = results_sorted.iloc[0]['模型']\n",
    "        best_model, best_scaler = trained_models[best_model_name]\n",
    "        \n",
    "        print(f\"最佳单一模型: {best_model_name}\")\n",
    "        \n",
    "        # 重新训练最佳模型\n",
    "        X_full_train = np.vstack([X_train_selected, X_val_selected])\n",
    "        y_full_train = np.hstack([y_train, y_val])\n",
    "        \n",
    "        if best_scaler:\n",
    "            X_full_scaled = best_scaler.fit_transform(X_full_train)\n",
    "            X_submit_scaled = best_scaler.transform(X_submit_selected)\n",
    "            best_model.fit(X_full_scaled, y_full_train)\n",
    "            best_predictions = best_model.predict(X_submit_scaled)\n",
    "        else:\n",
    "            best_model.fit(X_full_train, y_full_train)\n",
    "            best_predictions = best_model.predict(X_submit_selected)\n",
    "        \n",
    "        # 预测长度检查\n",
    "        print(f\"预测长度检查:\")\n",
    "        print(f\"  预测结果: {len(best_predictions)}\")\n",
    "        print(f\"  原始测试ID: {len(original_test_ids)}\")\n",
    "        \n",
    "        # 确保预测长度正确\n",
    "        if len(best_predictions) != len(original_test_ids):\n",
    "            print(f\"预测长度不匹配，进行修正...\")\n",
    "            if len(best_predictions) > len(original_test_ids):\n",
    "                best_predictions = best_predictions[:len(original_test_ids)]\n",
    "            else:\n",
    "                print(f\" 预测结果过短: {len(best_predictions)} < {len(original_test_ids)}\")\n",
    "                return None, None\n",
    "        \n",
    "        final_predictions = best_predictions\n",
    "        \n",
    "        # 如果有元学习模型，进行集成\n",
    "        if meta_model and meta_model_names:\n",
    "            print(f\"🔗 应用元学习集成...\")\n",
    "            # 生成元特征\n",
    "            meta_features_submit = []\n",
    "            for name in meta_model_names:\n",
    "                model, scaler = trained_models[name]\n",
    "                \n",
    "                # 重新训练每个模型\n",
    "                if scaler:\n",
    "                    X_full_scaled = scaler.fit_transform(X_full_train)\n",
    "                    X_submit_scaled = scaler.transform(X_submit_selected)\n",
    "                    model.fit(X_full_scaled, y_full_train)\n",
    "                    pred = model.predict(X_submit_scaled)\n",
    "                else:\n",
    "                    model.fit(X_full_train, y_full_train)\n",
    "                    pred = model.predict(X_submit_selected)\n",
    "                    \n",
    "                meta_features_submit.append(pred)\n",
    "            \n",
    "            if len(meta_features_submit) > 0:\n",
    "                meta_X_submit = np.column_stack(meta_features_submit)\n",
    "                \n",
    "                # 检查元特征长度\n",
    "                print(f\"元特征长度检查: {meta_X_submit.shape[0]} vs {len(original_test_ids)}\")\n",
    "                \n",
    "                # 重新训练元模型\n",
    "                # 生成训练时的元特征\n",
    "                meta_features_train = []\n",
    "                for name in meta_model_names:\n",
    "                    model, scaler = trained_models[name]\n",
    "                    if scaler:\n",
    "                        X_scaled = scaler.fit_transform(X_full_train)\n",
    "                        model.fit(X_scaled, y_full_train)\n",
    "                        pred = model.predict(X_scaled)\n",
    "                    else:\n",
    "                        model.fit(X_full_train, y_full_train)\n",
    "                        pred = model.predict(X_full_train)\n",
    "                    meta_features_train.append(pred)\n",
    "                \n",
    "                meta_X_train = np.column_stack(meta_features_train)\n",
    "                meta_model.fit(meta_X_train, y_full_train)\n",
    "                ensemble_predictions = meta_model.predict(meta_X_submit)\n",
    "                \n",
    "                # 长度匹配检查\n",
    "                if len(ensemble_predictions) == len(best_predictions):\n",
    "                    # 混合预测（给最佳模型更高权重）\n",
    "                    final_predictions = 0.8 * best_predictions + 0.2 * ensemble_predictions\n",
    "                    print(f\"使用集成预测 (最佳模型80% + 元学习20%)\")\n",
    "                else:\n",
    "                    print(f\"集成预测长度不匹配，使用最佳单一模型\")\n",
    "            else:\n",
    "                print(f\"元学习特征生成失败，使用最佳单一模型\")\n",
    "        else:\n",
    "            print(f\"使用最佳单一模型预测\")\n",
    "        \n",
    "        # 创建提交文件\n",
    "        print(f\"\\n创建提交文件...\")\n",
    "        print(f\"最终长度检查:\")\n",
    "        print(f\"  预测结果: {len(final_predictions)}\")\n",
    "        print(f\"  测试集ID: {len(original_test_ids)}\")\n",
    "        \n",
    "        # 最终长度确保\n",
    "        if len(final_predictions) != len(original_test_ids):\n",
    "            print(f\"最终长度不匹配，进行修正...\")\n",
    "            min_length = min(len(final_predictions), len(original_test_ids))\n",
    "            final_predictions = final_predictions[:min_length]\n",
    "            test_ids_to_use = original_test_ids.iloc[:min_length]\n",
    "        else:\n",
    "            test_ids_to_use = original_test_ids\n",
    "        \n",
    "        submission = pd.DataFrame({\n",
    "            'ID': test_ids_to_use,\n",
    "            '价格': final_predictions\n",
    "        })\n",
    "        \n",
    "        submission.to_csv('high_performance_submission.csv', index=False)\n",
    "        \n",
    "        print(f\"\\n预测完成!\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"预测统计:\")\n",
    "        print(f\"   样本数量: {len(submission)}\")\n",
    "        print(f\"   价格范围: {submission['价格'].min():.0f} - {submission['价格'].max():.0f}\")\n",
    "        print(f\"   平均价格: {submission['价格'].mean():.0f}\")\n",
    "        print(f\"   中位价格: {submission['价格'].median():.0f}\")\n",
    "        print(f\"   标准差: {submission['价格'].std():.0f}\")\n",
    "        print(f\"\\n文件保存: high_performance_submission.csv\")\n",
    "        \n",
    "        return submission, results_df\n",
    "    \n",
    "    else:\n",
    "        print(\"没有成功训练的模型\")\n",
    "        return None, None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    submission, results = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00a42c0-2530-420c-97a5-f36b66baf1ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
