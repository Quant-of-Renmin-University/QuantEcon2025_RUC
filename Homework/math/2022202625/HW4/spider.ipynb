{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【回龙观二手房|北京回龙观二手房出售】 - 北京房天下\n",
      "https://esf.fang.com/house-a012-b01182/\n",
      "chrome\n"
     ]
    }
   ],
   "source": [
    "#测试selenium\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "\n",
    "\n",
    "# browser.get('https://esf.fang.com/')\n",
    "#回龙观房价\n",
    "browser.get('https://esf.fang.com/house-a012-b01182/')\n",
    "\n",
    "\n",
    "# 打印网页标题、URL 和浏览器名称\n",
    "print(browser.title)\n",
    "print(browser.current_url)\n",
    "print(browser.name)\n",
    "\n",
    "# 关闭浏览器\n",
    "browser.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#原始代码\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.by import By\n",
    "# import time\n",
    "# import pandas as pd\n",
    "\n",
    "# # 启动 WebDriver\n",
    "# browser = webdriver.Chrome()\n",
    "\n",
    "# # 访问目标网站\n",
    "# browser.get(\"https://esf.fang.com/house-a012-b01182/i31\")  # page1 \n",
    "# website_template = 'https://esf.fang.com/house-a012-b01182/i{}'\n",
    "# #https://esf.fang.com/house-a012-b01182/i32/ # page2\n",
    "# #https://esf.fang.com/house-a012-b01182/i33/ # page3\n",
    "# time.sleep(3)  # 等待页面加载\n",
    "\n",
    "# # 定义 XPath 模板（请根据实际页面结构修改）\n",
    "# title_xpath_template ='/html/body/div[4]/div[4]/div[4]/dl[{}]/dd[1]/h4/a' \n",
    "# #标题 /html/body/div[4]/div[4]/div[4]/dl[1]/dd[1]/h4/a/span     /html/body/div[4]/div[4]/div[4]/dl[2]/dd[1]/h4/a/span\n",
    "# #title = browser.find_element(By.XPATH, title_xpath_template.format(i)).text\n",
    "\n",
    "# #布局 /html/body/div[4]/div[4]/div[4]/dl[1]/dd[1]/p[1]/text()[1]\n",
    "\n",
    "# #面积 /html/body/div[4]/div[4]/div[4]/dl[1]/dd[1]/p[1]/text()[2]\n",
    "# size_xpath_template ='/html/body/div[4]/div[4]/div[4]/dl[{}]/dd[1]/p[1]/text()[2]'\n",
    "# #size = browser.find_element(By.XPATH, size_xpath_template.format(i))\n",
    "\n",
    "# #层高 /html/body/div[4]/div[4]/div[4]/dl[1]/dd[1]/p[1]/a\n",
    "\n",
    "# #朝向 /html/body/div[4]/div[4]/div[4]/dl[1]/dd[1]/p[1]/text()[4]\n",
    "\n",
    "# #年份 /html/body/div[4]/div[4]/div[4]/dl[1]/dd[1]/p[1]/text()[5]\n",
    "\n",
    "# #位置 /html/body/div[4]/div[4]/div[4]/dl[1]/dd[1]/p[2]/span\n",
    "# location_xpath_template ='/html/body/div[4]/div[4]/div[4]/dl[{}]/dd[1]/p[2]/span'\n",
    "# #location = browser.find_element(By.XPATH, location_xpath_template.format(i)).text\n",
    "\n",
    "# #交通 /html/body/div[4]/div[4]/div[4]/dl[1]/dd[1]/p[3]/span\n",
    "\n",
    "# price_xpath_template ='/html/body/div[4]/div[4]/div[4]/dl[{}]/dd[2]/span[1]/b'\n",
    "# #价格 /html/body/div[4]/div[4]/div[4]/dl[1]/dd[2]/span[1]/b    /html/body/div[4]/div[4]/div[4]/dl[2]/dd[2]/span[1]/b\n",
    "# #price = browser.find_element(By.XPATH, price_xpath_template.format(i)).text\n",
    "\n",
    "# #每平方售价 /html/body/div[4]/div[4]/div[4]/dl[1]/dd[2]/span[2]\n",
    "\n",
    "\n",
    "# # 存储数据的列表\n",
    "# data = []\n",
    "\n",
    "# # 爬取页面内的 60个房源信息 \n",
    "# for i in range(1, 61):  \n",
    "#     try:\n",
    "#         # 获取标题\n",
    "#         title = browser.find_element(By.XPATH, title_xpath_template.format(i)).text#.format(i) later\n",
    "\n",
    "#         # 获取面积\n",
    "#         size = browser.find_element(By.XPATH, size_xpath_template.format(i)).text\n",
    "\n",
    "#         # 获取地点\n",
    "#         location = browser.find_element(By.XPATH, location_xpath_template.format(i)).text\n",
    "\n",
    "#         # 获取售价\n",
    "#         price = browser.find_element(By.XPATH, price_xpath_template.format(i)).text     \n",
    "\n",
    "#         # 添加到数据列表\n",
    "#         data.append([title, location, price])\n",
    "\n",
    "#         print(f\"房源 {i}: {title} - {size} - {location} - {price}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"无法获取第 {i} 个房源的信息: {e}\")\n",
    "\n",
    "# # 关闭浏览器\n",
    "# browser.quit()\n",
    "\n",
    "# # 创建 DataFrame\n",
    "# df = pd.DataFrame(data, columns=[\"标题\",\"面积\", \"地点\", \"售价\"])\n",
    "\n",
    "# # 保存到 CSV 文件\n",
    "# df.to_csv(\"房产数据.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# # 保存到 Excel 文件（XLSX 格式）\n",
    "# df.to_excel(\"房产数据.xlsx\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# print(\"数据已保存到 CSV 和 Excel 文件！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# import time\n",
    "# import pandas as pd\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# # 存储数据的列表\n",
    "# data = []\n",
    "\n",
    "# # 定义 XPath 模板\n",
    "# title_xpath_template = '/html/body/div[4]/div[4]/div[4]/dl[{}]/dd[1]/h4/a'\n",
    "# size_xpath_template = '/html/body/div[4]/div[4]/div[4]/dl[{}]/dd[1]/p[1]'  # 获取整个 p 标签\n",
    "# location_xpath_template = '/html/body/div[4]/div[4]/div[4]/dl[{}]/dd[1]/p[2]/span'\n",
    "# price_xpath_template = '/html/body/div[4]/div[4]/div[4]/dl[{}]/dd[2]/span[1]/b'\n",
    "\n",
    "# # 打开一个日志文件，将输出写入文件\n",
    "# with open(\"scraping_log.txt\", \"w\", encoding=\"utf-8\") as log_file:\n",
    "#     # 循环抓取页面内容\n",
    "#     for page_num in range(31, 41):  # 假设你要抓取第 31 到 40 页\n",
    "#         # 每次打开新页面，启动新的 WebDriver 实例\n",
    "#         browser = webdriver.Chrome()\n",
    "#         url = f'https://esf.fang.com/house-a012-b01182/i{page_num}'  # 动态生成 URL\n",
    "#         browser.get(url)\n",
    "        \n",
    "#         # 等待页面加载完成，确保元素可见\n",
    "#         WebDriverWait(browser, 20).until(\n",
    "#             EC.visibility_of_element_located((By.XPATH, '/html/body/div[4]/div[4]/div[4]/dl[1]/dd[1]/h4/a'))\n",
    "#         )\n",
    "#         #/html/body/div[4]/div[4]/div[3]/dl[1]/dd[1]/h4/a\n",
    "#         #/html/body/div[4]/div[4]/div[3]/dl[1]/dd[1]/p[1]\n",
    "        \n",
    "#         for i in range(1, 61):  # 每页有 60 个房源\n",
    "#             try:\n",
    "#                 # 获取标题\n",
    "#                 title = browser.find_element(By.XPATH, title_xpath_template.format(i)).text\n",
    "                \n",
    "#                 # 获取面积\n",
    "#                 p_element = browser.find_element(By.XPATH, size_xpath_template.format(i))\n",
    "#                 p_text = p_element.text\n",
    "                \n",
    "#                 # 使用正则表达式提取第一个 | 和第二个 | 之间的内容\n",
    "#                 size_match = re.search(r'\\|([^|]+)\\|', p_text)\n",
    "#                 if size_match:\n",
    "#                     size = size_match.group(1).strip()  # 去掉两侧的空格\n",
    "#                 else:\n",
    "#                     size = \"NULL\"\n",
    "                \n",
    "#                 # 获取地点\n",
    "#                 location = browser.find_element(By.XPATH, location_xpath_template.format(i)).text\n",
    "                \n",
    "#                 # 获取售价\n",
    "#                 price = browser.find_element(By.XPATH, price_xpath_template.format(i)).text\n",
    "                \n",
    "#                 # 将数据添加到列表\n",
    "#                 data.append([title, size, location, price])\n",
    "                \n",
    "#                 # 将每条房源信息写入日志文件\n",
    "#                 log_file.write(f\"房源 {i} (第{page_num}页): {title} - {size} - {location} - {price}\\n\")\n",
    "\n",
    "#             except Exception as e:\n",
    "#                 log_file.write(f\"无法获取第 {i} 个房源的信息: {e}\\n\")\n",
    "\n",
    "#         # 爬取完一个页面后关闭浏览器\n",
    "#         browser.quit()\n",
    "\n",
    "# # 创建 DataFrame\n",
    "# df = pd.DataFrame(data, columns=[\"标题\", \"面积\", \"地点\", \"售价\"])\n",
    "\n",
    "# # 保存到 CSV 文件\n",
    "# df.to_csv(\"房产数据.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# # 保存到 Excel 文件（XLSX 格式）\n",
    "# df.to_excel(\"房产数据.xlsx\", index=False)  # 不需要 encoding 参数\n",
    "\n",
    "# print(\"数据已保存到 CSV 和 Excel 文件！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
     ]
    }
   ],
   "source": [
    "! pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# 获取面积\u001b[39;00m\n\u001b[32m     59\u001b[39m p_element = browser.find_element(By.XPATH, size_xpath_template.format(i))\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m p_text = \u001b[43mp_element\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# 使用正则表达式提取第一个 | 和第二个 | 之间的内容\u001b[39;00m\n\u001b[32m     63\u001b[39m size_match = re.search(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m|([^|]+)\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m|\u001b[39m\u001b[33m'\u001b[39m, p_text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gav1n\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:109\u001b[39m, in \u001b[36mWebElement.text\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtext\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m     98\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"The text of the element.\u001b[39;00m\n\u001b[32m     99\u001b[39m \n\u001b[32m    100\u001b[39m \u001b[33;03m    Returns:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    107\u001b[39m \u001b[33;03m    >>> print(element.text)\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[43m.\u001b[49m\u001b[43mGET_ELEMENT_TEXT\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gav1n\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:572\u001b[39m, in \u001b[36mWebElement._execute\u001b[39m\u001b[34m(self, command, params)\u001b[39m\n\u001b[32m    570\u001b[39m     params = {}\n\u001b[32m    571\u001b[39m params[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m._id\n\u001b[32m--> \u001b[39m\u001b[32m572\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gav1n\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:427\u001b[39m, in \u001b[36mWebDriver.execute\u001b[39m\u001b[34m(self, driver_command, params)\u001b[39m\n\u001b[32m    424\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33msessionId\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[32m    425\u001b[39m         params[\u001b[33m\"\u001b[39m\u001b[33msessionId\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.session_id\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcommand_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[32m    429\u001b[39m     \u001b[38;5;28mself\u001b[39m.error_handler.check_response(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gav1n\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:404\u001b[39m, in \u001b[36mRemoteConnection.execute\u001b[39m\u001b[34m(self, command, params)\u001b[39m\n\u001b[32m    402\u001b[39m trimmed = \u001b[38;5;28mself\u001b[39m._trim_large_entries(params)\n\u001b[32m    403\u001b[39m LOGGER.debug(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, command_info[\u001b[32m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gav1n\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:428\u001b[39m, in \u001b[36mRemoteConnection._request\u001b[39m\u001b[34m(self, method, url, body)\u001b[39m\n\u001b[32m    425\u001b[39m     body = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    427\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client_config.keep_alive:\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    429\u001b[39m     statuscode = response.status\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gav1n\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\_request_methods.py:135\u001b[39m, in \u001b[36mRequestMethods.request\u001b[39m\u001b[34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[39m\n\u001b[32m    132\u001b[39m     urlopen_kw[\u001b[33m\"\u001b[39m\u001b[33mbody\u001b[39m\u001b[33m\"\u001b[39m] = body\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._encode_url_methods:\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest_encode_url\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43murlopen_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request_encode_body(\n\u001b[32m    144\u001b[39m         method, url, fields=fields, headers=headers, **urlopen_kw\n\u001b[32m    145\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gav1n\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\_request_methods.py:182\u001b[39m, in \u001b[36mRequestMethods.request_encode_url\u001b[39m\u001b[34m(self, method, url, fields, headers, **urlopen_kw)\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fields:\n\u001b[32m    180\u001b[39m     url += \u001b[33m\"\u001b[39m\u001b[33m?\u001b[39m\u001b[33m\"\u001b[39m + urlencode(fields)\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gav1n\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\poolmanager.py:443\u001b[39m, in \u001b[36mPoolManager.urlopen\u001b[39m\u001b[34m(self, method, url, redirect, **kw)\u001b[39m\n\u001b[32m    441\u001b[39m     response = conn.urlopen(method, url, **kw)\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    445\u001b[39m redirect_location = redirect \u001b[38;5;129;01mand\u001b[39;00m response.get_redirect_location()\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gav1n\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gav1n\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gav1n\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    513\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    519\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gav1n\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1428\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1432\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gav1n\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gav1n\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gav1n\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# import re\n",
    "# import pandas as pd\n",
    "# import logging\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# import datetime\n",
    "\n",
    "# # 获取当前日期和时间\n",
    "# current_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# # 动态生成文件名\n",
    "# csv_filename = f\"房产数据_{current_time}.csv\"\n",
    "# xlsx_filename = f\"房产数据_{current_time}.xlsx\"\n",
    "# log_filename = f\"scraping_log_{current_time}.txt\"\n",
    "# # 设置日志配置，确保使用 utf-8 编码\n",
    "# logging.basicConfig(\n",
    "#     filename=log_filename,  # 日志文件改为 .txt 文件\n",
    "#     level=logging.INFO,  # 设置日志级别为 INFO\n",
    "#     format='%(asctime)s - %(levelname)s - %(message)s',  # 日志输出格式\n",
    "#     encoding='utf-8'  # 设置日志文件的编码为 utf-8\n",
    "# )\n",
    "\n",
    "# # 存储数据的列表\n",
    "# data = []\n",
    "\n",
    "# # 初始化 WebDriver\n",
    "# browser = webdriver.Chrome()\n",
    "\n",
    "# # 循环抓取页面内容\n",
    "# for page_num in range(31, 41):  # 假设你要抓取第 31 到 40 页\n",
    "#     url = f'https://esf.fang.com/house-a012-b01182/i{page_num}'  # 动态生成 URL\n",
    "#     browser.get(url)\n",
    "    \n",
    "#     # 根据页面的不同动态选择 XPath\n",
    "#     if page_num == 31 or page_num == 40:  # 第1页和40页使用 div[4]\n",
    "#         div_xpath_prefix = '/html/body/div[4]/div[4]/div[4]'\n",
    "#     else:  # 后续使用 div[3]\n",
    "#         div_xpath_prefix = '/html/body/div[4]/div[4]/div[3]'\n",
    "    \n",
    "#     # 修改 XPath 模板\n",
    "#     title_xpath_template = f'{div_xpath_prefix}/dl[{{}}]/dd[1]/h4/a'\n",
    "#     size_xpath_template = f'{div_xpath_prefix}/dl[{{}}]/dd[1]/p[1]'  # 获取整个 p 标签\n",
    "#     location_xpath_template = f'{div_xpath_prefix}/dl[{{}}]/dd[1]/p[2]/span'\n",
    "#     price_xpath_template = f'{div_xpath_prefix}/dl[{{}}]/dd[2]/span[1]/b'\n",
    "    \n",
    "#     # 等待页面加载完成，确保元素可见\n",
    "#     WebDriverWait(browser, 20).until(\n",
    "#         EC.visibility_of_element_located((By.XPATH, title_xpath_template.format(1)))\n",
    "#     )\n",
    "\n",
    "#     for i in range(1, 61):  # 每页有 60 个房源\n",
    "#         try:\n",
    "#             # 获取标题\n",
    "#             title = browser.find_element(By.XPATH, title_xpath_template.format(i)).text\n",
    "            \n",
    "#             # 获取面积\n",
    "#             p_element = browser.find_element(By.XPATH, size_xpath_template.format(i))\n",
    "#             p_text = p_element.text\n",
    "            \n",
    "#             # 使用正则表达式提取第一个 | 和第二个 | 之间的内容\n",
    "#             size_match = re.search(r'\\|([^|]+)\\|', p_text)\n",
    "#             if size_match:\n",
    "#                 size = size_match.group(1).strip()  # 去掉两侧的空格\n",
    "#             else:\n",
    "#                 size = \"NULL\"\n",
    "            \n",
    "#             # 获取地点\n",
    "#             location = browser.find_element(By.XPATH, location_xpath_template.format(i)).text\n",
    "            \n",
    "#             # 获取售价\n",
    "#             price = browser.find_element(By.XPATH, price_xpath_template.format(i)).text\n",
    "            \n",
    "#             # 将数据添加到列表\n",
    "#             data.append([title, size, location, price])\n",
    "            \n",
    "#             # 打印每个房源的信息到日志文件\n",
    "#             logging.info(f\"房源 {i} (第{page_num}页): {title} - {size} - {location} - {price}\")\n",
    "        \n",
    "#         except Exception as e:\n",
    "#             logging.error(f\"无法获取第 {i} 个房源的信息: {e}\")\n",
    "\n",
    "# # 关闭浏览器\n",
    "# browser.quit()\n",
    "\n",
    "# # 创建 DataFrame\n",
    "# df = pd.DataFrame(data, columns=[\"标题\", \"面积\", \"地点\", \"售价\"])\n",
    "\n",
    "# # 保存到 CSV 文件\n",
    "# df.to_csv(csv_filename, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# # 保存到 Excel 文件（XLSX 格式）\n",
    "# df.to_excel(xlsx_filename, index=False)  # 不需要 encoding 参数\n",
    "\n",
    "# # 输出日志信息，表示程序执行完毕\n",
    "# logging.info(\"数据已保存到 CSV 和 Excel 文件！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# import pandas as pd\n",
    "# import datetime\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# # 获取当前日期和时间\n",
    "# current_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# # 动态生成文件名\n",
    "# csv_filename = f\"房产数据_{current_time}.csv\"\n",
    "# xlsx_filename = f\"房产数据_{current_time}.xlsx\"\n",
    "# log_filename = f\"scraping_log_{current_time}.txt\"\n",
    "\n",
    "# # 打开日志文件进行写入\n",
    "# log_file = open(log_filename, \"w\", encoding=\"utf-8\")\n",
    "\n",
    "# # 存储数据的列表\n",
    "# data = []\n",
    "\n",
    "# # 初始化 WebDriver\n",
    "# browser = webdriver.Chrome()\n",
    "\n",
    "# # 写入日志开始信息\n",
    "# log_file.write(f\"{current_time} - 数据抓取开始\\n\")\n",
    "\n",
    "# # 循环抓取页面内容\n",
    "# for page_num in range(31, 41):  # 假设你要抓取第 31 到 40 页\n",
    "#     url = f'https://esf.fang.com/house-a012-b01182/i{page_num}'  # 动态生成 URL\n",
    "#     browser.get(url)\n",
    "    \n",
    "#     # 根据页面的不同动态选择 XPath\n",
    "#     if page_num == 31 or page_num == 40:  # 第1页和40页使用 div[4]\n",
    "#         div_xpath_prefix = '/html/body/div[4]/div[4]/div[4]'\n",
    "#     else:  # 后续使用 div[3]\n",
    "#         div_xpath_prefix = '/html/body/div[4]/div[4]/div[3]'\n",
    "    \n",
    "#     # 修改 XPath 模板\n",
    "#     title_xpath_template = f'{div_xpath_prefix}/dl[{{}}]/dd[1]/h4/a'\n",
    "#     size_xpath_template = f'{div_xpath_prefix}/dl[{{}}]/dd[1]/p[1]'  # 获取整个 p 标签\n",
    "#     location_xpath_template = f'{div_xpath_prefix}/dl[{{}}]/dd[1]/p[2]/span'\n",
    "#     price_xpath_template = f'{div_xpath_prefix}/dl[{{}}]/dd[2]/span[1]/b'\n",
    "    \n",
    "#     # 等待页面加载完成，确保元素可见\n",
    "#     WebDriverWait(browser, 20).until(\n",
    "#         EC.visibility_of_element_located((By.XPATH, title_xpath_template.format(1)))\n",
    "#     )\n",
    "\n",
    "#     for i in range(1, 61):  # 每页有 60 个房源\n",
    "#         try:\n",
    "#             # 获取标题\n",
    "#             title = browser.find_element(By.XPATH, title_xpath_template.format(i)).text\n",
    "            \n",
    "#             # 获取面积\n",
    "#             p_element = browser.find_element(By.XPATH, size_xpath_template.format(i))\n",
    "#             p_text = p_element.text\n",
    "            \n",
    "#             # 使用正则表达式提取第一个 | 和第二个 | 之间的内容\n",
    "#             size_match = re.search(r'\\|([^|]+)\\|', p_text)\n",
    "#             if size_match:\n",
    "#                 size = size_match.group(1).strip()  # 去掉两侧的空格\n",
    "#             else:\n",
    "#                 size = \"NULL\"\n",
    "            \n",
    "#             # 获取地点\n",
    "#             location = browser.find_element(By.XPATH, location_xpath_template.format(i)).text\n",
    "            \n",
    "#             # 获取售价\n",
    "#             price = browser.find_element(By.XPATH, price_xpath_template.format(i)).text\n",
    "            \n",
    "#             # 将数据添加到列表\n",
    "#             data.append([title, size, location, price])\n",
    "            \n",
    "#             # 写入日志文件，记录每个房源的信息\n",
    "#             log_file.write(f\"房源 {i} (第{page_num}页): {title} - {size} - {location} - {price}\\n\")\n",
    "        \n",
    "#         except Exception as e:\n",
    "#             log_file.write(f\"无法获取第 {i} 个房源的信息: {e}\\n\")\n",
    "\n",
    "# # 关闭浏览器\n",
    "# browser.quit()\n",
    "\n",
    "# # 创建 DataFrame\n",
    "# df = pd.DataFrame(data, columns=[\"标题\", \"面积\", \"地点\", \"售价\"])\n",
    "\n",
    "# # 保存到 CSV 文件\n",
    "# df.to_csv(csv_filename, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# # 保存到 Excel 文件（XLSX 格式）\n",
    "# df.to_excel(xlsx_filename, index=False)  # 不需要 encoding 参数\n",
    "\n",
    "# # 写入日志信息，表示程序执行完毕\n",
    "# log_file.write(\"数据已保存到 CSV 和 Excel 文件！\\n\")\n",
    "\n",
    "# # 关闭日志文件\n",
    "# log_file.close()\n",
    "\n",
    "# print(\"数据已保存到 CSV 和 Excel 文件，日志文件已保存！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已保存到 2025-03-20_18-05-27 文件夹中的 CSV 和 Excel 文件，日志文件已保存！\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# 获取当前日期和时间\n",
    "current_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# 创建当前时间的文件夹\n",
    "output_dir = current_time\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 动态生成文件名\n",
    "csv_filename = os.path.join(output_dir, \"房产数据.csv\")\n",
    "xlsx_filename = os.path.join(output_dir, \"房产数据.xlsx\")\n",
    "log_filename = os.path.join(output_dir, \"scraping_log.txt\")\n",
    "\n",
    "# 打开日志文件进行写入\n",
    "log_file = open(log_filename, \"w\", encoding=\"utf-8\")\n",
    "\n",
    "# 存储数据的列表\n",
    "data = []\n",
    "\n",
    "# 初始化 WebDriver\n",
    "browser = webdriver.Chrome()\n",
    "\n",
    "# 写入日志开始信息\n",
    "log_file.write(f\"{current_time} - 数据抓取开始\\n\")\n",
    "\n",
    "# 循环抓取页面内容\n",
    "for page_num in range(1, 21):  \n",
    "    # 根据页面编号动态生成 URL\n",
    "    if page_num == 1:\n",
    "        url = f'https://esf.fang.com/house-a012-b01182/'  # 初始页面使用 b01182/\n",
    "    else:\n",
    "        url = f'https://esf.fang.com/house-a012-b01182/i3{page_num}'  # 后续页面使用 /i32 到 /i320\n",
    "    \n",
    "    # 打开页面\n",
    "    browser.get(url)\n",
    "    \n",
    "    # 根据页面的不同动态选择 XPath\n",
    "    #/html/body/div[4]/div[4]/div[4]\n",
    "    if page_num == 1:  # 第 1 页使用 div[4]\n",
    "        div_xpath_prefix = '/html/body/div[4]/div[4]/div[4]'\n",
    "    else:  # 后续页面使用 div[3]\n",
    "        div_xpath_prefix = '/html/body/div[4]/div[4]/div[3]'\n",
    "    \n",
    "    # 修改 XPath 模板并寻找规律    \n",
    "    #单价\n",
    "    #/html/body/div[4]/div[4]/div[4]/dl[1]/dd[2]/span[2]\n",
    "    #/html/body/div[4]/div[4]/div[4]/dl[2]/dd[2]/span[2]\n",
    "    unitprice_xpath_template = f'{div_xpath_prefix}/dl[{{}}]/dd[2]/span[2]'\n",
    "\n",
    "    #面积\n",
    "    #/html/body/div[4]/div[4]/div[4]/dl[1]/dd[1]/p[1]/text()[2]\n",
    "    #/html/body/div[4]/div[4]/div[4]/dl[2]/dd[1]/p[1]/text()[2]\n",
    "    size_xpath_template = f'{div_xpath_prefix}/dl[{{}}]/dd[1]/p[1]'  \n",
    "  \n",
    "    #价格\n",
    "    #/html/body/div[4]/div[4]/div[4]/dl[1]/dd[2]/span[1]\n",
    "    #/html/body/div[4]/div[4]/div[4]/dl[2]/dd[2]/span[1]\n",
    "    price_xpath_template = f'{div_xpath_prefix}/dl[{{}}]/dd[2]/span[1]/b'\n",
    "    \n",
    "    # 等待页面加载完成，确保元素可见\n",
    "    WebDriverWait(browser, 10).until(\n",
    "        EC.visibility_of_element_located((By.XPATH, size_xpath_template.format(1)))\n",
    "    )\n",
    "\n",
    "    for i in range(1, 61):  # 每页有 60 个房源\n",
    "        try:\n",
    "            \n",
    "            # 获取面积\n",
    "            p_element = browser.find_element(By.XPATH, size_xpath_template.format(i))\n",
    "            p_text = p_element.text\n",
    "            \n",
    "            # 使用正则表达式提取第一个 | 和第二个 | 之间的内容 获取面积\n",
    "            size_match = re.search(r'\\|([^|]+)\\|', p_text)\n",
    "            if size_match:\n",
    "                size = size_match.group(1).strip()  # 去掉两侧的空格\n",
    "            else:\n",
    "                size = \"NULL\"\n",
    "            \n",
    "            # 获取售价\n",
    "            price = browser.find_element(By.XPATH, price_xpath_template.format(i)).text\n",
    "            \n",
    "            # 获取单价\n",
    "            unitprice = browser.find_element(By.XPATH, unitprice_xpath_template.format(i)).text\n",
    "            \n",
    "            # 将数据添加到列表\n",
    "            data.append([size, unitprice, price])\n",
    "            \n",
    "            # 写入日志文件，记录每个房源的信息\n",
    "            log_file.write(f\"房源 {i} (第{page_num}页): {size} - {unitprice} - {price}\\n\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            log_file.write(f\"无法获取第 {i} 个房源的信息: {e}\\n\")\n",
    "\n",
    "# 关闭浏览器\n",
    "browser.quit()\n",
    "\n",
    "# 创建 DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"面积\", \"单价\", \"售价\"])\n",
    "\n",
    "# 保存到 CSV 文件\n",
    "df.to_csv(csv_filename, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# 保存到 Excel 文件（XLSX 格式）\n",
    "df.to_excel(xlsx_filename, index=False)  # 不需要 encoding 参数\n",
    "\n",
    "# 写入日志信息，表示程序执行完毕\n",
    "log_file.write(\"数据已保存到 CSV 和 Excel 文件！\\n\")\n",
    "\n",
    "# 关闭日志文件\n",
    "log_file.close()\n",
    "\n",
    "print(f\"数据已保存到 {output_dir} 文件夹中的 CSV 和 Excel 文件，日志文件已保存！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已保存到 2025-03-20_23-02-30 文件夹中的 CSV 和 Excel 文件，日志文件已保存！\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# 获取当前日期和时间\n",
    "current_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# 创建当前时间的文件夹\n",
    "output_dir = current_time\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 动态生成文件名\n",
    "csv_filename = os.path.join(output_dir, \"房产租用数据.csv\")\n",
    "xlsx_filename = os.path.join(output_dir, \"房产租用数据.xlsx\")\n",
    "log_filename = os.path.join(output_dir, \"scraping_log.txt\")\n",
    "\n",
    "# 打开日志文件进行写入\n",
    "log_file = open(log_filename, \"w\", encoding=\"utf-8\")\n",
    "\n",
    "# 存储数据的列表\n",
    "data = []\n",
    "\n",
    "# 初始化 WebDriver\n",
    "browser = webdriver.Chrome()\n",
    "\n",
    "# 写入日志开始信息\n",
    "log_file.write(f\"{current_time} - 数据抓取开始\\n\")\n",
    "\n",
    "# 循环抓取页面内容\n",
    "for page_num in range(1, 15):  \n",
    "    # 根据页面编号动态生成 URL\n",
    "    #https://zu.fang.com/house-a012-b01182/\n",
    "    #https://zu.fang.com/house-a012-b01182/i32/\n",
    "    if page_num == 1:\n",
    "        url = f'https://zu.fang.com/house-a012-b01182/'  # 初始页面使用 b01182/\n",
    "    else:\n",
    "        url = f'https://zu.fang.com/house-a012-b01182/i3{page_num}'  # 后续页面使用 /i32 到 /i320\n",
    "    \n",
    "    # 打开页面\n",
    "    browser.get(url)\n",
    "    \n",
    "    # 根据页面的不同动态选择 XPath\n",
    "    #/html/body/div[4]/div[4]/div[1]/div[4]\n",
    "    #/html/body/div[4]/div[4]/div[1]/div[4]\n",
    "    #/html/body/div[4]/div[4]/div[1]/div[4]\n",
    "    div_xpath_prefix = '/html/body/div[4]/div[4]/div[1]/div[4]'\n",
    " \n",
    "    # 修改 XPath 模板并寻找规律    \n",
    "    #单价\n",
    "    #/html/body/div[4]/div[4]/div[1]/div[4]/dl[1]/dd/div[2]/p/span\n",
    "    #/html/body/div[4]/div[4]/div[1]/div[4]/dl[2]/dd/div[2]/p/span\n",
    "    unitprice_xpath_template = f'{div_xpath_prefix}/dl[{{}}]/dd/div[2]/p/span'\n",
    "\n",
    "    #面积\n",
    "    #/html/body/div[4]/div[4]/div[1]/div[4]/dl[1]/dd/p[2]/text()[3]\n",
    "    #/html/body/div[4]/div[4]/div[1]/div[4]/dl[2]/dd/p[2]/text()[3]\n",
    "    size_xpath_template = f'{div_xpath_prefix}/dl[{{}}]/dd/p[2]'  \n",
    "    \n",
    "    \n",
    "    # 等待页面加载完成，确保元素可见\n",
    "    WebDriverWait(browser, 10).until(\n",
    "        EC.visibility_of_element_located((By.XPATH, unitprice_xpath_template.format(1)))\n",
    "    )\n",
    "\n",
    "    for i in range(1, 61):  # 每页有 60 个房源\n",
    "        try:\n",
    "            \n",
    "            # 获取面积\n",
    "            p_element = browser.find_element(By.XPATH, size_xpath_template.format(i))\n",
    "            p_text = p_element.text\n",
    "            \n",
    "            # 使用正则表达式提取第一个 | 和第二个 | 之间的内容 获取面积\n",
    "            size_match = re.search(r'\\|[^|]*\\|([^|]+)\\|', p_text)\n",
    "            if size_match:\n",
    "                size = size_match.group(1).strip()  # 去掉两侧的空格\n",
    "            else:\n",
    "                size = \"NULL\"\n",
    "           \n",
    "            # 获取单价\n",
    "            unitprice = browser.find_element(By.XPATH, unitprice_xpath_template.format(i)).text\n",
    "            \n",
    "            # 将数据添加到列表\n",
    "            data.append([size, unitprice])\n",
    "            \n",
    "            # 写入日志文件，记录每个房源的信息\n",
    "            log_file.write(f\"房源 {i} (第{page_num}页): {size} - {unitprice} \\n\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            break\n",
    "\n",
    "# 关闭浏览器\n",
    "browser.quit()\n",
    "\n",
    "# 创建 DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"面积\", \"单价\"])\n",
    "\n",
    "# 保存到 CSV 文件\n",
    "df.to_csv(csv_filename, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# 保存到 Excel 文件（XLSX 格式）\n",
    "df.to_excel(xlsx_filename, index=False)  # 不需要 encoding 参数\n",
    "\n",
    "# 写入日志信息，表示程序执行完毕\n",
    "log_file.write(\"数据已保存到 CSV 和 Excel 文件！\\n\")\n",
    "\n",
    "# 关闭日志文件\n",
    "log_file.close()\n",
    "\n",
    "print(f\"数据已保存到 {output_dir} 文件夹中的 CSV 和 Excel 文件，日志文件已保存！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
