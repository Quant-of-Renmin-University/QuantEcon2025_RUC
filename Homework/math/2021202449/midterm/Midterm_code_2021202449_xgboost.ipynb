{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "91c7f332-e396-4495-a027-2f4bcbeb20a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa85187e-12b6-4304-bd37-b5326bebe120",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_excel(\"Data/ruc_Class25Q1_train.xlsx\")\n",
    "test_df = pd.read_excel(\"Data/ruc_Class25Q1_test.xlsx\")\n",
    "details_df = pd.read_excel(\"Data/ruc_Class25Q1_details.xlsx\")\n",
    "rent_df = pd.read_excel(\"Data/ruc_Class25Q1_rent.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca41a25-c8ee-4971-96ab-40b0351964f5",
   "metadata": {},
   "source": [
    "## 1. 数据预处理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5475a772-00fa-41f9-a2e3-34124a13d743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 全局变量，用于在训练和测试之间共享\n",
    "imputers = {}\n",
    "freq_map_for_test = {}\n",
    "encoded_columns = None\n",
    "feature_list = None\n",
    "scaler = None\n",
    "pca = None\n",
    "\n",
    "def process_data(train_df, test_df, details_df, rent_df, is_training=True):\n",
    "    \"\"\"\n",
    "    处理房价预测数据集，执行特征工程和数据预处理\n",
    "    \n",
    "    参数:\n",
    "    train_df: 训练数据集\n",
    "    test_df: 测试数据集\n",
    "    details_df: 小区详细信息数据集\n",
    "    rent_df: 租赁数据集\n",
    "    is_training: 是否为训练模式(True)或预测模式(False)\n",
    "    \n",
    "    返回:\n",
    "    X: 处理后的特征数据\n",
    "    y: 目标变量(仅在训练模式下)\n",
    "    scaler: 标准化对象(仅在训练模式下)\n",
    "    pca: PCA对象(仅在训练模式下)\n",
    "    \"\"\"\n",
    "    global imputers, freq_map_for_test, encoded_columns, feature_list, scaler, pca\n",
    "    \n",
    "    # 确定当前处理的数据集\n",
    "    if is_training:\n",
    "        df = train_df.copy()\n",
    "    else:\n",
    "        df = test_df.copy()\n",
    "        \n",
    "    # 1. 定义辅助函数\n",
    "    def extract_area(area_str):\n",
    "        if pd.isna(area_str):\n",
    "            return np.nan\n",
    "        # 移除所有非数字和小数点的字符\n",
    "        cleaned_str = re.sub(r'[^\\d.]', '', str(area_str))\n",
    "        try:\n",
    "            return float(cleaned_str) if cleaned_str else np.nan\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "    \n",
    "    def extract_floor_info(floor_str):\n",
    "        if pd.isna(floor_str):\n",
    "            return np.nan, np.nan\n",
    "        \n",
    "        # 提取当前楼层\n",
    "        current_match = re.search(r'(底层|低楼层|中楼层|高楼层|顶层)', str(floor_str))\n",
    "        current_floor = current_match.group(1) if current_match else np.nan\n",
    "        \n",
    "        # 提取总楼层\n",
    "        total_match = re.search(r'共(\\d+)层', str(floor_str))\n",
    "        total_floor = int(total_match.group(1)) if total_match else np.nan\n",
    "        \n",
    "        return current_floor, total_floor\n",
    "    \n",
    "    def extract_house_type(type_str):\n",
    "        if pd.isna(type_str):\n",
    "            return np.nan, np.nan, np.nan, np.nan\n",
    "        \n",
    "        rooms = re.search(r'(\\d+)室', str(type_str))\n",
    "        rooms = int(rooms.group(1)) if rooms else 0\n",
    "        \n",
    "        living_rooms = re.search(r'(\\d+)厅', str(type_str))\n",
    "        living_rooms = int(living_rooms.group(1)) if living_rooms else 0\n",
    "        \n",
    "        kitchens = re.search(r'(\\d+)厨', str(type_str))\n",
    "        kitchens = int(kitchens.group(1)) if kitchens else 0\n",
    "        \n",
    "        bathrooms = re.search(r'(\\d+)卫', str(type_str))\n",
    "        bathrooms = int(bathrooms.group(1)) if bathrooms else 0\n",
    "        \n",
    "        return rooms, living_rooms, kitchens, bathrooms\n",
    "    \n",
    "    def extract_number(x):\n",
    "        if pd.isna(x) or not isinstance(x, str):\n",
    "            return np.nan\n",
    "        match = re.search(r'(\\d+\\.?\\d*)', x)\n",
    "        if match:\n",
    "            return float(match.group(1))\n",
    "        return np.nan\n",
    "    \n",
    "    # 2. 处理面积数据\n",
    "    df['建筑面积_数值'] = df['建筑面积'].apply(extract_area)\n",
    "    df['套内面积_数值'] = df['套内面积'].apply(extract_area)\n",
    "    \n",
    "    # 3. 处理楼层信息\n",
    "    floor_info = df['所在楼层'].apply(extract_floor_info)\n",
    "    df['当前楼层'] = [x[0] for x in floor_info]\n",
    "    df['总楼层'] = [x[1] for x in floor_info]\n",
    "    \n",
    "    # 4. 处理户型信息\n",
    "    house_type_info = df['房屋户型'].apply(extract_house_type)\n",
    "    df['房间数'] = [x[0] for x in house_type_info]\n",
    "    df['客厅数'] = [x[1] for x in house_type_info]\n",
    "    df['厨房数'] = [x[2] for x in house_type_info]\n",
    "    df['卫生间数'] = [x[3] for x in house_type_info]\n",
    "    \n",
    "    # 5. 创建楼层比例特征\n",
    "    floor_map = {'底层': 0, '低楼层': 0.25, '中楼层': 0.5, '高楼层': 0.75, '顶层': 1}\n",
    "    df['楼层比例'] = df['当前楼层'].map(floor_map)\n",
    "    \n",
    "    # 6. 处理电梯\n",
    "    df['有电梯'] = df['配备电梯'].map({'有': 1, '无': 0})\n",
    "    \n",
    "    # 7. 与小区详情合并\n",
    "    merged_df = pd.merge(df, details_df, left_on=['小区名称', '城市'], right_on=['名称', '城市'], how='left')\n",
    "    \n",
    "    # 8. 提取小区建筑年代\n",
    "    merged_df['建筑年代_数值'] = merged_df['建筑年代'].str.extract(r'(\\d+)').astype(float)\n",
    "    \n",
    "    # 9. 提取容积率和绿化率\n",
    "    merged_df['容积率_数值'] = merged_df['容 积 率'].apply(extract_number)\n",
    "    merged_df['绿化率_数值'] = merged_df['绿 化 率'].apply(lambda x: extract_number(x)/100 if pd.notna(x) and isinstance(x, str) and '%' in x else extract_number(x))\n",
    "    \n",
    "    # 10. 计算房龄\n",
    "    current_year = 2025  # 假设当前年份为2024年\n",
    "    merged_df['房龄'] = current_year - merged_df['建筑年代_数值']\n",
    "    \n",
    "    # 11. 与租赁数据合并\n",
    "    rent_avg = rent_df.groupby('小区名称')['价格'].mean().reset_index()\n",
    "    rent_avg.rename(columns={'价格': '平均租金'}, inplace=True)\n",
    "    merged_df = pd.merge(merged_df, rent_avg, on='小区名称', how='left')\n",
    "    \n",
    "    # 12. 计算租售比 (只在训练集或包含价格信息时计算)\n",
    "    if is_training or '价格' in merged_df.columns:\n",
    "        merged_df['租售比'] = merged_df['平均租金'] / merged_df['价格']\n",
    "    \n",
    "    # 13. 频率编码\n",
    "    if is_training:\n",
    "        # 在训练集上计算频率\n",
    "        freq_map = merged_df['板块_x'].value_counts(normalize=True).to_dict()\n",
    "        # 保存频率映射，以便应用到测试集\n",
    "        freq_map_for_test = freq_map\n",
    "    else:\n",
    "        # 使用训练集上计算的频率映射\n",
    "        freq_map = freq_map_for_test\n",
    "    \n",
    "    merged_df['板块_x_freq'] = merged_df['板块_x'].map(freq_map)\n",
    "    \n",
    "    # 14. 删除不需要的列和有数据泄露的列\n",
    "    cols_to_drop = ['套内面积', '所在楼层', '房屋户型', '配备电梯', '名称', '建筑年代', \n",
    "                   '容 积 率', '绿 化 率', '物 业 费', '核心卖点', '户型介绍', '周边配套', '交通出行','建筑面积']\n",
    "    processed_df = merged_df.drop(columns=cols_to_drop, errors='ignore')\n",
    "    \n",
    "    # 15. 处理缺失值\n",
    "    # 获取数值型列\n",
    "    numeric_cols = processed_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    if is_training and '价格' in numeric_cols:\n",
    "        numeric_cols.remove('价格')\n",
    "    \n",
    "    # 重要修改：先创建所有列的imputer，然后再应用\n",
    "    if is_training:\n",
    "        # 初始化存储所有列的imputer\n",
    "        imputers = {}\n",
    "        for col in numeric_cols:\n",
    "            if processed_df[col].isnull().any():\n",
    "                imputer = SimpleImputer(strategy='median')\n",
    "                imputer.fit(processed_df[col].values.reshape(-1, 1))\n",
    "                imputers[col] = imputer\n",
    "    \n",
    "    # 应用imputer进行缺失值填充\n",
    "    for col in numeric_cols:\n",
    "        if processed_df[col].isnull().any():\n",
    "            if col in imputers:\n",
    "                # 使用已有的imputer填充\n",
    "                processed_df[col] = imputers[col].transform(processed_df[col].values.reshape(-1, 1))\n",
    "            else:\n",
    "                # 如果没有这个列的imputer(新列或测试集特有的列)，使用当前数据的中位数填充\n",
    "                median_val = processed_df[col].median()\n",
    "                processed_df[col].fillna(median_val, inplace=True)\n",
    "    \n",
    "    # 16. 处理分类特征\n",
    "    categorical_features_to_use = ['城市', '区域', '板块_x_freq', '环线', '装修情况', '当前楼层', '房屋朝向', '建筑结构_x', '别墅类型']\n",
    "    # 过滤存在于数据中的分类特征\n",
    "    categorical_features_to_use = [col for col in categorical_features_to_use if col in processed_df.columns]\n",
    "    \n",
    "    # 使用get_dummies进行One-Hot编码\n",
    "    if is_training:\n",
    "        # 在训练集上进行独热编码\n",
    "        processed_df_encoded = pd.get_dummies(processed_df, columns=categorical_features_to_use, drop_first=True)\n",
    "        # 保存编码的列，以便应用到测试集\n",
    "        encoded_columns = processed_df_encoded.columns\n",
    "    else:\n",
    "        # 在测试集上进行独热编码，确保列与训练集相同\n",
    "        processed_df_encoded = pd.get_dummies(processed_df, columns=categorical_features_to_use, drop_first=True)\n",
    "        \n",
    "        # 确保测试集与训练集具有相同的特征列\n",
    "        for col in encoded_columns:\n",
    "            if col not in processed_df_encoded.columns:\n",
    "                processed_df_encoded[col] = 0\n",
    "        \n",
    "        # 测试集可能有训练集没有的列，需要移除\n",
    "        extra_cols = [col for col in processed_df_encoded.columns if col not in encoded_columns]\n",
    "        if extra_cols:\n",
    "            processed_df_encoded = processed_df_encoded.drop(columns=extra_cols)\n",
    "        \n",
    "        # 确保列的顺序一致\n",
    "        processed_df_encoded = processed_df_encoded[encoded_columns.intersection(processed_df_encoded.columns)]\n",
    "    \n",
    "    # 17. 特征选择 - 选择用于训练的特征\n",
    "    # 移除不用于训练的列和冗余特征\n",
    "    columns_to_exclude = [\n",
    "        # 识别信息\n",
    "        '小区名称', '小区地址', '区县', \n",
    "        \n",
    "        # 冗余或潜在数据泄露特征\n",
    "        '板块_y', '建筑结构_y', '物业办公电话', '产权描述',\n",
    "        '供水', '供暖', '供电', '燃气费', '供热费', '停车位', '停车费用',\n",
    "        \n",
    "        # 已经转换为数值的特征原始列\n",
    "        '梯户比例', '交易时间', '交易权属', '上次交易', '房屋用途', '产权所属', \n",
    "        '抵押信息', '房屋年限', '环线位置',\n",
    "        \n",
    "        # 已有提取特征的原始数据\n",
    "        '开发商', '物业公司', '物业类别', '房屋优势', '房屋总数', '楼栋总数',\n",
    "        \n",
    "        # 可能与其他特征重复的坐标\n",
    "        'coord_x', 'coord_y', '板块_x'\n",
    "    ]\n",
    "    \n",
    "    # 获取特征列表\n",
    "    if is_training:\n",
    "        features = [col for col in processed_df_encoded.columns if col not in columns_to_exclude and col != '价格']\n",
    "        feature_list = features\n",
    "    else:\n",
    "        features = [col for col in feature_list if col in processed_df_encoded.columns]\n",
    "    \n",
    "    # 确保所有特征都存在于处理后的数据中\n",
    "    for col in features:\n",
    "        if col not in processed_df_encoded.columns:\n",
    "            processed_df_encoded[col] = 0  # 如果缺少某列，用0填充\n",
    "    \n",
    "    X = processed_df_encoded[features]\n",
    "    \n",
    "    # 18. 添加非线性特征\n",
    "    # 确保这些基础特征存在\n",
    "    base_features = ['建筑面积_数值', '房间数', '客厅数', '厨房数', '卫生间数', '总楼层', '房龄']\n",
    "    for feat in base_features:\n",
    "        if feat not in X.columns:\n",
    "            X[feat] = 0  # 使用0填充缺失的基础特征\n",
    "    \n",
    "    X['建筑面积_平方'] = X['建筑面积_数值'] ** 2\n",
    "    X['建筑面积_平方根'] = np.sqrt(X['建筑面积_数值'])\n",
    "    \n",
    "    # 特征交互 - 增加错误处理\n",
    "    # 避免除以零\n",
    "    X['房间密度'] = (X['房间数'] + X['客厅数'] + X['厨房数'] + X['卫生间数']) / X['建筑面积_数值'].replace(0, 1)\n",
    "    X['平均每房面积'] = X['建筑面积_数值'] / X['房间数'].replace(0, 1)\n",
    "    X['楼层面积比'] = X['总楼层'] / X['建筑面积_数值'].replace(0, 1)\n",
    "    X['房龄平方'] = X['房龄'] ** 2\n",
    "    \n",
    "    # 19. 标准化特征\n",
    "    if is_training:\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        # 可选: PCA降维\n",
    "        pca = PCA(n_components=0.95)  # 保留95%的方差\n",
    "        X_pca = pca.fit_transform(X_scaled)\n",
    "        \n",
    "        # 获取目标变量\n",
    "        y = processed_df_encoded['价格'] if '价格' in processed_df_encoded.columns else None\n",
    "        \n",
    "        return X, X_scaled, X_pca, y, scaler, pca, feature_list\n",
    "    else:\n",
    "        # 使用训练集的scaler\n",
    "        X_scaled = scaler.transform(X)\n",
    "        \n",
    "        # 使用训练集的PCA\n",
    "        X_pca = pca.transform(X_scaled)\n",
    "        \n",
    "        return X, X_scaled, X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3fee8bd-d57e-4056-9e9b-59993575e0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用示例:\n",
    "# 训练模式:\n",
    "X, X_scaled, X_pca, y, scaler, pca, feature_list = process_data(train_df, test_df, details_df, rent_df, is_training=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20853d50-820b-4cef-94e0-ef22e41a8ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试模式:\n",
    "X_test, X_test_scaled, X_test_pca = process_data(train_df, test_df, details_df, rent_df, is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74b2c384-1614-4bd9-8a97-bdb04dbd6f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集形状: (67683, 562)\n",
      "测试集形状: (16921, 562)\n",
      "PCA特征数量: 440\n"
     ]
    }
   ],
   "source": [
    "# 划分训练集和测试集\n",
    "X_train, X_test, X_train_scaled, X_test_scaled, X_train_pca, X_test_pca, y_train, y_test = train_test_split(\n",
    "    X, X_scaled, X_pca, y, test_size=0.2, random_state=111\n",
    ")\n",
    "\n",
    "print(f\"训练集形状: {X_train.shape}\")\n",
    "print(f\"测试集形状: {X_test.shape}\")\n",
    "print(f\"PCA特征数量: {X_train_pca.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a6b72d-059f-455d-bcc8-5ae45e22fe02",
   "metadata": {},
   "source": [
    "## 2. Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e343e7b3-8886-41b0-baab-d5b0f26b0904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    \"\"\"评估模型性能，包括样本内外性能和交叉验证\"\"\"\n",
    "    start_time = time.time()\n",
    "    print(f\"\\n开始训练 {model_name}...\")\n",
    "    \n",
    "    # 训练模型\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 样本内预测\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    \n",
    "    # 样本外预测\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # 计算MAE\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    \n",
    "    # 计算RMSE\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    \n",
    "    # 计算R2\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # 6折交叉验证\n",
    "    print(f\"执行 {model_name} 的6折交叉验证...\")\n",
    "    cv = KFold(n_splits=6, shuffle=True, random_state=111)\n",
    "    \n",
    "    # 使用手动循环代替cross_val_score以添加进度条\n",
    "    cv_mae_scores = []\n",
    "    cv_rmse_scores = []\n",
    "    cv_r2_scores = []\n",
    "    \n",
    "    for train_idx, val_idx in tqdm(cv.split(X_train), total=6, desc=\"交叉验证进度\"):\n",
    "        X_cv_train, X_cv_val = X_train[train_idx], X_train[val_idx]\n",
    "        y_cv_train, y_cv_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        # 训练模型\n",
    "        model_cv = clone(model)\n",
    "        model_cv.fit(X_cv_train, y_cv_train)\n",
    "        \n",
    "        # 预测\n",
    "        y_cv_pred = model_cv.predict(X_cv_val)\n",
    "        \n",
    "        # 计算指标\n",
    "        cv_mae_scores.append(mean_absolute_error(y_cv_val, y_cv_pred))\n",
    "        cv_rmse_scores.append(np.sqrt(mean_squared_error(y_cv_val, y_cv_pred)))\n",
    "        cv_r2_scores.append(r2_score(y_cv_val, y_cv_pred))\n",
    "    \n",
    "    # 计算平均分数\n",
    "    cv_mae = np.mean(cv_mae_scores)\n",
    "    cv_rmse = np.mean(cv_rmse_scores)\n",
    "    cv_r2 = np.mean(cv_r2_scores)\n",
    "    \n",
    "    # 计算训练时间\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # 输出结果\n",
    "    print(f\"\\n{model_name} 评估结果:\")\n",
    "    print(f\"训练时间: {training_time:.2f}秒\")\n",
    "    print(f\"In-sample MAE: {train_mae:.4f}\")\n",
    "    print(f\"Out-of-sample MAE: {test_mae:.4f}\")\n",
    "    print(f\"CV MAE: {cv_mae:.4f}\")\n",
    "    print(f\"In-sample RMSE: {train_rmse:.4f}\")\n",
    "    print(f\"Out-of-sample RMSE: {test_rmse:.4f}\")\n",
    "    print(f\"CV RMSE: {cv_rmse:.4f}\")\n",
    "    print(f\"In-sample R²: {train_r2:.4f}\")\n",
    "    print(f\"Out-of-sample R²: {test_r2:.4f}\")\n",
    "    print(f\"CV R²: {cv_r2:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'train_mae': train_mae,\n",
    "        'test_mae': test_mae,\n",
    "        'cv_mae': cv_mae,\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'cv_rmse': cv_rmse,\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2,\n",
    "        'cv_r2': cv_r2,\n",
    "        'training_time': training_time,\n",
    "        'model': model\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9481fb0-1562-45b9-8272-7bd9cd2c8860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X_train, X_test, y_train, y_test, use_pca=True):\n",
    "    \"\"\"训练多个模型并返回评估结果\"\"\"\n",
    "    models = []\n",
    "    \n",
    "    # 选择使用原始特征还是PCA特征\n",
    "    X_train_data = X_train_pca if use_pca else X_train_scaled\n",
    "    X_test_data = X_test_pca if use_pca else X_test_scaled\n",
    "    \n",
    "    # 线性回归（OLS）\n",
    "    suffix = \"(PCA)\" if use_pca else \"\"\n",
    "    ols = LinearRegression()\n",
    "    ols_results = evaluate_model(ols, X_train_data, X_test_data, y_train, y_test, f\"OLS {suffix}\")\n",
    "    models.append(ols_results)\n",
    "    \n",
    "    # # Lasso回归（L1正则化） -  # 增大alpha值, 减少最大迭代次数\n",
    "    # lasso = Lasso(alpha=1.0, max_iter=500, tol=0.1, warm_start=True, random_state=111)\n",
    "    # lasso_results = evaluate_model(lasso, X_train_data, X_test_data, y_train, y_test, f\"Lasso {suffix}\")\n",
    "    # models.append(lasso_results)\n",
    "    \n",
    "    # Ridge回归（L2正则化）\n",
    "    ridge = Ridge(alpha=1.0, random_state=111)\n",
    "    ridge_results = evaluate_model(ridge, X_train_data, X_test_data, y_train, y_test, f\"Ridge {suffix}\")\n",
    "    models.append(ridge_results)\n",
    "    \n",
    "    # ElasticNet（结合L1和L2正则化）\n",
    "    elastic = ElasticNet(alpha=0.01, l1_ratio=0.5, max_iter=10000, random_state=111)\n",
    "    elastic_results = evaluate_model(elastic, X_train_data, X_test_data, y_train, y_test, f\"ElasticNet {suffix}\")\n",
    "    models.append(elastic_results)\n",
    "    \n",
    "    # 按测试集MAE排序\n",
    "    sorted_models = sorted(models, key=lambda x: x['test_mae'])\n",
    "    best_model = sorted_models[0]\n",
    "    \n",
    "    print(f\"\\n总体最佳模型: {best_model['model_name']}，测试集MAE: {best_model['test_mae']:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'models': models,\n",
    "        'best_model': best_model,\n",
    "        'ols_results': ols_results,\n",
    "        # 'lasso_results': lasso_results,\n",
    "        'ridge_results': ridge_results,\n",
    "        'elastic_results': elastic_results\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e7833dc-d0fb-4ba1-aa66-7268237db5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "795690e2-bd3c-451c-b381-a4ac7ff0baac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_boosting_models(X_train, X_test, y_train, y_test, fast_mode=True):\n",
    "    \"\"\"\n",
    "    评估梯度提升模型（LightGBM和XGBoost）的性能\n",
    "    \n",
    "    参数:\n",
    "    X_train, X_test: 训练和测试特征\n",
    "    y_train, y_test: 训练和测试标签\n",
    "    fast_mode: 是否使用快速模式(减少迭代次数和交叉验证)\n",
    "    \n",
    "    返回:\n",
    "    models_results: 包含模型评估结果的列表\n",
    "    \"\"\"\n",
    "    # 创建一个模型列表来存储所有评估结果\n",
    "    models_results = []\n",
    "    \n",
    "    # 设置参数 - 快速模式下使用更少的迭代次数\n",
    "    n_estimators = 50 if fast_mode else 100\n",
    "    cv_folds = 3 if fast_mode else 6\n",
    "    \n",
    "    # 定义评估函数\n",
    "    def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "        start_time = time.time()\n",
    "        print(f\"\\n开始训练 {model_name}...\")\n",
    "        \n",
    "        # 训练模型\n",
    "        try:\n",
    "            # 对于LightGBM和XGBoost，使用验证集以便早停\n",
    "            if isinstance(model, lgb.LGBMRegressor) or isinstance(model, xgb.XGBRegressor):\n",
    "                # 从训练集中分离出一部分作为验证集\n",
    "                X_train_part, X_valid, y_train_part, y_valid = train_test_split(\n",
    "                    X_train, y_train, test_size=0.2, random_state=111\n",
    "                )\n",
    "                \n",
    "                if fast_mode:\n",
    "                    # 快速模式下，不使用early_stopping以加快速度\n",
    "                    model.fit(X_train, y_train, verbose=100 if not fast_mode else 0)\n",
    "                else:\n",
    "                    # 完整模式下使用验证集和早停\n",
    "                    model.fit(\n",
    "                        X_train_part, y_train_part,\n",
    "                        eval_set=[(X_valid, y_valid)],\n",
    "                        early_stopping_rounds=10,\n",
    "                        verbose=100\n",
    "                    )\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "        except Exception as e:\n",
    "            print(f\"训练模型时出错: {e}\")\n",
    "            try:\n",
    "                # 尝试使用基本方法拟合\n",
    "                model.fit(X_train, y_train)\n",
    "            except Exception as e2:\n",
    "                print(f\"基本训练方法也失败了: {e2}\")\n",
    "                # 返回空结果\n",
    "                return None\n",
    "        \n",
    "        # 计算训练时间\n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        # 样本内预测\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        \n",
    "        # 样本外预测\n",
    "        try:\n",
    "            y_test_pred = model.predict(X_test)\n",
    "        except Exception as e:\n",
    "            print(f\"预测时出错: {e}\")\n",
    "            return None\n",
    "        \n",
    "        # 计算指标\n",
    "        train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "        test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "        train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "        test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "        train_r2 = r2_score(y_train, y_train_pred)\n",
    "        test_r2 = r2_score(y_test, y_test_pred)\n",
    "        \n",
    "        # 如果在快速模式下，跳过交叉验证或简化它\n",
    "        cv_mae, cv_rmse, cv_r2 = 0, 0, 0\n",
    "        \n",
    "        if not fast_mode:\n",
    "            # 交叉验证\n",
    "            print(f\"执行 {model_name} 的{cv_folds}折交叉验证...\")\n",
    "            cv = KFold(n_splits=cv_folds, shuffle=True, random_state=111)\n",
    "            \n",
    "            cv_mae_scores = []\n",
    "            cv_rmse_scores = []\n",
    "            cv_r2_scores = []\n",
    "            \n",
    "            for train_idx, val_idx in tqdm(cv.split(X_train), total=cv_folds, desc=\"交叉验证进度\"):\n",
    "                # 处理不同类型的输入\n",
    "                if isinstance(X_train, pd.DataFrame):\n",
    "                    X_cv_train, X_cv_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "                else:\n",
    "                    X_cv_train, X_cv_val = X_train[train_idx], X_train[val_idx]\n",
    "                \n",
    "                if isinstance(y_train, pd.Series):\n",
    "                    y_cv_train, y_cv_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "                else:\n",
    "                    y_cv_train, y_cv_val = y_train[train_idx], y_train[val_idx]\n",
    "                \n",
    "                # 创建并训练模型克隆\n",
    "                try:\n",
    "                    model_cv = model.__class__(**model.get_params())\n",
    "                    \n",
    "                    # 提高训练速度，简化参数\n",
    "                    if isinstance(model_cv, lgb.LGBMRegressor) or isinstance(model_cv, xgb.XGBRegressor):\n",
    "                        # 交叉验证中简化参数设置\n",
    "                        model_cv.n_estimators = min(50, model_cv.n_estimators)\n",
    "                        if hasattr(model_cv, 'verbose'):\n",
    "                            model_cv.verbose = 0\n",
    "                        \n",
    "                    model_cv.fit(X_cv_train, y_cv_train)\n",
    "                    y_cv_pred = model_cv.predict(X_cv_val)\n",
    "                    \n",
    "                    # 计算指标\n",
    "                    cv_mae_scores.append(mean_absolute_error(y_cv_val, y_cv_pred))\n",
    "                    cv_rmse_scores.append(np.sqrt(mean_squared_error(y_cv_val, y_cv_pred)))\n",
    "                    cv_r2_scores.append(r2_score(y_cv_val, y_cv_pred))\n",
    "                except Exception as e:\n",
    "                    print(f\"交叉验证中出错: {e}\")\n",
    "                    # 跳过这一折\n",
    "                    continue\n",
    "            \n",
    "            # 只有在有足够折数的情况下计算平均值\n",
    "            if cv_mae_scores:\n",
    "                cv_mae = np.mean(cv_mae_scores)\n",
    "                cv_rmse = np.mean(cv_rmse_scores)\n",
    "                cv_r2 = np.mean(cv_r2_scores)\n",
    "            else:\n",
    "                # 如果交叉验证完全失败，使用测试集结果作为替代\n",
    "                cv_mae = test_mae\n",
    "                cv_rmse = test_rmse\n",
    "                cv_r2 = test_r2\n",
    "        else:\n",
    "            # 快速模式下跳过交叉验证，使用测试集结果\n",
    "            cv_mae = test_mae\n",
    "            cv_rmse = test_rmse\n",
    "            cv_r2 = test_r2\n",
    "            print(\"快速模式: 跳过交叉验证，使用测试集性能作为替代\")\n",
    "        \n",
    "        # 输出结果\n",
    "        print(f\"\\n{model_name} 评估结果:\")\n",
    "        print(f\"训练时间: {training_time:.2f}秒\")\n",
    "        print(f\"In-sample MAE: {train_mae:.4f}\")\n",
    "        print(f\"Out-of-sample MAE: {test_mae:.4f}\")\n",
    "        print(f\"CV MAE: {cv_mae:.4f}\")\n",
    "        print(f\"In-sample RMSE: {train_rmse:.4f}\")\n",
    "        print(f\"Out-of-sample RMSE: {test_rmse:.4f}\")\n",
    "        print(f\"CV RMSE: {cv_rmse:.4f}\")\n",
    "        print(f\"In-sample R²: {train_r2:.4f}\")\n",
    "        print(f\"Out-of-sample R²: {test_r2:.4f}\")\n",
    "        print(f\"CV R²: {cv_r2:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        return {\n",
    "            'model_name': model_name,\n",
    "            'train_mae': train_mae,\n",
    "            'test_mae': test_mae,\n",
    "            'cv_mae': cv_mae,\n",
    "            'train_rmse': train_rmse,\n",
    "            'test_rmse': test_rmse,\n",
    "            'cv_rmse': cv_rmse,\n",
    "            'train_r2': train_r2,\n",
    "            'test_r2': test_r2,\n",
    "            'cv_r2': cv_r2,\n",
    "            'training_time': training_time,\n",
    "            'model': model\n",
    "        }\n",
    "    \n",
    "    # 尝试LightGBM线性模型\n",
    "    try:\n",
    "        print(\"\\n开始评估LightGBM线性模型...\")\n",
    "        # LightGBM - 线性提升器（类似于带正则化的线性模型）\n",
    "        lgb_linear = lgb.LGBMRegressor(\n",
    "            objective='regression',\n",
    "            boosting_type='gblinear',  # 使用线性提升器\n",
    "            lambda_l1=0.1,  # L1正则化，相当于Lasso\n",
    "            lambda_l2=0.1,  # L2正则化，相当于Ridge\n",
    "            learning_rate=0.1,\n",
    "            n_estimators=n_estimators,\n",
    "            random_state=111,\n",
    "            n_jobs=-1  # 使用所有CPU\n",
    "        )\n",
    "        lgb_result = evaluate_model(\n",
    "            lgb_linear, \n",
    "            X_train, X_test, \n",
    "            y_train, y_test, \n",
    "            \"LightGBM (Linear)\"\n",
    "        )\n",
    "        if lgb_result:\n",
    "            models_results.append(lgb_result)\n",
    "    except Exception as e:\n",
    "        print(f\"LightGBM线性模型评估失败: {e}\")\n",
    "    \n",
    "    # 尝试LightGBM树模型\n",
    "    try:\n",
    "        print(\"\\n开始评估LightGBM树模型...\")\n",
    "        # LightGBM - 树模型\n",
    "        lgb_tree = lgb.LGBMRegressor(\n",
    "            objective='regression',\n",
    "            n_estimators=n_estimators,\n",
    "            num_leaves=31,  # 控制树复杂度\n",
    "            learning_rate=0.1,\n",
    "            random_state=111,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        lgb_tree_result = evaluate_model(\n",
    "            lgb_tree, \n",
    "            X_train, X_test, \n",
    "            y_train, y_test, \n",
    "            \"LightGBM (Tree)\"\n",
    "        )\n",
    "        if lgb_tree_result:\n",
    "            models_results.append(lgb_tree_result)\n",
    "    except Exception as e:\n",
    "        print(f\"LightGBM树模型评估失败: {e}\")\n",
    "    \n",
    "    # 尝试XGBoost线性模型\n",
    "    try:\n",
    "        print(\"\\n开始评估XGBoost线性模型...\")\n",
    "        # XGBoost - 线性提升器\n",
    "        xgb_linear = xgb.XGBRegressor(\n",
    "            objective='reg:squarederror',\n",
    "            booster='gblinear',  # 使用线性提升器\n",
    "            alpha=0.1,  # L1正则化\n",
    "            lambda_=0.1,  # L2正则化\n",
    "            learning_rate=0.1,\n",
    "            n_estimators=n_estimators,\n",
    "            random_state=111,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        xgb_result = evaluate_model(\n",
    "            xgb_linear, \n",
    "            X_train, X_test, \n",
    "            y_train, y_test, \n",
    "            \"XGBoost (Linear)\"\n",
    "        )\n",
    "        if xgb_result:\n",
    "            models_results.append(xgb_result)\n",
    "    except Exception as e:\n",
    "        print(f\"XGBoost线性模型评估失败: {e}\")\n",
    "    \n",
    "    # 尝试XGBoost树模型\n",
    "    try:\n",
    "        print(\"\\n开始评估XGBoost树模型...\")\n",
    "        # XGBoost - 树模型\n",
    "        xgb_tree = xgb.XGBRegressor(\n",
    "            objective='reg:squarederror',\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=6,  # 控制树深度\n",
    "            learning_rate=0.1,\n",
    "            random_state=111,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        xgb_tree_result = evaluate_model(\n",
    "            xgb_tree, \n",
    "            X_train, X_test, \n",
    "            y_train, y_test, \n",
    "            \"XGBoost (Tree)\"\n",
    "        )\n",
    "        if xgb_tree_result:\n",
    "            models_results.append(xgb_tree_result)\n",
    "    except Exception as e:\n",
    "        print(f\"XGBoost树模型评估失败: {e}\")\n",
    "    \n",
    "    # 排序并返回模型结果\n",
    "    return sorted(models_results, key=lambda x: x['test_mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cff6aa6-0081-4c1c-b545-46fa03fca5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始评估LightGBM线性模型...\n",
      "\n",
      "开始训练 LightGBM (Linear)...\n",
      "训练模型时出错: LGBMRegressor.fit() got an unexpected keyword argument 'verbose'\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "基本训练方法也失败了: Unknown boosting type gblinear\n",
      "\n",
      "开始评估LightGBM树模型...\n",
      "\n",
      "开始训练 LightGBM (Tree)...\n",
      "训练模型时出错: LGBMRegressor.fit() got an unexpected keyword argument 'verbose'\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.094876 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4096\n",
      "[LightGBM] [Info] Number of data points in the train set: 67683, number of used features: 437\n",
      "[LightGBM] [Info] Start training from score 1977293.724717\n",
      "快速模式: 跳过交叉验证，使用测试集性能作为替代\n",
      "\n",
      "LightGBM (Tree) 评估结果:\n",
      "训练时间: 2.63秒\n",
      "In-sample MAE: 70540.6438\n",
      "Out-of-sample MAE: 78239.8759\n",
      "CV MAE: 78239.8759\n",
      "In-sample RMSE: 334730.1417\n",
      "Out-of-sample RMSE: 416113.2555\n",
      "CV RMSE: 416113.2555\n",
      "In-sample R²: 0.9839\n",
      "Out-of-sample R²: 0.9747\n",
      "CV R²: 0.9747\n",
      "--------------------------------------------------\n",
      "\n",
      "开始评估XGBoost线性模型...\n",
      "\n",
      "开始训练 XGBoost (Linear)...\n",
      "快速模式: 跳过交叉验证，使用测试集性能作为替代\n",
      "\n",
      "XGBoost (Linear) 评估结果:\n",
      "训练时间: 5.87秒\n",
      "In-sample MAE: 578766.5000\n",
      "Out-of-sample MAE: 583542.5000\n",
      "CV MAE: 583542.5000\n",
      "In-sample RMSE: 1170249.2806\n",
      "Out-of-sample RMSE: 1196446.6678\n",
      "CV RMSE: 1196446.6678\n",
      "In-sample R²: 0.8035\n",
      "Out-of-sample R²: 0.7906\n",
      "CV R²: 0.7906\n",
      "--------------------------------------------------\n",
      "\n",
      "开始评估XGBoost树模型...\n",
      "\n",
      "开始训练 XGBoost (Tree)...\n",
      "快速模式: 跳过交叉验证，使用测试集性能作为替代\n",
      "\n",
      "XGBoost (Tree) 评估结果:\n",
      "训练时间: 4.59秒\n",
      "In-sample MAE: 62560.7695\n",
      "Out-of-sample MAE: 73360.7422\n",
      "CV MAE: 73360.7422\n",
      "In-sample RMSE: 212343.6864\n",
      "Out-of-sample RMSE: 394450.7489\n",
      "CV RMSE: 394450.7489\n",
      "In-sample R²: 0.9935\n",
      "Out-of-sample R²: 0.9772\n",
      "CV R²: 0.9772\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "boosting_results = evaluate_boosting_models(X_train, X_test, y_train, y_test, fast_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38dac420-22c2-4ab4-817c-f6b1397939d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "最佳梯度提升模型: XGBoost (Tree), 测试集MAE: 73360.7422\n"
     ]
    }
   ],
   "source": [
    "# # 获取最佳模型\n",
    "if boosting_results:\n",
    "    best_boosting_model = boosting_results[0]\n",
    "    print(f\"\\n最佳梯度提升模型: {best_boosting_model['model_name']}, 测试集MAE: {best_boosting_model['test_mae']:.4f}\")\n",
    "else:\n",
    "    print(\"所有梯度提升模型评估失败\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b94796c-8f2a-4da6-941c-e987fe3f48f8",
   "metadata": {},
   "source": [
    "## 3. Prediction and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "552328b0-405f-4b59-96db-f7406c383e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_normal_predictions(model, X_test, y_test):\n",
    "    \"\"\"计算去除异常值后的预测总数\"\"\"\n",
    "    print(\"\\n计算去除异常值后的预测总数...\")\n",
    "    \n",
    "    # 使用模型预测\n",
    "    y_pred = model.predict(X_test)\n",
    "    errors = np.abs(y_test - y_pred)\n",
    "    mean_error = np.mean(errors)\n",
    "    std_error = np.std(errors)\n",
    "    threshold = mean_error + 3 * std_error\n",
    "    \n",
    "    # 统计非异常值的预测数量\n",
    "    normal_predictions = np.sum(errors < threshold)\n",
    "    print(f\"去除异常值后的预测总数: {normal_predictions} (共 {len(y_test)} 个样本)\")\n",
    "    \n",
    "    return normal_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f08f6b8-62d1-413c-9e25-c8f72d01f70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions_for_submission(best_model, X_test_pca, test_df):\n",
    "    \"\"\"为提交生成预测结果\"\"\"\n",
    "    print(\"\\n为提交生成预测结果...\")\n",
    "    \n",
    "    # 使用最佳模型预测测试集\n",
    "    predictions = best_model.predict(X_test_pca)\n",
    "    \n",
    "    # 创建提交文件\n",
    "    # 假设测试集有房产ID列\n",
    "    id_column = test_df.iloc[:, 0].values if 'ID' not in test_df.columns else test_df['ID'].values\n",
    "    \n",
    "    submission_df = pd.DataFrame({\n",
    "        'ID': id_column,\n",
    "        'Price': predictions\n",
    "    })\n",
    "    \n",
    "    # 保存提交文件\n",
    "    submission_file = 'submission_boost.csv'\n",
    "    #submission_df.to_csv(submission_file, index=False)\n",
    "    print(f\"预测结果已保存到 {submission_file}\")\n",
    "    \n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c6ae025-6615-46b5-a7ff-47546ccad333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions_for_submission_new(best_model, X_test_features, test_df):\n",
    "    \"\"\"为提交生成预测结果，并确保ID和预测值长度匹配\"\"\"\n",
    "    print(\"\\n为提交生成预测结果...\")\n",
    "    print(f\"测试特征形状: {X_test_features.shape}\")\n",
    "    print(f\"测试数据形状: {test_df.shape}\")\n",
    "    \n",
    "    # 使用最佳模型预测测试集\n",
    "    predictions = best_model.predict(X_test_features)\n",
    "    print(f\"预测结果长度: {len(predictions)}\")\n",
    "    \n",
    "    # 获取ID列\n",
    "    id_column = test_df.iloc[:, 0].values if 'ID' not in test_df.columns else test_df['ID'].values\n",
    "    print(f\"ID列长度: {len(id_column)}\")\n",
    "    \n",
    "    # 确保ID列和预测结果长度匹配\n",
    "    if len(id_column) != len(predictions):\n",
    "        print(\"警告: ID列和预测结果长度不匹配。进行调整...\")\n",
    "        \n",
    "        # 如果两者长度不同，有以下几种可能性：\n",
    "        if len(id_column) > len(predictions):\n",
    "            # 情况1: 测试数据某些行在预处理时被删除了\n",
    "            # 解决方案: 对所有缺失的预测使用均值填充\n",
    "            print(\"ID数量大于预测数量，使用均值填充缺失预测...\")\n",
    "            mean_prediction = predictions.mean()\n",
    "            full_predictions = np.ones(len(id_column)) * mean_prediction\n",
    "            \n",
    "            # 使用已有的预测填充前面部分\n",
    "            full_predictions[:len(predictions)] = predictions\n",
    "            predictions = full_predictions\n",
    "        else:\n",
    "            # 情况2: 预测结果多于ID (这种情况较少见)\n",
    "            # 解决方案: 截断预测结果与ID匹配\n",
    "            print(\"预测数量大于ID数量，截断多余预测...\")\n",
    "            predictions = predictions[:len(id_column)]\n",
    "    \n",
    "    # 创建提交文件\n",
    "    submission_df = pd.DataFrame({\n",
    "        'ID': id_column,\n",
    "        'Price': predictions\n",
    "    })\n",
    "    \n",
    "    # 保存提交文件\n",
    "    submission_file = 'submission_xgboostlinear.csv'\n",
    "    submission_df.to_csv(submission_file, index=False)\n",
    "    print(f\"预测结果已保存到 {submission_file}\")\n",
    "    \n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c0e36a1-ab60-4668-b6e0-bc4ac6210ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model, feature_names, top_n=20):\n",
    "    \"\"\"绘制特征重要性图\"\"\"\n",
    "    if hasattr(model, 'coef_'):\n",
    "        # 获取系数\n",
    "        coef = model.coef_\n",
    "        \n",
    "        # 创建一个包含特征名称和系数的DataFrame\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Importance': np.abs(coef)\n",
    "        })\n",
    "        \n",
    "        # 按重要性降序排序\n",
    "        feature_importance = feature_importance.sort_values('Importance', ascending=False)\n",
    "        \n",
    "        # 选择前N个特征\n",
    "        top_features = feature_importance.head(top_n)\n",
    "        \n",
    "        # 绘制条形图\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.barplot(x='Importance', y='Feature', data=top_features)\n",
    "        plt.title(f'Top {top_n} 特征重要性')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('feature_importance.png')\n",
    "        plt.show()\n",
    "        \n",
    "        return feature_importance\n",
    "    else:\n",
    "        print(\"这个模型没有可以直接解释的特征系数。\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd3efb24-d0aa-497a-ae8a-59a199585f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "整体最佳模型: XGBoost (Tree)，测试集MAE: 73360.7422\n",
      "\n",
      "计算去除异常值后的预测总数...\n",
      "去除异常值后的预测总数: 16808 (共 16921 个样本)\n"
     ]
    }
   ],
   "source": [
    "# 选择整体最佳模型\n",
    "all_models = boosting_results\n",
    "sorted_all_models = sorted(all_models, key=lambda x: x['test_mae'])\n",
    "best_overall_model = sorted_all_models[0]\n",
    "\n",
    "print(f\"\\n整体最佳模型: {best_overall_model['model_name']}，测试集MAE: {best_overall_model['test_mae']:.4f}\")\n",
    "\n",
    "# 计算去除异常值后的预测总数\n",
    "if \"PCA\" in best_overall_model['model_name']:\n",
    "    normal_predictions = calculate_normal_predictions(best_overall_model['model'], X_test_pca, y_test)\n",
    "else:\n",
    "    normal_predictions = calculate_normal_predictions(best_overall_model['model'], X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2a37a13-5f9f-44cd-9f95-48e0fd153284",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.sans-serif'] = ['STZhongsong']  # 设置中文为“华文中宋”\n",
    "plt.rcParams['font.family'] = ['STZhongsong', 'Times New Roman']  # 设置英文字体为 Times New Roman\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 解决负号显示问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c9b75710-ac10-440c-abf2-a48728c0bbfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "处理测试数据...\n"
     ]
    }
   ],
   "source": [
    "if hasattr(best_overall_model['model'], 'coef_'):\n",
    "    plot_feature_importance(best_overall_model['model'], X.columns)\n",
    "\n",
    "# 处理测试数据并生成提交结果\n",
    "print(\"\\n处理测试数据...\")\n",
    "X_test_data, X_test_data_scaled, X_test_data_pca = process_data(train_df, test_df, details_df, rent_df, is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bfb01acf-e8dc-425a-b331-7ab5c680ca23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "为提交生成预测结果...\n",
      "测试特征形状: (16921, 562)\n",
      "测试数据形状: (14786, 31)\n",
      "预测结果长度: 16921\n",
      "ID列长度: 14786\n",
      "警告: ID列和预测结果长度不匹配。进行调整...\n",
      "预测数量大于ID数量，截断多余预测...\n",
      "预测结果已保存到 submission_xgboostlinear.csv\n",
      "\n",
      "分析完成!\n"
     ]
    }
   ],
   "source": [
    "# 根据最佳模型选择相应的特征集\n",
    "if \"PCA\" in best_overall_model['model_name']:\n",
    "    submission_df = generate_predictions_for_submission_new(best_overall_model['model'], X_test_data_pca, test_df)\n",
    "else:\n",
    "    submission_df = generate_predictions_for_submission_new(best_overall_model['model'], X_test, test_df)\n",
    "\n",
    "print(\"\\n分析完成!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py310)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
