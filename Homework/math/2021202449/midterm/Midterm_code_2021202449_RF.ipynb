{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91c7f332-e396-4495-a027-2f4bcbeb20a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa85187e-12b6-4304-bd37-b5326bebe120",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_excel(\"Data/ruc_Class25Q1_train.xlsx\")\n",
    "test_df = pd.read_excel(\"Data/ruc_Class25Q1_test.xlsx\")\n",
    "details_df = pd.read_excel(\"Data/ruc_Class25Q1_details.xlsx\")\n",
    "rent_df = pd.read_excel(\"Data/ruc_Class25Q1_rent.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca41a25-c8ee-4971-96ab-40b0351964f5",
   "metadata": {},
   "source": [
    "## 1. 数据预处理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5475a772-00fa-41f9-a2e3-34124a13d743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 全局变量，用于在训练和测试之间共享\n",
    "imputers = {}\n",
    "freq_map_for_test = {}\n",
    "encoded_columns = None\n",
    "feature_list = None\n",
    "scaler = None\n",
    "pca = None\n",
    "\n",
    "def process_data(train_df, test_df, details_df, rent_df, is_training=True):\n",
    "    \"\"\"\n",
    "    处理房价预测数据集，执行特征工程和数据预处理\n",
    "    \n",
    "    参数:\n",
    "    train_df: 训练数据集\n",
    "    test_df: 测试数据集\n",
    "    details_df: 小区详细信息数据集\n",
    "    rent_df: 租赁数据集\n",
    "    is_training: 是否为训练模式(True)或预测模式(False)\n",
    "    \n",
    "    返回:\n",
    "    X: 处理后的特征数据\n",
    "    y: 目标变量(仅在训练模式下)\n",
    "    scaler: 标准化对象(仅在训练模式下)\n",
    "    pca: PCA对象(仅在训练模式下)\n",
    "    \"\"\"\n",
    "    global imputers, freq_map_for_test, encoded_columns, feature_list, scaler, pca\n",
    "    \n",
    "    # 确定当前处理的数据集\n",
    "    if is_training:\n",
    "        df = train_df.copy()\n",
    "    else:\n",
    "        df = test_df.copy()\n",
    "        \n",
    "    # 1. 定义辅助函数\n",
    "    def extract_area(area_str):\n",
    "        if pd.isna(area_str):\n",
    "            return np.nan\n",
    "        # 移除所有非数字和小数点的字符\n",
    "        cleaned_str = re.sub(r'[^\\d.]', '', str(area_str))\n",
    "        try:\n",
    "            return float(cleaned_str) if cleaned_str else np.nan\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "    \n",
    "    def extract_floor_info(floor_str):\n",
    "        if pd.isna(floor_str):\n",
    "            return np.nan, np.nan\n",
    "        \n",
    "        # 提取当前楼层\n",
    "        current_match = re.search(r'(底层|低楼层|中楼层|高楼层|顶层)', str(floor_str))\n",
    "        current_floor = current_match.group(1) if current_match else np.nan\n",
    "        \n",
    "        # 提取总楼层\n",
    "        total_match = re.search(r'共(\\d+)层', str(floor_str))\n",
    "        total_floor = int(total_match.group(1)) if total_match else np.nan\n",
    "        \n",
    "        return current_floor, total_floor\n",
    "    \n",
    "    def extract_house_type(type_str):\n",
    "        if pd.isna(type_str):\n",
    "            return np.nan, np.nan, np.nan, np.nan\n",
    "        \n",
    "        rooms = re.search(r'(\\d+)室', str(type_str))\n",
    "        rooms = int(rooms.group(1)) if rooms else 0\n",
    "        \n",
    "        living_rooms = re.search(r'(\\d+)厅', str(type_str))\n",
    "        living_rooms = int(living_rooms.group(1)) if living_rooms else 0\n",
    "        \n",
    "        kitchens = re.search(r'(\\d+)厨', str(type_str))\n",
    "        kitchens = int(kitchens.group(1)) if kitchens else 0\n",
    "        \n",
    "        bathrooms = re.search(r'(\\d+)卫', str(type_str))\n",
    "        bathrooms = int(bathrooms.group(1)) if bathrooms else 0\n",
    "        \n",
    "        return rooms, living_rooms, kitchens, bathrooms\n",
    "    \n",
    "    def extract_number(x):\n",
    "        if pd.isna(x) or not isinstance(x, str):\n",
    "            return np.nan\n",
    "        match = re.search(r'(\\d+\\.?\\d*)', x)\n",
    "        if match:\n",
    "            return float(match.group(1))\n",
    "        return np.nan\n",
    "    \n",
    "    # 2. 处理面积数据\n",
    "    df['建筑面积_数值'] = df['建筑面积'].apply(extract_area)\n",
    "    df['套内面积_数值'] = df['套内面积'].apply(extract_area)\n",
    "    \n",
    "    # 3. 处理楼层信息\n",
    "    floor_info = df['所在楼层'].apply(extract_floor_info)\n",
    "    df['当前楼层'] = [x[0] for x in floor_info]\n",
    "    df['总楼层'] = [x[1] for x in floor_info]\n",
    "    \n",
    "    # 4. 处理户型信息\n",
    "    house_type_info = df['房屋户型'].apply(extract_house_type)\n",
    "    df['房间数'] = [x[0] for x in house_type_info]\n",
    "    df['客厅数'] = [x[1] for x in house_type_info]\n",
    "    df['厨房数'] = [x[2] for x in house_type_info]\n",
    "    df['卫生间数'] = [x[3] for x in house_type_info]\n",
    "    \n",
    "    # 5. 创建楼层比例特征\n",
    "    floor_map = {'底层': 0, '低楼层': 0.25, '中楼层': 0.5, '高楼层': 0.75, '顶层': 1}\n",
    "    df['楼层比例'] = df['当前楼层'].map(floor_map)\n",
    "    \n",
    "    # 6. 处理电梯\n",
    "    df['有电梯'] = df['配备电梯'].map({'有': 1, '无': 0})\n",
    "    \n",
    "    # 7. 与小区详情合并\n",
    "    merged_df = pd.merge(df, details_df, left_on=['小区名称', '城市'], right_on=['名称', '城市'], how='left')\n",
    "    \n",
    "    # 8. 提取小区建筑年代\n",
    "    merged_df['建筑年代_数值'] = merged_df['建筑年代'].str.extract(r'(\\d+)').astype(float)\n",
    "    \n",
    "    # 9. 提取容积率和绿化率\n",
    "    merged_df['容积率_数值'] = merged_df['容 积 率'].apply(extract_number)\n",
    "    merged_df['绿化率_数值'] = merged_df['绿 化 率'].apply(lambda x: extract_number(x)/100 if pd.notna(x) and isinstance(x, str) and '%' in x else extract_number(x))\n",
    "    \n",
    "    # 10. 计算房龄\n",
    "    current_year = 2025  # 假设当前年份为2024年\n",
    "    merged_df['房龄'] = current_year - merged_df['建筑年代_数值']\n",
    "    \n",
    "    # 11. 与租赁数据合并\n",
    "    rent_avg = rent_df.groupby('小区名称')['价格'].mean().reset_index()\n",
    "    rent_avg.rename(columns={'价格': '平均租金'}, inplace=True)\n",
    "    merged_df = pd.merge(merged_df, rent_avg, on='小区名称', how='left')\n",
    "    \n",
    "    # 12. 计算租售比 (只在训练集或包含价格信息时计算)\n",
    "    if is_training or '价格' in merged_df.columns:\n",
    "        merged_df['租售比'] = merged_df['平均租金'] / merged_df['价格']\n",
    "    \n",
    "    # 13. 频率编码\n",
    "    if is_training:\n",
    "        # 在训练集上计算频率\n",
    "        freq_map = merged_df['板块_x'].value_counts(normalize=True).to_dict()\n",
    "        # 保存频率映射，以便应用到测试集\n",
    "        freq_map_for_test = freq_map\n",
    "    else:\n",
    "        # 使用训练集上计算的频率映射\n",
    "        freq_map = freq_map_for_test\n",
    "    \n",
    "    merged_df['板块_x_freq'] = merged_df['板块_x'].map(freq_map)\n",
    "    \n",
    "    # 14. 删除不需要的列和有数据泄露的列\n",
    "    cols_to_drop = ['套内面积', '所在楼层', '房屋户型', '配备电梯', '名称', '建筑年代', \n",
    "                   '容 积 率', '绿 化 率', '物 业 费', '核心卖点', '户型介绍', '周边配套', '交通出行','建筑面积']\n",
    "    processed_df = merged_df.drop(columns=cols_to_drop, errors='ignore')\n",
    "    \n",
    "    # 15. 处理缺失值\n",
    "    # 获取数值型列\n",
    "    numeric_cols = processed_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    if is_training and '价格' in numeric_cols:\n",
    "        numeric_cols.remove('价格')\n",
    "    \n",
    "    # 重要修改：先创建所有列的imputer，然后再应用\n",
    "    if is_training:\n",
    "        # 初始化存储所有列的imputer\n",
    "        imputers = {}\n",
    "        for col in numeric_cols:\n",
    "            if processed_df[col].isnull().any():\n",
    "                imputer = SimpleImputer(strategy='median')\n",
    "                imputer.fit(processed_df[col].values.reshape(-1, 1))\n",
    "                imputers[col] = imputer\n",
    "    \n",
    "    # 应用imputer进行缺失值填充\n",
    "    for col in numeric_cols:\n",
    "        if processed_df[col].isnull().any():\n",
    "            if col in imputers:\n",
    "                # 使用已有的imputer填充\n",
    "                processed_df[col] = imputers[col].transform(processed_df[col].values.reshape(-1, 1))\n",
    "            else:\n",
    "                # 如果没有这个列的imputer(新列或测试集特有的列)，使用当前数据的中位数填充\n",
    "                median_val = processed_df[col].median()\n",
    "                processed_df[col].fillna(median_val, inplace=True)\n",
    "    \n",
    "    # 16. 处理分类特征\n",
    "    categorical_features_to_use = ['城市', '区域', '板块_x_freq', '环线', '装修情况', '当前楼层', '房屋朝向', '建筑结构_x', '别墅类型']\n",
    "    # 过滤存在于数据中的分类特征\n",
    "    categorical_features_to_use = [col for col in categorical_features_to_use if col in processed_df.columns]\n",
    "    \n",
    "    # 使用get_dummies进行One-Hot编码\n",
    "    if is_training:\n",
    "        # 在训练集上进行独热编码\n",
    "        processed_df_encoded = pd.get_dummies(processed_df, columns=categorical_features_to_use, drop_first=True)\n",
    "        # 保存编码的列，以便应用到测试集\n",
    "        encoded_columns = processed_df_encoded.columns\n",
    "    else:\n",
    "        # 在测试集上进行独热编码，确保列与训练集相同\n",
    "        processed_df_encoded = pd.get_dummies(processed_df, columns=categorical_features_to_use, drop_first=True)\n",
    "        \n",
    "        # 确保测试集与训练集具有相同的特征列\n",
    "        for col in encoded_columns:\n",
    "            if col not in processed_df_encoded.columns:\n",
    "                processed_df_encoded[col] = 0\n",
    "        \n",
    "        # 测试集可能有训练集没有的列，需要移除\n",
    "        extra_cols = [col for col in processed_df_encoded.columns if col not in encoded_columns]\n",
    "        if extra_cols:\n",
    "            processed_df_encoded = processed_df_encoded.drop(columns=extra_cols)\n",
    "        \n",
    "        # 确保列的顺序一致\n",
    "        processed_df_encoded = processed_df_encoded[encoded_columns.intersection(processed_df_encoded.columns)]\n",
    "    \n",
    "    # 17. 特征选择 - 选择用于训练的特征\n",
    "    # 移除不用于训练的列和冗余特征\n",
    "    columns_to_exclude = [\n",
    "        # 识别信息\n",
    "        '小区名称', '小区地址', '区县', \n",
    "        \n",
    "        # 冗余或潜在数据泄露特征\n",
    "        '板块_y', '建筑结构_y', '物业办公电话', '产权描述',\n",
    "        '供水', '供暖', '供电', '燃气费', '供热费', '停车位', '停车费用',\n",
    "        \n",
    "        # 已经转换为数值的特征原始列\n",
    "        '梯户比例', '交易时间', '交易权属', '上次交易', '房屋用途', '产权所属', \n",
    "        '抵押信息', '房屋年限', '环线位置',\n",
    "        \n",
    "        # 已有提取特征的原始数据\n",
    "        '开发商', '物业公司', '物业类别', '房屋优势', '房屋总数', '楼栋总数',\n",
    "        \n",
    "        # 可能与其他特征重复的坐标\n",
    "        'coord_x', 'coord_y', '板块_x'\n",
    "    ]\n",
    "    \n",
    "    # 获取特征列表\n",
    "    if is_training:\n",
    "        features = [col for col in processed_df_encoded.columns if col not in columns_to_exclude and col != '价格']\n",
    "        feature_list = features\n",
    "    else:\n",
    "        features = [col for col in feature_list if col in processed_df_encoded.columns]\n",
    "    \n",
    "    # 确保所有特征都存在于处理后的数据中\n",
    "    for col in features:\n",
    "        if col not in processed_df_encoded.columns:\n",
    "            processed_df_encoded[col] = 0  # 如果缺少某列，用0填充\n",
    "    \n",
    "    X = processed_df_encoded[features]\n",
    "    \n",
    "    # 18. 添加非线性特征\n",
    "    # 确保这些基础特征存在\n",
    "    base_features = ['建筑面积_数值', '房间数', '客厅数', '厨房数', '卫生间数', '总楼层', '房龄']\n",
    "    for feat in base_features:\n",
    "        if feat not in X.columns:\n",
    "            X[feat] = 0  # 使用0填充缺失的基础特征\n",
    "    \n",
    "    X['建筑面积_平方'] = X['建筑面积_数值'] ** 2\n",
    "    X['建筑面积_平方根'] = np.sqrt(X['建筑面积_数值'])\n",
    "    \n",
    "    # 特征交互 - 增加错误处理\n",
    "    # 避免除以零\n",
    "    X['房间密度'] = (X['房间数'] + X['客厅数'] + X['厨房数'] + X['卫生间数']) / X['建筑面积_数值'].replace(0, 1)\n",
    "    X['平均每房面积'] = X['建筑面积_数值'] / X['房间数'].replace(0, 1)\n",
    "    X['楼层面积比'] = X['总楼层'] / X['建筑面积_数值'].replace(0, 1)\n",
    "    X['房龄平方'] = X['房龄'] ** 2\n",
    "    \n",
    "    # 19. 标准化特征\n",
    "    if is_training:\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        # 可选: PCA降维\n",
    "        pca = PCA(n_components=0.95)  # 保留95%的方差\n",
    "        X_pca = pca.fit_transform(X_scaled)\n",
    "        \n",
    "        # 获取目标变量\n",
    "        y = processed_df_encoded['价格'] if '价格' in processed_df_encoded.columns else None\n",
    "        \n",
    "        return X, X_scaled, X_pca, y, scaler, pca, feature_list\n",
    "    else:\n",
    "        # 使用训练集的scaler\n",
    "        X_scaled = scaler.transform(X)\n",
    "        \n",
    "        # 使用训练集的PCA\n",
    "        X_pca = pca.transform(X_scaled)\n",
    "        \n",
    "        return X, X_scaled, X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3fee8bd-d57e-4056-9e9b-59993575e0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用示例:\n",
    "# 训练模式:\n",
    "X, X_scaled, X_pca, y, scaler, pca, feature_list = process_data(train_df, test_df, details_df, rent_df, is_training=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20853d50-820b-4cef-94e0-ef22e41a8ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试模式:\n",
    "X_test, X_test_scaled, X_test_pca = process_data(train_df, test_df, details_df, rent_df, is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74b2c384-1614-4bd9-8a97-bdb04dbd6f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集形状: (67683, 562)\n",
      "测试集形状: (16921, 562)\n",
      "PCA特征数量: 440\n"
     ]
    }
   ],
   "source": [
    "# 划分训练集和测试集\n",
    "X_train, X_test, X_train_scaled, X_test_scaled, X_train_pca, X_test_pca, y_train, y_test = train_test_split(\n",
    "    X, X_scaled, X_pca, y, test_size=0.2, random_state=111\n",
    ")\n",
    "\n",
    "print(f\"训练集形状: {X_train.shape}\")\n",
    "print(f\"测试集形状: {X_test.shape}\")\n",
    "print(f\"PCA特征数量: {X_train_pca.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a6b72d-059f-455d-bcc8-5ae45e22fe02",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering - random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e343e7b3-8886-41b0-baab-d5b0f26b0904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    \"\"\"评估模型性能，包括样本内外性能和交叉验证\"\"\"\n",
    "    start_time = time.time()\n",
    "    print(f\"\\n开始训练 {model_name}...\")\n",
    "    \n",
    "    # 训练模型\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 样本内预测\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    \n",
    "    # 样本外预测\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # 计算MAE\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    \n",
    "    # 计算RMSE\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    \n",
    "    # 计算R2\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # 6折交叉验证\n",
    "    print(f\"执行 {model_name} 的6折交叉验证...\")\n",
    "    cv = KFold(n_splits=6, shuffle=True, random_state=111)\n",
    "    \n",
    "    # 使用手动循环代替cross_val_score以添加进度条\n",
    "    cv_mae_scores = []\n",
    "    cv_rmse_scores = []\n",
    "    cv_r2_scores = []\n",
    "    \n",
    "    for train_idx, val_idx in tqdm(cv.split(X_train), total=6, desc=\"交叉验证进度\"):\n",
    "        X_cv_train, X_cv_val = X_train[train_idx], X_train[val_idx]\n",
    "        y_cv_train, y_cv_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        # 训练模型\n",
    "        model_cv = clone(model)\n",
    "        model_cv.fit(X_cv_train, y_cv_train)\n",
    "        \n",
    "        # 预测\n",
    "        y_cv_pred = model_cv.predict(X_cv_val)\n",
    "        \n",
    "        # 计算指标\n",
    "        cv_mae_scores.append(mean_absolute_error(y_cv_val, y_cv_pred))\n",
    "        cv_rmse_scores.append(np.sqrt(mean_squared_error(y_cv_val, y_cv_pred)))\n",
    "        cv_r2_scores.append(r2_score(y_cv_val, y_cv_pred))\n",
    "    \n",
    "    # 计算平均分数\n",
    "    cv_mae = np.mean(cv_mae_scores)\n",
    "    cv_rmse = np.mean(cv_rmse_scores)\n",
    "    cv_r2 = np.mean(cv_r2_scores)\n",
    "    \n",
    "    # 计算训练时间\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # 输出结果\n",
    "    print(f\"\\n{model_name} 评估结果:\")\n",
    "    print(f\"训练时间: {training_time:.2f}秒\")\n",
    "    print(f\"In-sample MAE: {train_mae:.4f}\")\n",
    "    print(f\"Out-of-sample MAE: {test_mae:.4f}\")\n",
    "    print(f\"CV MAE: {cv_mae:.4f}\")\n",
    "    print(f\"In-sample RMSE: {train_rmse:.4f}\")\n",
    "    print(f\"Out-of-sample RMSE: {test_rmse:.4f}\")\n",
    "    print(f\"CV RMSE: {cv_rmse:.4f}\")\n",
    "    print(f\"In-sample R²: {train_r2:.4f}\")\n",
    "    print(f\"Out-of-sample R²: {test_r2:.4f}\")\n",
    "    print(f\"CV R²: {cv_r2:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'train_mae': train_mae,\n",
    "        'test_mae': test_mae,\n",
    "        'cv_mae': cv_mae,\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'cv_rmse': cv_rmse,\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2,\n",
    "        'cv_r2': cv_r2,\n",
    "        'training_time': training_time,\n",
    "        'model': model\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c7b023c-95c1-4502-ac9a-c33a72bc8f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_features(X, y, n_features=200):\n",
    "    \"\"\"使用特征重要性选择最佳特征\"\"\"\n",
    "    from sklearn.feature_selection import SelectFromModel\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    \n",
    "    # 使用随机森林确定特征重要性\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=111)\n",
    "    rf.fit(X, y)\n",
    "    \n",
    "    # 创建选择器\n",
    "    selector = SelectFromModel(rf, threshold=-np.inf, max_features=n_features)\n",
    "    selector.fit(X, y)\n",
    "    \n",
    "    # 获取选择的特征\n",
    "    selected_features = X.columns[selector.get_support()]\n",
    "    print(f\"已选择{len(selected_features)}个最重要特征\")\n",
    "    \n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5ad36cc-e6d5-4662-a2d4-8a805b23ba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_nonlinear_features(X):\n",
    "    \"\"\"添加非线性特征和交互特征\"\"\"\n",
    "    X_new = X.copy()\n",
    "    \n",
    "    # 数值型特征列表\n",
    "    numeric_cols = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "    key_features = ['建筑面积_数值', '房间数', '客厅数', '总楼层', '房龄', '平均租金']\n",
    "    \n",
    "    # 添加更多非线性转换\n",
    "    for col in key_features:\n",
    "        if col in X.columns:\n",
    "            # 对数变换\n",
    "            X_new[f'{col}_log'] = np.log1p(X[col].replace(0, 1e-5))\n",
    "            \n",
    "            # 平方根变换\n",
    "            X_new[f'{col}_sqrt'] = np.sqrt(X[col].replace(0, 0))\n",
    "            \n",
    "            # 立方根变换\n",
    "            X_new[f'{col}_cbrt'] = np.cbrt(X[col])\n",
    "            \n",
    "            # 平方变换\n",
    "            X_new[f'{col}_squared'] = X[col] ** 2\n",
    "            \n",
    "            # 立方变换\n",
    "            X_new[f'{col}_cubed'] = X[col] ** 3\n",
    "    \n",
    "    # 添加交互特征\n",
    "    for i, col1 in enumerate(key_features):\n",
    "        if col1 not in X.columns:\n",
    "            continue\n",
    "            \n",
    "        for col2 in key_features[i+1:]:\n",
    "            if col2 not in X.columns:\n",
    "                continue\n",
    "                \n",
    "            # 特征相乘\n",
    "            X_new[f'{col1}_{col2}_mult'] = X[col1] * X[col2]\n",
    "            \n",
    "            # 特征相除 (避免除以零)\n",
    "            X_new[f'{col1}_{col2}_div'] = X[col1] / X[col2].replace(0, 1e-5)\n",
    "            \n",
    "            # 特征之和\n",
    "            X_new[f'{col1}_{col2}_sum'] = X[col1] + X[col2]\n",
    "            \n",
    "            # 特征之差\n",
    "            X_new[f'{col1}_{col2}_diff'] = X[col1] - X[col2]\n",
    "    \n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14e9b3cd-071b-4080-8b85-abc24d995404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# 对关键特征添加多项式特征\n",
    "def add_polynomial_features(X, degree=2):\n",
    "    \"\"\"为关键特征添加多项式特征\"\"\"\n",
    "    # 选择关键特征\n",
    "    key_features = ['建筑面积_数值', '房龄', '总楼层', '平均租金']\n",
    "    key_features = [col for col in key_features if col in X.columns]\n",
    "    \n",
    "    if not key_features:\n",
    "        return X.copy()\n",
    "    \n",
    "    # 创建多项式特征生成器\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    \n",
    "    # 对关键特征生成多项式\n",
    "    X_poly = poly.fit_transform(X[key_features])\n",
    "    \n",
    "    # 创建多项式特征的列名\n",
    "    poly_features = pd.DataFrame(\n",
    "        X_poly, \n",
    "        columns=poly.get_feature_names_out(input_features=key_features),\n",
    "        index=X.index\n",
    "    )\n",
    "    \n",
    "    # 只保留交互项和高阶项（去除原始特征）\n",
    "    poly_features = poly_features.iloc[:, len(key_features):]\n",
    "    \n",
    "    # 合并回原始特征集\n",
    "    return pd.concat([X, poly_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c30278f-c839-4f0d-8b6d-4cd5a556ed90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "添加非线性特征...\n",
      "添加非线性特征后的特征数: 652\n",
      "添加多项式特征...\n",
      "添加多项式特征后的特征数: 662\n"
     ]
    }
   ],
   "source": [
    "# 添加非线性特征\n",
    "print(\"添加非线性特征...\")\n",
    "X_enhanced = add_nonlinear_features(X)\n",
    "print(f\"添加非线性特征后的特征数: {X_enhanced.shape[1]}\")\n",
    "\n",
    "# 添加多项式特征\n",
    "print(\"添加多项式特征...\")\n",
    "X_poly = add_polynomial_features(X_enhanced, degree=2)\n",
    "print(f\"添加多项式特征后的特征数: {X_poly.shape[1]}\")\n",
    "\n",
    "# 标准化新特征集\n",
    "scaler_enhanced = StandardScaler()\n",
    "X_scaled_enhanced = scaler_enhanced.fit_transform(X_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba229c97-8a67-44aa-8a3b-c9895b0bc341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "执行特征选择...\n",
      "已选择300个最重要特征\n",
      "特征选择后的特征数: 300\n"
     ]
    }
   ],
   "source": [
    "# 特征选择\n",
    "print(\"执行特征选择...\")\n",
    "selected_features = select_best_features(X_poly, y, n_features=300)\n",
    "X_selected = X_poly[selected_features]\n",
    "print(f\"特征选择后的特征数: {X_selected.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc9293c9-e1be-4949-8dc2-4f46a3252855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准化选定的特征\n",
    "scaler_selected = StandardScaler()\n",
    "X_scaled_selected = scaler_selected.fit_transform(X_selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18e08828-087c-4e96-ab4a-0c0b34a302ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集形状: (67683, 300)\n",
      "测试集形状: (16921, 300)\n"
     ]
    }
   ],
   "source": [
    "# 划分训练集和测试集\n",
    "X_train, X_test, X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(\n",
    "    X_selected, X_scaled_selected, y, test_size=0.2, random_state=111\n",
    ")\n",
    "\n",
    "print(f\"训练集形状: {X_train.shape}\")\n",
    "print(f\"测试集形状: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2e18eb6-4159-4039-9ced-6540486b3315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理测试数据\n",
    "X_test_data, X_test_data_scaled, X_test_data_pca = process_data(train_df, test_df, details_df, rent_df, is_training=False)\n",
    "\n",
    "# 添加与训练集相同的非线性特征\n",
    "X_test_enhanced = add_nonlinear_features(X_test_data)\n",
    "\n",
    "# 添加多项式特征\n",
    "X_test_poly = add_polynomial_features(X_test_enhanced, degree=2)\n",
    "\n",
    "# 只选择训练时使用的特征\n",
    "X_test_selected = X_test_poly[selected_features]\n",
    "\n",
    "# 标准化\n",
    "X_test_scaled_selected = scaler_selected.transform(X_test_selected)\n",
    "\n",
    "# # 使用最佳模型生成预测\n",
    "# best_model = models_results['best_model']['model']\n",
    "# submission_df = generate_predictions_for_submission_improved(best_model, X_test_scaled_selected, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7bd44a-eb84-46ba-8e0e-d865047b1e9d",
   "metadata": {},
   "source": [
    "## 3. Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9481fb0-1562-45b9-8272-7bd9cd2c8860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X_train, X_test, y_train, y_test, use_pca=True):\n",
    "    \"\"\"训练多个模型并返回评估结果\"\"\"\n",
    "    models = []\n",
    "    \n",
    "    # 选择使用原始特征还是PCA特征\n",
    "    X_train_data = X_train_pca if use_pca else X_train_scaled\n",
    "    X_test_data = X_test_pca if use_pca else X_test_scaled\n",
    "    \n",
    "    # 线性回归（OLS）\n",
    "    suffix = \"(PCA)\" if use_pca else \"\"\n",
    "    ols = LinearRegression()\n",
    "    ols_results = evaluate_model(ols, X_train_data, X_test_data, y_train, y_test, f\"OLS {suffix}\")\n",
    "    models.append(ols_results)\n",
    "    \n",
    "    # Lasso回归（L1正则化） -  # 增大alpha值, 减少最大迭代次数\n",
    "    lasso = Lasso(alpha=1.0, max_iter=500, tol=0.1, warm_start=True, random_state=111)\n",
    "    lasso_results = evaluate_model(lasso, X_train_data, X_test_data, y_train, y_test, f\"Lasso {suffix}\")\n",
    "    models.append(lasso_results)\n",
    "    \n",
    "    # Ridge回归（L2正则化）\n",
    "    ridge = Ridge(alpha=1.0, random_state=111)\n",
    "    ridge_results = evaluate_model(ridge, X_train_data, X_test_data, y_train, y_test, f\"Ridge {suffix}\")\n",
    "    models.append(ridge_results)\n",
    "    \n",
    "    # ElasticNet（结合L1和L2正则化）\n",
    "    elastic = ElasticNet(alpha=0.01, l1_ratio=0.5, max_iter=10000, random_state=111)\n",
    "    elastic_results = evaluate_model(elastic, X_train_data, X_test_data, y_train, y_test, f\"ElasticNet {suffix}\")\n",
    "    models.append(elastic_results)\n",
    "    \n",
    "    # 按测试集MAE排序\n",
    "    sorted_models = sorted(models, key=lambda x: x['test_mae'])\n",
    "    best_model = sorted_models[0]\n",
    "    \n",
    "    print(f\"\\n总体最佳模型: {best_model['model_name']}，测试集MAE: {best_model['test_mae']:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'models': models,\n",
    "        'best_model': best_model,\n",
    "        'ols_results': ols_results,\n",
    "        'lasso_results': lasso_results,\n",
    "        'ridge_results': ridge_results,\n",
    "        'elastic_results': elastic_results\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9368faa1-8c10-4a44-81e9-d3c192cca57a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "使用特征选择+标准化特征训练模型...\n",
      "\n",
      "开始训练 OLS ...\n",
      "执行 OLS  的6折交叉验证...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "交叉验证进度: 100%|██████████████████████████████████████████████████████████████████████| 6/6 [00:09<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OLS  评估结果:\n",
      "训练时间: 11.42秒\n",
      "In-sample MAE: 452971.0437\n",
      "Out-of-sample MAE: 454830.0627\n",
      "CV MAE: 626097.2592\n",
      "In-sample RMSE: 923596.2754\n",
      "Out-of-sample RMSE: 979017.0221\n",
      "CV RMSE: 16958405.8980\n",
      "In-sample R²: 0.8776\n",
      "Out-of-sample R²: 0.8598\n",
      "CV R²: -182.8419\n",
      "--------------------------------------------------\n",
      "\n",
      "开始训练 Lasso ...\n",
      "执行 Lasso  的6折交叉验证...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "交叉验证进度: 100%|██████████████████████████████████████████████████████████████████████| 6/6 [00:05<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso  评估结果:\n",
      "训练时间: 6.93秒\n",
      "In-sample MAE: 527124.3624\n",
      "Out-of-sample MAE: 526794.7532\n",
      "CV MAE: 546221.5315\n",
      "In-sample RMSE: 1050400.7489\n",
      "Out-of-sample RMSE: 1054245.9689\n",
      "CV RMSE: 2446546.8131\n",
      "In-sample R²: 0.8417\n",
      "Out-of-sample R²: 0.8374\n",
      "CV R²: -1.1331\n",
      "--------------------------------------------------\n",
      "\n",
      "开始训练 Ridge ...\n",
      "执行 Ridge  的6折交叉验证...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "交叉验证进度: 100%|██████████████████████████████████████████████████████████████████████| 6/6 [00:03<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ridge  评估结果:\n",
      "训练时间: 4.63秒\n",
      "In-sample MAE: 461744.1876\n",
      "Out-of-sample MAE: 463676.9958\n",
      "CV MAE: 475741.6789\n",
      "In-sample RMSE: 932629.8914\n",
      "Out-of-sample RMSE: 976216.1972\n",
      "CV RMSE: 1624241.4705\n",
      "In-sample R²: 0.8752\n",
      "Out-of-sample R²: 0.8606\n",
      "CV R²: 0.4552\n",
      "--------------------------------------------------\n",
      "\n",
      "开始训练 ElasticNet ...\n",
      "执行 ElasticNet  的6折交叉验证...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "交叉验证进度: 100%|██████████████████████████████████████████████████████████████████| 6/6 [3:06:10<00:00, 1861.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ElasticNet  评估结果:\n",
      "训练时间: 13350.87秒\n",
      "In-sample MAE: 459978.1336\n",
      "Out-of-sample MAE: 461489.4971\n",
      "CV MAE: 464938.2949\n",
      "In-sample RMSE: 941627.4374\n",
      "Out-of-sample RMSE: 985635.4672\n",
      "CV RMSE: 973454.3563\n",
      "In-sample R²: 0.8728\n",
      "Out-of-sample R²: 0.8579\n",
      "CV R²: 0.8637\n",
      "--------------------------------------------------\n",
      "\n",
      "总体最佳模型: OLS ，测试集MAE: 454830.0627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n使用特征选择+标准化特征训练模型...\")\n",
    "selected_models_results = train_models(X_train_scaled, X_test_scaled, y_train, y_test, use_pca=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8ab5cc-818d-4074-b8c0-33d4eff5b5ed",
   "metadata": {},
   "source": [
    "## prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee99ae07-577e-4e50-bb93-0d736edbaab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9885137-2fe0-49ef-8f0b-d815e7b044b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_normal_predictions(model, X_test, y_test):\n",
    "    \"\"\"计算去除异常值后的预测总数\"\"\"\n",
    "    print(\"\\n计算去除异常值后的预测总数...\")\n",
    "    \n",
    "    # 使用模型预测\n",
    "    y_pred = model.predict(X_test)\n",
    "    errors = np.abs(y_test - y_pred)\n",
    "    mean_error = np.mean(errors)\n",
    "    std_error = np.std(errors)\n",
    "    threshold = mean_error + 3 * std_error\n",
    "    \n",
    "    # 统计非异常值的预测数量\n",
    "    normal_predictions = np.sum(errors < threshold)\n",
    "    print(f\"去除异常值后的预测总数: {normal_predictions} (共 {len(y_test)} 个样本)\")\n",
    "    \n",
    "    return normal_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e12c819c-4f54-4989-b474-a8a44d888f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions_for_submission_new(best_model, X_test_features, test_df):\n",
    "    \"\"\"为提交生成预测结果，并确保ID和预测值长度匹配\"\"\"\n",
    "    print(\"\\n为提交生成预测结果...\")\n",
    "    print(f\"测试特征形状: {X_test_features.shape}\")\n",
    "    print(f\"测试数据形状: {test_df.shape}\")\n",
    "    \n",
    "    # 使用最佳模型预测测试集\n",
    "    predictions = best_model.predict(X_test_features)\n",
    "    print(f\"预测结果长度: {len(predictions)}\")\n",
    "    \n",
    "    # 获取ID列\n",
    "    id_column = test_df.iloc[:, 0].values if 'ID' not in test_df.columns else test_df['ID'].values\n",
    "    print(f\"ID列长度: {len(id_column)}\")\n",
    "    \n",
    "    # 确保ID列和预测结果长度匹配\n",
    "    if len(id_column) != len(predictions):\n",
    "        print(\"警告: ID列和预测结果长度不匹配。进行调整...\")\n",
    "        \n",
    "        # 如果两者长度不同，有以下几种可能性：\n",
    "        if len(id_column) > len(predictions):\n",
    "            # 情况1: 测试数据某些行在预处理时被删除了\n",
    "            # 解决方案: 对所有缺失的预测使用均值填充\n",
    "            print(\"ID数量大于预测数量，使用均值填充缺失预测...\")\n",
    "            mean_prediction = predictions.mean()\n",
    "            full_predictions = np.ones(len(id_column)) * mean_prediction\n",
    "            \n",
    "            # 使用已有的预测填充前面部分\n",
    "            full_predictions[:len(predictions)] = predictions\n",
    "            predictions = full_predictions\n",
    "        else:\n",
    "            # 情况2: 预测结果多于ID (这种情况较少见)\n",
    "            # 解决方案: 截断预测结果与ID匹配\n",
    "            print(\"预测数量大于ID数量，截断多余预测...\")\n",
    "            predictions = predictions[:len(id_column)]\n",
    "    \n",
    "    # 创建提交文件\n",
    "    submission_df = pd.DataFrame({\n",
    "        'ID': id_column,\n",
    "        'Price': predictions\n",
    "    })\n",
    "    \n",
    "    # 保存提交文件\n",
    "    submission_file = 'submission_endlasso.csv'\n",
    "    submission_df.to_csv(submission_file, index=False)\n",
    "    print(f\"预测结果已保存到 {submission_file}\")\n",
    "    \n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3831b73-bf17-491b-a5c2-df0e99390341",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'selected_models_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 选择整体最佳模型\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m all_models \u001b[38;5;241m=\u001b[39m \u001b[43mselected_models_results\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m sorted_all_models \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(all_models, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_mae\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m best_overall_model \u001b[38;5;241m=\u001b[39m sorted_all_models[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'selected_models_results' is not defined"
     ]
    }
   ],
   "source": [
    "# 选择整体最佳模型\n",
    "all_models = selected_models_results['models']\n",
    "sorted_all_models = sorted(all_models, key=lambda x: x['test_mae'])\n",
    "best_overall_model = sorted_all_models[4]\n",
    "\n",
    "print(f\"\\n整体最佳模型: {best_overall_model['model_name']}，测试集MAE: {best_overall_model['test_mae']:.4f}\")\n",
    "\n",
    "# 计算去除异常值后的预测总数\n",
    "if \"PCA\" in best_overall_model['model_name']:\n",
    "    normal_predictions = calculate_normal_predictions(best_overall_model['model'], X_test_pca, y_test)\n",
    "else:\n",
    "    normal_predictions = calculate_normal_predictions(best_overall_model['model'], X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034d31da-1dad-41c6-b9e5-8b6ff5ed6ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "为提交生成预测结果...\n",
      "测试特征形状: (16921, 300)\n",
      "测试数据形状: (14786, 31)\n",
      "预测结果长度: 16921\n",
      "ID列长度: 14786\n",
      "警告: ID列和预测结果长度不匹配。进行调整...\n",
      "预测数量大于ID数量，截断多余预测...\n",
      "预测结果已保存到 submission_endlasso.csv\n",
      "\n",
      "分析完成!\n"
     ]
    }
   ],
   "source": [
    "# 根据最佳模型选择相应的特征集\n",
    "if \"PCA\" in best_overall_model['model_name']:\n",
    "    submission_df = generate_predictions_for_submission_new(best_overall_model['model'], X_test_data_pca, test_df)\n",
    "else:\n",
    "    submission_df = generate_predictions_for_submission_new(best_overall_model['model'], X_test_scaled, test_df)\n",
    "\n",
    "print(\"\\n分析完成!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py310)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
